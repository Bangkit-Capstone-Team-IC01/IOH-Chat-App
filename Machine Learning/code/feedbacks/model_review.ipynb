{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_review.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Load the Data**"
      ],
      "metadata": {
        "id": "Z_rKaPqbEMJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "EsU8eTWe2s-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Nn766VAjvuS"
      },
      "outputs": [],
      "source": [
        "#panggil dataset yang telah disimpan di Google Drive pribadi\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#explore the dataset\n",
        "with open(\"/content/drive/MyDrive/Pribadi/data_feedbacks.csv\", 'r') as csvfile:\n",
        "    print(f\"First line (header) looks like this:\\n\\n{csvfile.readline()}\")\n",
        "    print(f\"Each data point looks like this:\\n\\n{csvfile.readline()}\")"
      ],
      "metadata": {
        "id": "Od6WLQB2kAkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing Stopwords**"
      ],
      "metadata": {
        "id": "GU0n0TgwkZoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwVs4ly5khze",
        "outputId": "c033ebe2-6cba-45d7-d65a-bf89e1659a33"
      },
      "execution_count": 838,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sastrawi in /usr/local/lib/python3.7/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: remove_stopwords\n",
        "def remove_stopwords(ulasan):\n",
        "    # List of stopwords\n",
        "    stopwords = [\"yang\", \"untuk\", \"pada\", \"ke\", \"para\", \"namun\", \"menurut\", \"antara\", \"dia\", \"dua\", \"ia\", \"seperti\", \n",
        "              \"jika\", \"sehingga\", \"kembali\", \"dan\", \"karena\", \"kepada\", \"oleh\", \"saat\", \"harus\", \"sementara\", \n",
        "              \"setelah\", \"belum\", \"kami\", \"sekitar\", \"bagi\", \"serta\", \"di\", \"dari\", \"telah\", \"sebagai\", \"masih\", \n",
        "              \"hal\", \"ketika\", \"adalah\", \"itu\", \"dalam\", \"bisa\", \"bahwa\", \"atau\", \"hanya\", \"kita\", \"dengan\", \"akan\", \n",
        "              \"juga\", \"ada\", \"mereka\", \"sudah\", \"saya\", \"terhadap\", \"secara\", \"agar\", \"lain\", \"anda\", \"begitu\", \"mengapa\", \n",
        "              \"kenapa\", \"yaitu\", \"yakni\", \"daripada\", \"itulah\", \"lagi\", \"maka\", \"tentang\", \"demi\", \"dimana\", \"kemana\",\n",
        "              \"pula\", \"sambil\", \"sebelum\", \"sesudah\", \"supaya\", \"guna\", \"kah\", \"pun\", \"sampai\", \"sedangkan\", \"selagi\",\n",
        "              \"sementara\", \"tetapi\", \"apakah\", \"kecuali\", \"sebab\", \"selain\", \"seolah\", \"seterusnya\", \"tanpa\", \"agak\",\n",
        "              \"boleh\", \"dapat\", \"dsb\", \"dst\", \"dll\", \"dahulu\", \"dulunya\", \"anu\", \"demikian\", \"tapi\", \"ingin\", \"juga\",\n",
        "              \"nggak\", \"mari\", \"nanti\", \"melainkan\", \"oh\", \"ok\"]\n",
        "    \n",
        "    # Sentence converted to lowercase-only\n",
        "    ulasan = ulasan.lower()\n",
        "    \n",
        "    ### START CODE HERE\n",
        "    \n",
        "    # Use this to read file content as a stream:\n",
        "    words = ulasan.split()\n",
        "    ulasan = []\n",
        "    for r in words:\n",
        "        if not r in ulasan:\n",
        "            ulasan.append(r)\n",
        "            \n",
        "    ulasan=\" \".join(ulasan)\n",
        "    ### END CODE HERE\n",
        "    return ulasan"
      ],
      "metadata": {
        "id": "xkvgxMFpkxjm"
      },
      "execution_count": 839,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**convert to lowercase, strip and remove punctuations**"
      ],
      "metadata": {
        "id": "Nq0TdQGUzXv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(ulasan):\n",
        "    ulasan = ulasan.lower() \n",
        "    ulasan = ulasan.strip()  \n",
        "    ulasan = re.compile('<.*?>').sub('', ulasan) \n",
        "    ulasan = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', ulasan)  \n",
        "    ulasan = re.sub('\\s+', ' ', ulasan)  \n",
        "    ulasan = re.sub(r'\\[[0-9]*\\]',' ',ulasan) \n",
        "    ulasan = re.sub(r'[^\\w\\s]', '', str(ulasan).lower().strip())\n",
        "    ulasan = re.sub(r'\\d',' ',ulasan) \n",
        "    ulasan = re.sub(r'\\s+',' ',ulasan) \n",
        "    return ulasan"
      ],
      "metadata": {
        "id": "PYezrSbIzaD_"
      },
      "execution_count": 840,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reading the raw data**"
      ],
      "metadata": {
        "id": "T91QdnYi5Ca9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_data_from_file(filename):\n",
        "    ulasan = []\n",
        "    label = []\n",
        "    with open(filename, 'r') as csvfile:\n",
        "        ### START CODE HERE\n",
        "        skip = True\n",
        "        if skip:\n",
        "            skip = False\n",
        "            reader = csv.reader(csvfile, delimiter=',')\n",
        "            next(reader)\n",
        "\n",
        "            for row in reader:\n",
        "                row[0] = remove_stopwords(row[0])\n",
        "                row[1] = remove_stopwords(row[1])\n",
        "                label.append(row[0])\n",
        "                ulasan.append(row[1])\n",
        "            \n",
        "        ### END CODE HERE\n",
        "    return ulasan, label"
      ],
      "metadata": {
        "id": "yuztjVYs5F1b"
      },
      "execution_count": 841,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function\n",
        "ulasan, label = parse_data_from_file(\"/content/drive/MyDrive/Pribadi/data_feedbacks.csv\")\n",
        "\n",
        "print(f\"There are {len(ulasan)} sentences in the dataset.\\n\")\n",
        "print(f\"First sentence has {len(ulasan[0])} words (after removing stopwords).\\n\")\n",
        "print(f\"There are {len(label)} labels in the dataset.\\n\")\n",
        "print(f\"The first 5 labels are {label[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGqKK8ss5Qr5",
        "outputId": "f0aab21e-a5bc-433d-8ac0-22771e5fb44c"
      },
      "execution_count": 842,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 200 sentences in the dataset.\n",
            "\n",
            "First sentence has 323 words (after removing stopwords).\n",
            "\n",
            "There are 200 labels in the dataset.\n",
            "\n",
            "The first 5 labels are ['1', '1', '1', '1', '0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Pre-Processing**"
      ],
      "metadata": {
        "id": "EIvc8zq3EHOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the lemmatizer\n",
        "wl = WordNetLemmatizer()\n",
        " \n",
        "# This is a helper function to map NTLK position tags\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "# Tokenize the sentence\n",
        "def lemmatizer(string):\n",
        "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
        "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
        "    return \" \".join(a)"
      ],
      "metadata": {
        "id": "mw-bJuDABnaT"
      },
      "execution_count": 844,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finalpreprocess(string):\n",
        "    return lemmatizer(stopword(preprocess(string)))"
      ],
      "metadata": {
        "id": "I9OhfuclBfNs"
      },
      "execution_count": 845,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text'] = df['ulasan'].apply(lambda x: finalpreprocess(x))\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5hmh2-_SA2zN",
        "outputId": "499d0770-7fd2-425c-e6fb-ca2e72876011"
      },
      "execution_count": 846,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                             ulasan  \\\n",
              "0    1.0  Secara keseluruhan saya menyukai aplikasi ini,...   \n",
              "1    1.0  Saya beri 4 bintang karena versi PC memiliki f...   \n",
              "2    0.0  1. Autoscroll ke bawah tidak dapat dinonaktifk...   \n",
              "3    1.0  Benar-benar waktu yang baik menggunakan aplika...   \n",
              "4    1.0  Ini adalah aplikasi yang bagus dan sangat muda...   \n",
              "\n",
              "                                          clean_text  \n",
              "0  cara seluruh saya suka aplikasi ini tetapi mas...  \n",
              "1  saya beri bintang karena versi pc milik fitur ...  \n",
              "2  autoscroll ke bawah tidak dapat nonaktif yang ...  \n",
              "3  benar benar waktu yang baik guna aplikasi ini ...  \n",
              "4  ini adalah aplikasi yang bagus dan sangat muda...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-732ca41a-e76f-463d-9f49-f4049c167376\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>ulasan</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Secara keseluruhan saya menyukai aplikasi ini,...</td>\n",
              "      <td>cara seluruh saya suka aplikasi ini tetapi mas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Saya beri 4 bintang karena versi PC memiliki f...</td>\n",
              "      <td>saya beri bintang karena versi pc milik fitur ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1. Autoscroll ke bawah tidak dapat dinonaktifk...</td>\n",
              "      <td>autoscroll ke bawah tidak dapat nonaktif yang ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Benar-benar waktu yang baik menggunakan aplika...</td>\n",
              "      <td>benar benar waktu yang baik guna aplikasi ini ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Ini adalah aplikasi yang bagus dan sangat muda...</td>\n",
              "      <td>ini adalah aplikasi yang bagus dan sangat muda...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-732ca41a-e76f-463d-9f49-f4049c167376')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-732ca41a-e76f-463d-9f49-f4049c167376 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-732ca41a-e76f-463d-9f49-f4049c167376');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 846
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining some useful global variables**"
      ],
      "metadata": {
        "id": "6hiBKrAWRk8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 100\n",
        "MAXLEN = 16\n",
        "TRUNCATING = 'post'\n",
        "PADDING = 'post'\n",
        "OOV_TOKEN = \"<OOV>\"\n",
        "MAX_EXAMPLES = 160000\n",
        "TRAINING_SPLIT = 0.9"
      ],
      "metadata": {
        "id": "jWbNu04nRnnG"
      },
      "execution_count": 847,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_split(ulasan, label, training_split):\n",
        "    \n",
        "    ### START CODE HERE\n",
        "    \n",
        "    # Compute the number of ulasan that will be used for training (should be an integer)\n",
        "    train_size = int(len(ulasan)*training_split)\n",
        "\n",
        "    # Split the sentences and labels into train/validation splits\n",
        "    train_ulasan = ulasan[:train_size]\n",
        "    train_label = label[:train_size]\n",
        "\n",
        "    validation_ulasan = ulasan[train_size:]\n",
        "    validation_label = label[train_size:]\n",
        "    \n",
        "    ### END CODE HERE\n",
        "    \n",
        "    return train_ulasan, validation_ulasan, train_label, validation_label"
      ],
      "metadata": {
        "id": "_gNwg74YRuPi"
      },
      "execution_count": 848,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function\n",
        "train_ulasan, validation_ulasan, train_label, validation_label = train_val_split(ulasan, label, TRAINING_SPLIT)\n",
        "\n",
        "print(f\"There are {len(train_ulasan)} sentences for training.\\n\")\n",
        "print(f\"There are {len(train_label)} labels for training.\\n\")\n",
        "print(f\"There are {len(validation_ulasan)} sentences for validation.\\n\")\n",
        "print(f\"There are {len(validation_label)} labels for validation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhtT_fjWSba6",
        "outputId": "e1cd64db-4b88-44b8-c73b-87b451d29afd"
      },
      "execution_count": 849,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 180 sentences for training.\n",
            "\n",
            "There are 180 labels for training.\n",
            "\n",
            "There are 20 sentences for validation.\n",
            "\n",
            "There are 20 labels for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization - Sequences, truncating and padding**"
      ],
      "metadata": {
        "id": "2ylzy019S0c8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_tokenizer(train_ulasan, oov_token):\n",
        "    \n",
        "    ### START CODE HERE\n",
        "    \n",
        "    # Instantiate the Tokenizer class, passing in the correct values for num_words and oov_token\n",
        "    tokenizer = Tokenizer(num_words = len(train_ulasan), oov_token=\"<OOV>\")\n",
        "    \n",
        "    # Fit the tokenizer to the training sentences\n",
        "    tokenizer.fit_on_texts(train_ulasan)\n",
        "    \n",
        "    ### END CODE HERE\n",
        "    \n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "TfUQ0_lvS2_V"
      },
      "execution_count": 850,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function\n",
        "tokenizer = fit_tokenizer(train_ulasan, OOV_TOKEN)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "VOCAB_SIZE = len(word_index)\n",
        "\n",
        "print(f\"Vocabulary contains {VOCAB_SIZE} words\\n\")\n",
        "print(\"<OOV> token included in vocabulary\" if \"<OOV>\" in word_index else \"<OOV> token NOT included in vocabulary\")\n",
        "print(f\"\\nindex of word 'i' should be {word_index['i']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn5yX5MGS9K9",
        "outputId": "4c3f5d50-750c-4022-a996-67e11c5802c1"
      },
      "execution_count": 851,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary contains 1401 words\n",
            "\n",
            "<OOV> token included in vocabulary\n",
            "\n",
            "index of word 'i' should be 1114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seq_pad_and_trunc(ulasan, tokenizer, padding, truncating, maxlen):\n",
        "    \n",
        "    ### START CODE HERE\n",
        "       \n",
        "    # Convert sentences to sequences\n",
        "    ulasan = tokenizer.texts_to_sequences(ulasan)\n",
        "    \n",
        "    # Pad the sequences using the correct padding, truncating and maxlen\n",
        "    pad_trunc_sequences = pad_sequences(ulasan, padding='post', truncating='post', maxlen=maxlen)\n",
        "    \n",
        "    ### END CODE HERE\n",
        "    \n",
        "    return pad_trunc_sequences"
      ],
      "metadata": {
        "id": "JSW6e7gYTBnR"
      },
      "execution_count": 852,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function\n",
        "train_pad_trunc_seq = seq_pad_and_trunc(train_ulasan, tokenizer, PADDING, TRUNCATING, MAXLEN)\n",
        "val_pad_trunc_seq = seq_pad_and_trunc(validation_ulasan, tokenizer, PADDING, TRUNCATING, MAXLEN)\n",
        "\n",
        "print(f\"Padded and truncated training sequences have shape: {train_pad_trunc_seq.shape}\\n\")\n",
        "print(f\"Padded and truncated validation sequences have shape: {val_pad_trunc_seq.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kPytn8pTHDy",
        "outputId": "7c40f77d-d0cc-439b-92c6-070e07f3e0ef"
      },
      "execution_count": 853,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded and truncated training sequences have shape: (180, 16)\n",
            "\n",
            "Padded and truncated validation sequences have shape: (20, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_label = np.array(train_label)\n",
        "validation_label = np.array(validation_label)"
      ],
      "metadata": {
        "id": "m74DWa8ATOPE"
      },
      "execution_count": 854,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using pre-defined Embeddings**"
      ],
      "metadata": {
        "id": "Rx3IYQQBTmL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path to file containing the embeddings\n",
        "GLOVE_FILE = './data/glove.6B.100d.txt'\n",
        "\n",
        "# Initialize an empty embeddings index dictionary\n",
        "GLOVE_EMBEDDINGS = {}\n",
        "\n",
        "# Read file and fill GLOVE_EMBEDDINGS with its contents\n",
        "with open(GLOVE_FILE) as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        GLOVE_EMBEDDINGS[word] = coefs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "mHASsUWYToeA",
        "outputId": "f148a129-7713-465c-9dce-a4cd902bc56b"
      },
      "execution_count": 855,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-855-3567015ddf6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Read file and fill GLOVE_EMBEDDINGS with its contents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGLOVE_FILE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/glove.6B.100d.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rryNCDxFTZfg"
      }
    }
  ]
}