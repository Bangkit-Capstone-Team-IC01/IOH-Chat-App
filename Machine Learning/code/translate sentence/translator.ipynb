{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "translator amin.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHyTJejSeLb5",
        "outputId": "e0b697eb-2638-4c1a-b912-fbf974482358"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "56aTseK4q9ol"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import subprocess\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tz4aY7oDbyeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8c5f907-ebd5-41b9-c9fb-42ebcaff7a8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "git_dir = \"/content/IOH-Chat-App\"\n",
        "git_url = \"https://github.com/Bangkit-Capstone-Team/IOH-Chat-App.git\"\n",
        "\n",
        "if not os.path.exists(git_dir):\n",
        "  subprocess.call([\"git\", \"clone\", git_url])"
      ],
      "metadata": {
        "id": "2ZtMplOQv6Lz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslatorDataset:\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.filedir = \"/content/IOH-Chat-App/Machine Learning/datasets/translate sentence/result/eng-ind.csv\"\n",
        "    self.input_tokenizer = None\n",
        "    self.target_tokenizer = None\n",
        "    self._load_data_from_file()\n",
        "\n",
        "  def _load_data_from_file(self):\n",
        "    df = pd.read_csv(self.filedir)\n",
        "\n",
        "    self.input_lang = df.English.tolist()\n",
        "    self.target_lang = df.Indonesia.values.tolist()\n",
        "\n",
        "  def normalize_and_preprocess(self, text):\n",
        "    text = text.lower().strip()\n",
        "    text = text.replace(\"\\t\\n\", \"\")\n",
        "\n",
        "    return text\n",
        "\n",
        "  def _create_dataset(self):\n",
        "    self.input_lang = np.array(list(map(self.normalize_and_preprocess, self.input_lang)))\n",
        "    self.target_lang = np.array(list(map(self.normalize_and_preprocess, self.target_lang)))\n",
        "    \n",
        "    return self.input_lang, self.target_lang\n",
        "\n",
        "  def _tokenize(self, sentence, num_words, maxlen):\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "    tokenizer.fit_on_texts(sentence)\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(sentence)\n",
        "    sequences = pad_sequences(sequences, maxlen, padding=\"post\")\n",
        "\n",
        "    return sequences, tokenizer\n",
        "\n",
        "  def _load_dataset(self, num_words):\n",
        "    input_lang, target_lang = self._create_dataset()\n",
        "\n",
        "    self.maxlen = max([len(i)for i in input_lang])\n",
        "\n",
        "    input_sequences, input_tokenizer = self._tokenize(input_lang, num_words,  self.maxlen)\n",
        "    target_sequences, target_tokenizer = self._tokenize(target_lang, num_words,  self.maxlen)\n",
        "\n",
        "    return (input_sequences, input_tokenizer), (target_sequences, target_tokenizer)\n",
        "  \n",
        "  def call(self, num_words, batch_size, buffer_size):\n",
        "    input, target = self._load_dataset(num_words)\n",
        "\n",
        "    input_sequences, self.input_tokenizer = input\n",
        "    target_sequences, self.target_tokenizer = target\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((input_sequences, target_sequences))\n",
        "    dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "    return self.input_tokenizer, self.target_tokenizer, dataset"
      ],
      "metadata": {
        "id": "KA5VqxGKtrWx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buffer_size = 8000\n",
        "batch_size = 128\n",
        "num_words = 500\n",
        "\n",
        "translator_dataset = TranslatorDataset()\n",
        "input_tokenizer, target_tokenizer, dataset = translator_dataset.call(num_words, \n",
        "                                                                     batch_size, \n",
        "                                                                     buffer_size)\n",
        "\n",
        "input_batch, target_batch = next(iter(dataset))\n",
        "input_batch.shape, target_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW7fD1GdrExy",
        "outputId": "a96c60a2-f40a-4656-dfa7-54c31610febc"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([128, 163]), TensorShape([128, 163]))"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
        "input_maxlen = input_batch.shape[1]\n",
        "target_maxlen = target_batch.shape[1]\n",
        "\n",
        "input_maxlen, target_maxlen, input_vocab_size, target_vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI-TplUE22Tk",
        "outputId": "14c8d68b-f0f7-4419-e53c-745525e13662"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(163, 163, 4091, 4874)"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq:\n",
        "\n",
        "  def __init__(self, input_vocab_size, output_vocab_size, embedding_dim, units, batch_size, maxlen):\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.maxlen = maxlen\n",
        "    self.batch_size = batch_size\n",
        "    self.units = units\n",
        "    self.en_embedding = layers.Embedding(self.input_vocab_size, embedding_dim)\n",
        "    self.dec_embedding = layers.Embedding(self.input_vocab_size, embedding_dim)\n",
        "    self.en_lstm_layer = layers.LSTM(self.units,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True,\n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "    self.dec_lstm_layer = layers.LSTM(self.units,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True)\n",
        "\n",
        "  def _create_dense(self, input):\n",
        "    x = layers.Dense(512, activation=tf.nn.relu)(input)\n",
        "    x = layers.Dropout(.5)(x)\n",
        "    x = layers.Dense(1024, activation=tf.nn.relu)(x)\n",
        "    x = layers.Dropout(.5)(x)\n",
        "    outputs = layers.TimeDistributed(layers.Dense(self.output_vocab_size, activation=tf.nn.softmax))(x)\n",
        "    return outputs\n",
        "\n",
        "  def encoder(self, input):\n",
        "    embedding = self.en_embedding(input)\n",
        "    output, h, c = self.en_lstm_layer(embedding)\n",
        "\n",
        "    return output, h, c\n",
        "\n",
        "  def decoder(self, input, encoder_state):\n",
        "    embedding = self.dec_embedding(input)\n",
        "    outputs, _, _ = self.dec_lstm_layer(embedding, \n",
        "                                        initial_state=encoder_state)\n",
        "    outputs = self._create_dense(outputs)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "xuYpsBWmexe7"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dims = 256\n",
        "epochs = 10\n",
        "units = 512\n",
        "lr = 1e-4\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "       from_logits=True, reduction='none')"
      ],
      "metadata": {
        "id": "CeQhJSGasf4P"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq = Seq2Seq(input_vocab_size, \n",
        "                  target_vocab_size, \n",
        "                  embed_dims, \n",
        "                  units, \n",
        "                  batch_size, \n",
        "                  input_maxlen)"
      ],
      "metadata": {
        "id": "kvYCPy4UptZ6"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_outputs, en_h_state, en_c_state = seq2seq.encoder(input_batch)\n",
        "\n",
        "print(en_outputs.shape)\n",
        "print(en_h_state.shape)\n",
        "print(en_c_state.shape)"
      ],
      "metadata": {
        "id": "ciAQcC-GBjal",
        "outputId": "7a56ca85-426a-4f9a-eebc-7a5c52a25e10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 163, 512)\n",
            "(128, 512)\n",
            "(128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dec_outputs = seq2seq.decoder(target_batch, [en_h_state, en_c_state])\n",
        "\n",
        "print(dec_outputs.shape)"
      ],
      "metadata": {
        "id": "zo43VZr2C_ZQ",
        "outputId": "2f970dbd-063d-4f06-b3fe-308b1e01e676",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 163, 4874)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(seq2seq, batch_size, shape):\n",
        "  en_inputs = layers.Input(shape=(shape[1],))\n",
        "  \n",
        "  en_outputs, en_h_state, en_c_state = seq2seq.encoder(en_inputs)\n",
        "  dec_outputs = seq2seq.decoder(en_inputs, [en_h_state, en_c_state])\n",
        "\n",
        "  model = Model(en_inputs, dec_outputs)\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=optimizer,\n",
        "      loss=loss,\n",
        "      metrics=[\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "EMWZXYLLwiwP"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/IOH-Chat-App/Machine Learning/code/translate sentence/training_checkpoints/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        "    save_freq=10,\n",
        "    verbose=1, \n",
        ")\n",
        "model = build_model(\n",
        "    seq2seq, \n",
        "    batch_size, \n",
        "    input_batch.shape\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.save_weights(checkpoint_path.format(epoch=0))"
      ],
      "metadata": {
        "id": "2cqjvZ5Owjsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2580ffa9-69cd-48a3-99ba-d5203479025e"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, 163)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_35 (Embedding)       (None, 163, 256)     1047296     ['input_11[0][0]']               \n",
            "                                                                                                  \n",
            " embedding_36 (Embedding)       (None, 163, 256)     1047296     ['input_11[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_21 (LSTM)                 [(None, 163, 512),   1574912     ['embedding_35[0][0]']           \n",
            "                                 (None, 512),                                                     \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " lstm_22 (LSTM)                 [(None, 163, 512),   1574912     ['embedding_36[0][0]',           \n",
            "                                 (None, 512),                     'lstm_21[0][1]',                \n",
            "                                 (None, 512)]                     'lstm_21[0][2]']                \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 163, 512)     262656      ['lstm_22[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 163, 512)     0           ['dense_18[0][0]']               \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 163, 1024)    525312      ['dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 163, 1024)    0           ['dense_19[0][0]']               \n",
            "                                                                                                  \n",
            " time_distributed_5 (TimeDistri  (None, 163, 4874)   4995850     ['dropout_11[0][0]']             \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,028,234\n",
            "Trainable params: 11,028,234\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit(dataset,\n",
        "#           epochs=epochs,\n",
        "#           callbacks=[cp_callback],\n",
        "#           verbose=1)"
      ],
      "metadata": {
        "id": "HJygvxEGlUWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_path = \"/content/drive/MyDrive/saved_model/transelate/translate.h5\"\n",
        "saved_model_dir = os.path.dirname(saved_model_path)\n",
        "\n",
        "if os.path.exists(saved_model_dir):\n",
        "  shutil.rmtree(saved_model_dir)\n",
        "model.save(saved_model_path)"
      ],
      "metadata": {
        "id": "0QGxWYuiQPnv"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(TranslatorDataset):\n",
        "  def __init__(self):\n",
        "    self.saved_model_path = \"/content/drive/MyDrive/saved_model/transelate/translate.h5\"\n",
        "    self._load_seq2seq()\n",
        "\n",
        "  def _load_seq2seq(self):\n",
        "    model = tf.keras.models.load_model(self.saved_model_path)\n",
        "\n",
        "    enc_outputs, state_h_enc, state_c_enc = model.layers[3].output\n",
        "    self.enc_model = Model(model.input, [state_h_enc, state_c_enc])\n",
        "\n",
        "    dec_h_input = layers.Input(shape=(512,))\n",
        "    dec_c_input = layers.Input(shape=(512,))\n",
        "    dec_inputs = [dec_h_input, dec_c_input]\n",
        "\n",
        "    dec_lstm = model.layers[4]\n",
        "    dec_outputs, dec_h, dec_c = dec_lstm(model.input,\n",
        "                                        initial_state=dec_inputs)\n",
        "    \n",
        "    dec_states = [dec_h, dec_c]\n",
        "    x = model.layers[5](dec_outputs)\n",
        "    x = model.layers[6](x)\n",
        "    x = model.layers[7](x)\n",
        "    x = model.layers[8](x)\n",
        "    dense = model.layers[9](x)\n",
        "\n",
        "    self.dec_model = Model([model.input] + dec_inputs,\n",
        "                            [dense] + dec_states)\n",
        "\n",
        "  def translate(self, text):\n",
        "    words = list()\n",
        "\n",
        "    sequences = self.input_tokenizer.texts_to_sequences([text])\n",
        "    sequences = tf.convert_to_tensor(pad_sequences(sequences, \n",
        "                                                   self.maxlen, \n",
        "                                                   padding=\"post\"))\n",
        "    input = self.enc_model.predict(sequences)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "\n",
        "    for i in sequences:\n",
        "        output_chars, h, c = self.dec_model.predict([target_seq] + input)\n",
        "        char_index = np.argmax(output_chars)\n",
        "        text_char = self.target_tokenizer.index_word[char_index]\n",
        "        words.append(text_char)\n",
        "\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = char_index\n",
        "        states_value = [h, c]\n",
        "\n",
        "    sentence = \" \".join(words)\n",
        "    return sentence\n"
      ],
      "metadata": {
        "id": "1YmcvYUyzqLd"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator()\n",
        "translator.translate(\"Good bye!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "kPaH88FL3MYk",
        "outputId": "ef83003c-ec35-4827-e16d-ff80f67f303d"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-170-94bd821e4d90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Good bye!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-168-d290e9a0af60>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/saved_model/transelate/translate.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_seq2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_load_seq2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-168-d290e9a0af60>\u001b[0m in \u001b[0;36m_load_seq2seq\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdec_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     dec_outputs, dec_h, dec_c = dec_lstm(model.input,\n\u001b[0;32m---> 18\u001b[0;31m                                         initial_state=dec_inputs)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdec_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdec_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m       \u001b[0;31m# Perform the call with temporarily replaced input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m       \u001b[0;31m# Remove the additional_specs from input spec and keep the rest. It is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m       \u001b[0;31m# important to keep since the input spec was populated by build(), and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   4464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4465\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0minput_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflatted_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4466\u001b[0;31m     \u001b[0minput_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rank_at_least\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4468\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"lstm_22\" (type LSTM).\n\nShape (163, None) must have rank at least 3\n\nCall arguments received:\n  • inputs=['tf.Tensor(shape=(None, 163), dtype=float32)', 'tf.Tensor(shape=(None, 512), dtype=float32)', 'tf.Tensor(shape=(None, 512), dtype=float32)']\n  • mask=None\n  • training=False\n  • initial_state=None"
          ]
        }
      ]
    }
  ]
}