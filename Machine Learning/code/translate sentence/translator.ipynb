{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "translator amin.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "56aTseK4q9ol"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import subprocess\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tz4aY7oDbyeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f47219a-48e4-4ca4-e5a2-a1fdb02f9112"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "git_dir = \"/content/IOH-Chat-App\"\n",
        "git_url = \"https://github.com/Bangkit-Capstone-Team/IOH-Chat-App.git\"\n",
        "\n",
        "if not os.path.exists(git_dir):\n",
        "  subprocess.call([\"git\", \"clone\", git_url])"
      ],
      "metadata": {
        "id": "2ZtMplOQv6Lz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslatorDataset:\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.filedir = \"/content/IOH-Chat-App/Machine Learning/datasets/translate sentence/result/eng-ind.csv\"\n",
        "    self.input_tokenizer = None\n",
        "    self.target_tokenizer = None\n",
        "    self._load_data_from_file()\n",
        "\n",
        "  def _load_data_from_file(self):\n",
        "    df = pd.read_csv(self.filedir)\n",
        "\n",
        "    self.input_lang = df.English.tolist()\n",
        "    self.target_lang = df.Indonesia.values.tolist()\n",
        "\n",
        "  def normalize_and_preprocess(self, text):\n",
        "    text = text.lower().strip()\n",
        "    text = text.replace(\"\\t\\n\", \"\")\n",
        "\n",
        "    return text\n",
        "\n",
        "  def _create_dataset(self):\n",
        "    self.input_lang = np.array(list(map(self.normalize_and_preprocess, self.input_lang)))\n",
        "    self.target_lang = np.array(list(map(self.normalize_and_preprocess, self.target_lang)))\n",
        "    \n",
        "    return self.input_lang, self.target_lang\n",
        "\n",
        "  def _tokenize(self, sentence, num_words, maxlen):\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "    tokenizer.fit_on_texts(sentence)\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(sentence)\n",
        "    sequences = pad_sequences(sequences, maxlen, padding=\"post\")\n",
        "\n",
        "    return sequences, tokenizer\n",
        "\n",
        "  def _load_dataset(self, num_words):\n",
        "    input_lang, target_lang = self._create_dataset()\n",
        "\n",
        "    maxlen = max([len(i)for i in input_lang])\n",
        "\n",
        "    input_sequences, input_tokenizer = self._tokenize(input_lang, num_words, maxlen)\n",
        "    target_sequences, target_tokenizer = self._tokenize(target_lang, num_words, maxlen)\n",
        "\n",
        "    return (input_sequences, input_tokenizer), (target_sequences, target_tokenizer)\n",
        "  \n",
        "  def call(self, num_words, batch_size, buffer_size):\n",
        "    input, target = self._load_dataset(num_words)\n",
        "\n",
        "    input_sequences, self.input_tokenizer = input\n",
        "    target_sequences, self.target_tokenizer = target\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((input_sequences, target_sequences))\n",
        "    dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "    return self.input_tokenizer, self.target_tokenizer, dataset"
      ],
      "metadata": {
        "id": "KA5VqxGKtrWx"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buffer_size = 8000\n",
        "batch_size = 128\n",
        "num_words = 500\n",
        "\n",
        "translator_dataset = TranslatorDataset()\n",
        "input_tokenizer, target_tokenizer, dataset = translator_dataset.call(num_words, \n",
        "                                                                     batch_size, \n",
        "                                                                     buffer_size)\n",
        "\n",
        "input_batch, target_batch = next(iter(dataset))\n",
        "input_batch.shape, target_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW7fD1GdrExy",
        "outputId": "41ad6acb-33f2-47c0-ea45-eafe902dcfb5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([128, 163]), TensorShape([128, 163]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
        "input_maxlen = input_batch.shape[1]\n",
        "target_maxlen = target_batch.shape[1]\n",
        "\n",
        "input_maxlen, target_maxlen, input_vocab_size, target_vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI-TplUE22Tk",
        "outputId": "57f93f75-ebd2-4352-8686-b81e9ea0785d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(163, 163, 4091, 4874)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq():\n",
        "\n",
        "  def __init__(self, input_vocab_size, output_vocab_size, embedding_dim, units, batch_size, maxlen):\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.maxlen = maxlen\n",
        "    self.batch_size = batch_size\n",
        "    self.units = units\n",
        "    self.en_embedding = layers.Embedding(self.input_vocab_size, embedding_dim)\n",
        "    self.dec_embedding = layers.Embedding(self.input_vocab_size, embedding_dim)\n",
        "    self.en_lstm_layer = layers.LSTM(self.units,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True,\n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "    self.dec_lstm_layer = layers.LSTM(self.units,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True)\n",
        "\n",
        "  def _create_dense(self, input):\n",
        "    x = layers.Dense(512, activation=tf.nn.relu)(input)\n",
        "    x = layers.Dropout(.5)(x)\n",
        "    x = layers.Dense(1024, activation=tf.nn.relu)(x)\n",
        "    x = layers.Dropout(.5)(x)\n",
        "    outputs = layers.TimeDistributed(layers.Dense(self.output_vocab_size, activation=tf.nn.softmax))(x)\n",
        "    return outputs\n",
        "\n",
        "  def encoder(self, input):\n",
        "    embedding = self.en_embedding(input)\n",
        "    output, h, c = self.en_lstm_layer(embedding)\n",
        "\n",
        "    return output, h, c\n",
        "\n",
        "  def decoder(self, input, encoder_state):\n",
        "    embedding = self.dec_embedding(input)\n",
        "    outputs, _, _ = self.dec_lstm_layer(embedding, \n",
        "                                        initial_state=encoder_state)\n",
        "    outputs = self._create_dense(outputs)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "VixmOkyJ7s_B"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dims = 256\n",
        "epochs = 10\n",
        "units = 512\n",
        "lr = 1e-4\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "       from_logits=True, reduction='none')"
      ],
      "metadata": {
        "id": "CeQhJSGasf4P"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq = Seq2Seq(input_vocab_size, \n",
        "                  target_vocab_size, \n",
        "                  embed_dims, \n",
        "                  units, \n",
        "                  batch_size, \n",
        "                  input_maxlen)"
      ],
      "metadata": {
        "id": "24cbBI6f6J2R"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_outputs, en_h_state, en_c_state = seq2seq.encoder(input_batch)\n",
        "\n",
        "print(en_outputs.shape)\n",
        "print(en_h_state.shape)\n",
        "print(en_c_state.shape)"
      ],
      "metadata": {
        "id": "ciAQcC-GBjal",
        "outputId": "93fb6a8f-f757-4be0-810a-3f85991840dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 163, 512)\n",
            "(128, 512)\n",
            "(128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dec_outputs = seq2seq.decoder(target_batch, [en_h_state, en_c_state])\n",
        "\n",
        "print(dec_outputs.shape)"
      ],
      "metadata": {
        "id": "zo43VZr2C_ZQ",
        "outputId": "43df78c6-f100-438d-cb3d-ad621ce0ca3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 163, 4874)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(seq2seq, batch_size, shape):\n",
        "  en_inputs = layers.Input(shape=(shape[1],))\n",
        "  en_outputs, en_h_state, en_c_state = seq2seq.encoder(en_inputs)\n",
        "  dec_outputs = seq2seq.decoder(en_inputs, [en_h_state, en_c_state])\n",
        "\n",
        "  model = Model(en_inputs, dec_outputs)\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=optimizer,\n",
        "      loss=loss,\n",
        "      metrics=[\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "EMWZXYLLwiwP"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/IOH-Chat-App/Machine Learning/code/translate sentence/training_checkpoints/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        "    save_freq=10,\n",
        "    verbose=1, \n",
        ")\n",
        "model = build_model(\n",
        "    seq2seq, \n",
        "    batch_size, \n",
        "    input_batch.shape\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.save_weights(checkpoint_path.format(epoch=0))"
      ],
      "metadata": {
        "id": "2cqjvZ5Owjsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e610c3-fece-4982-f71e-1047b7c6107e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None, 163)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 163, 256)     1047296     ['input_12[0][0]']               \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 163, 256)     1047296     ['input_12[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 163, 512),   1574912     ['embedding_2[5][0]']            \n",
            "                                 (None, 512),                                                     \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, 163, 512),   1574912     ['embedding_3[5][0]',            \n",
            "                                 (None, 512),                     'lstm_2[5][1]',                 \n",
            "                                 (None, 512)]                     'lstm_2[5][2]']                 \n",
            "                                                                                                  \n",
            " dense_39 (Dense)               (None, 163, 512)     262656      ['lstm_3[5][0]']                 \n",
            "                                                                                                  \n",
            " dropout_26 (Dropout)           (None, 163, 512)     0           ['dense_39[0][0]']               \n",
            "                                                                                                  \n",
            " dense_40 (Dense)               (None, 163, 1024)    525312      ['dropout_26[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_27 (Dropout)           (None, 163, 1024)    0           ['dense_40[0][0]']               \n",
            "                                                                                                  \n",
            " time_distributed_13 (TimeDistr  (None, 163, 4874)   4995850     ['dropout_27[0][0]']             \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,028,234\n",
            "Trainable params: 11,028,234\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset,\n",
        "          epochs=epochs,\n",
        "          callbacks=[cp_callback],\n",
        "          verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJygvxEGlUWz",
        "outputId": "dfdc09b9-17f3-4db9-be15-6396fe456a74"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 9/68 [==>...........................] - ETA: 19s - loss: 7.8433 - accuracy: 0.8669WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "19/68 [=======>......................] - ETA: 15s - loss: 7.6719 - accuracy: 0.9234WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "29/68 [===========>..................] - ETA: 12s - loss: 7.6186 - accuracy: 0.9411WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "39/68 [================>.............] - ETA: 9s - loss: 7.5925 - accuracy: 0.9498WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "49/68 [====================>.........] - ETA: 5s - loss: 7.5772 - accuracy: 0.9549WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "59/68 [=========================>....] - ETA: 2s - loss: 7.5671 - accuracy: 0.9582WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "68/68 [==============================] - 24s 310ms/step - loss: 7.5604 - accuracy: 0.9605\n",
            "Epoch 2/10\n",
            " 1/68 [..............................] - ETA: 20s - loss: 7.5151 - accuracy: 0.9769WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "11/68 [===>..........................] - ETA: 17s - loss: 7.5164 - accuracy: 0.9757WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "21/68 [========>.....................] - ETA: 14s - loss: 7.5167 - accuracy: 0.9753WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "31/68 [============>.................] - ETA: 11s - loss: 7.5169 - accuracy: 0.9751WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "41/68 [=================>............] - ETA: 8s - loss: 7.5171 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "51/68 [=====================>........] - ETA: 5s - loss: 7.5172 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "61/68 [=========================>....] - ETA: 2s - loss: 7.5172 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "68/68 [==============================] - 21s 306ms/step - loss: 7.5172 - accuracy: 0.9748\n",
            "Epoch 3/10\n",
            " 3/68 [>.............................] - ETA: 19s - loss: 7.5154 - accuracy: 0.9766WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "13/68 [====>.........................] - ETA: 17s - loss: 7.5168 - accuracy: 0.9752WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "23/68 [=========>....................] - ETA: 14s - loss: 7.5171 - accuracy: 0.9750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "33/68 [=============>................] - ETA: 10s - loss: 7.5171 - accuracy: 0.9750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "43/68 [=================>............] - ETA: 7s - loss: 7.5171 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "53/68 [======================>.......] - ETA: 4s - loss: 7.5172 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "63/68 [==========================>...] - ETA: 1s - loss: 7.5172 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "68/68 [==============================] - 21s 313ms/step - loss: 7.5171 - accuracy: 0.9749\n",
            "Epoch 4/10\n",
            " 5/68 [=>............................] - ETA: 20s - loss: 7.5163 - accuracy: 0.9757WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "15/68 [=====>........................] - ETA: 16s - loss: 7.5168 - accuracy: 0.9752WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "25/68 [==========>...................] - ETA: 13s - loss: 7.5170 - accuracy: 0.9750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "35/68 [==============>...............] - ETA: 10s - loss: 7.5173 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "45/68 [==================>...........] - ETA: 7s - loss: 7.5172 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "55/68 [=======================>......] - ETA: 4s - loss: 7.5172 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "65/68 [===========================>..] - ETA: 0s - loss: 7.5172 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "68/68 [==============================] - 22s 320ms/step - loss: 7.5172 - accuracy: 0.9748\n",
            "Epoch 5/10\n",
            " 7/68 [==>...........................] - ETA: 19s - loss: 7.5155 - accuracy: 0.9765WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "17/68 [======>.......................] - ETA: 16s - loss: 7.5166 - accuracy: 0.9754WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "27/68 [==========>...................] - ETA: 13s - loss: 7.5167 - accuracy: 0.9753WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "37/68 [===============>..............] - ETA: 9s - loss: 7.5170 - accuracy: 0.9750 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "47/68 [===================>..........] - ETA: 6s - loss: 7.5171 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "57/68 [========================>.....] - ETA: 3s - loss: 7.5171 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "67/68 [============================>.] - ETA: 0s - loss: 7.5172 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "68/68 [==============================] - 22s 321ms/step - loss: 7.5172 - accuracy: 0.9749\n",
            "Epoch 6/10\n",
            " 9/68 [==>...........................] - ETA: 18s - loss: 7.5167 - accuracy: 0.9753WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "19/68 [=======>......................] - ETA: 15s - loss: 7.5171 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "29/68 [===========>..................] - ETA: 12s - loss: 7.5172 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "39/68 [================>.............] - ETA: 9s - loss: 7.5172 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "49/68 [====================>.........] - ETA: 5s - loss: 7.5172 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "59/68 [=========================>....] - ETA: 2s - loss: 7.5172 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "68/68 [==============================] - 22s 316ms/step - loss: 7.5172 - accuracy: 0.9749\n",
            "Epoch 7/10\n",
            " 1/68 [..............................] - ETA: 26s - loss: 7.5165 - accuracy: 0.9755WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "11/68 [===>..........................] - ETA: 18s - loss: 7.5166 - accuracy: 0.9754WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "21/68 [========>.....................] - ETA: 14s - loss: 7.5169 - accuracy: 0.9751WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "31/68 [============>.................] - ETA: 11s - loss: 7.5169 - accuracy: 0.9751WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "41/68 [=================>............] - ETA: 8s - loss: 7.5171 - accuracy: 0.9750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "51/68 [=====================>........] - ETA: 5s - loss: 7.5171 - accuracy: 0.9750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "61/68 [=========================>....] - ETA: 2s - loss: 7.5172 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "68/68 [==============================] - 22s 318ms/step - loss: 7.5172 - accuracy: 0.9749\n",
            "Epoch 8/10\n",
            " 3/68 [>.............................] - ETA: 20s - loss: 7.5147 - accuracy: 0.9774WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "13/68 [====>.........................] - ETA: 17s - loss: 7.5162 - accuracy: 0.9758WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "23/68 [=========>....................] - ETA: 14s - loss: 7.5165 - accuracy: 0.9755WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "33/68 [=============>................] - ETA: 11s - loss: 7.5169 - accuracy: 0.9751WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "43/68 [=================>............] - ETA: 7s - loss: 7.5170 - accuracy: 0.9750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "53/68 [======================>.......] - ETA: 4s - loss: 7.5171 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "63/68 [==========================>...] - ETA: 1s - loss: 7.5171 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "68/68 [==============================] - 22s 321ms/step - loss: 7.5171 - accuracy: 0.9749\n",
            "Epoch 9/10\n",
            " 5/68 [=>............................] - ETA: 20s - loss: 7.5158 - accuracy: 0.9762WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "15/68 [=====>........................] - ETA: 17s - loss: 7.5170 - accuracy: 0.9750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "25/68 [==========>...................] - ETA: 13s - loss: 7.5170 - accuracy: 0.9750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "35/68 [==============>...............] - ETA: 10s - loss: 7.5171 - accuracy: 0.9750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "45/68 [==================>...........] - ETA: 7s - loss: 7.5171 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "55/68 [=======================>......] - ETA: 4s - loss: 7.5172 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "65/68 [===========================>..] - ETA: 0s - loss: 7.5172 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "68/68 [==============================] - 22s 322ms/step - loss: 7.5172 - accuracy: 0.9748\n",
            "Epoch 10/10\n",
            " 7/68 [==>...........................] - ETA: 19s - loss: 7.5157 - accuracy: 0.9763WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "17/68 [======>.......................] - ETA: 16s - loss: 7.5169 - accuracy: 0.9752WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "27/68 [==========>...................] - ETA: 13s - loss: 7.5170 - accuracy: 0.9750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "37/68 [===============>..............] - ETA: 10s - loss: 7.5172 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "47/68 [===================>..........] - ETA: 6s - loss: 7.5170 - accuracy: 0.9750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "57/68 [========================>.....] - ETA: 3s - loss: 7.5171 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "67/68 [============================>.] - ETA: 0s - loss: 7.5172 - accuracy: 0.9749WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "68/68 [==============================] - 22s 326ms/step - loss: 7.5171 - accuracy: 0.9749\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fab7793ed10>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_path = \"/content/drive/MyDrive/saved_model/transelate/translate.h5\"\n",
        "saved_model_dir = os.path.dirname(saved_model_path)\n",
        "\n",
        "if os.path.exists(saved_model_dir):\n",
        "  shutil.rmtree(saved_model_dir)\n",
        "else:\n",
        "  model.save(saved_model_path)"
      ],
      "metadata": {
        "id": "0QGxWYuiQPnv"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(TranslatorDataset):\n",
        "  def __init__(self):\n",
        "    self.saved_model_path = \"/content/drive/MyDrive/saved_model/transelate/translate.h5\"\n",
        "    self._load_seq2seq()\n",
        "\n",
        "  def _load_seq2seq(self):\n",
        "    model = tf.keras.models.load_model(self.saved_model_path)\n",
        "\n",
        "    enc_outputs, state_h_enc, state_c_enc = model.layers[3].output\n",
        "    self.enc_model = Model(model.input[0], [state_h_enc, state_c_enc])\n",
        "\n",
        "    dec_h_input = layers.Input(shape=self.units)\n",
        "    dec_c_input = layers.Input(shape=self.units)\n",
        "    dec_inputs = [dec_h_input, dec_c_input]\n",
        "\n",
        "    dec_lstm = model.layers[4]\n",
        "    dec_outputs, dec_h, dec_c = dec_lstm(model.input[0],\n",
        "                                          initial_state=dec_inputs)\n",
        "    dec_states = [dec_h, dec_c]\n",
        "    x = model.layers[5](dec_outputs)\n",
        "    x = model.layers[6](x)\n",
        "    x = model.layers[7](x)\n",
        "    x = model.layers[8](x)\n",
        "    dense = model.layers[9](x)\n",
        "\n",
        "    self.dec_model = Model([model.input[0]] + dec_inputs,\n",
        "                            [dense] + dec_states)\n",
        "\n",
        "  def translate(self, text):\n",
        "    tokens = list()\n",
        "\n",
        "    sequences = self.input_tokenizer.texts_to_sequences([text])\n",
        "    sequences = tf.convert_to_tensor(pad_sequences(\n",
        "        sequences, self.maxlen, padding=\"post\"))\n",
        "    input = self.enc_model.predict(sequences)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "\n",
        "    for i in sequences:\n",
        "        output_chars, h, c = self.dec_model.predict([target_seq] + input)\n",
        "        char_index = np.argmax(output_chars)\n",
        "        text_char = self.target_tokenizer.index_word[char_index]\n",
        "        tokens.append(text_char)\n",
        "\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = char_index\n",
        "        states_value = [h, c]\n",
        "\n",
        "    sentence = \" \".join(tokens)\n",
        "    return sentence\n"
      ],
      "metadata": {
        "id": "1YmcvYUyzqLd"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator()\n",
        "translator.translate(\"Goodbye.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "kPaH88FL3MYk",
        "outputId": "b1c5eff8-f0df-46ba-f8f9-06926c84c14a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-bddea4c5a19a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Goodbye.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-765c28ba298e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/saved_model/transelate/translate.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_seq2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_load_seq2seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-765c28ba298e>\u001b[0m in \u001b[0;36m_load_seq2seq\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0menc_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_h_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate_h_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c_enc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdec_h_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m       if not all([functional_utils.is_input_keras_tensor(t)\n\u001b[1;32m    146\u001b[0m                   for t in tf.nest.flatten(inputs)]):\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional_utils.py\u001b[0m in \u001b[0;36mclone_graph_nodes\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcreate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \"\"\"\n\u001b[0;32m--> 146\u001b[0;31m   \u001b[0mnodes_to_clone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_nodes_by_inputs_and_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m   \u001b[0mcloned_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0mcloned_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional_utils.py\u001b[0m in \u001b[0;36mfind_nodes_by_inputs_and_outputs\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    114\u001b[0m                          \u001b[0;34m'output tensors. Please make sure the tensor {} is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                          \u001b[0;34m'included in the model inputs when building '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                          'functional model.'.format(kt))\n\u001b[0m\u001b[1;32m    117\u001b[0m       \u001b[0mnodes_to_visit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input tensor cannot be reached given provided output tensors. Please make sure the tensor KerasTensor(type_spec=TensorSpec(shape=(None, 163), dtype=tf.float32, name='input_11'), name='input_11', description=\"created by layer 'input_11'\") is included in the model inputs when building functional model."
          ]
        }
      ]
    }
  ]
}