{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHiaujHDIXrDD1NrNUgQNa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-uEPHMdd6at"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GIT_URL = \"https://github.com/Bangkit-Capstone-Team/IOH-Chat-App.git\"\n",
        "GIT_DIR = \"content/IOH-Chat-App\"\n",
        "\n",
        "if os.path.exists(GIT_DIR):\n",
        "  shutil.rmtree(GIT_DIR)\n",
        "\n",
        "subprocess.call([\"git\", \"clone\", GIT_URL])"
      ],
      "metadata": {
        "id": "fkJGx0F_fIof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(file_dir):\n",
        "  corpus = list()\n",
        "\n",
        "  with open(file_dir) as f:\n",
        "    for sentence in f.readlines():\n",
        "      corpus.append(sentence.replace(\"\\n\", \"\"))\n",
        "\n",
        "  return corpus"
      ],
      "metadata": {
        "id": "2M9DEtRMgGCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_DIR = \"/content/IOH-Chat-App/Machine Learning/datasets/text generation/sentence.txt\"\n",
        "\n",
        "ds = load_dataset(DATASET_DIR)"
      ],
      "metadata": {
        "id": "xPx2o0lmgh5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_WORDS = 1000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
        "tokenizer.fit_on_texts(ds)\n",
        "\n",
        "total_words = len(tokenizer.index_word) + 1\n",
        "\n",
        "print(f\"Data length: {total_words}\")\n",
        "print(f\"Example: {tokenizer.index_word}\")"
      ],
      "metadata": {
        "id": "xlsvHgT6hBY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def n_gram_sequences(sentence):\n",
        "  sequences = list()\n",
        "\n",
        "  for line in sentence:\n",
        "    tokens = tokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "    for i in range(1, len(tokens)):\n",
        "      n_gram = tokens[:i+1]\n",
        "      sequences.append(n_gram)\n",
        "      \n",
        "  return sequences"
      ],
      "metadata": {
        "id": "Uvfz7I4NhyEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = n_gram_sequences(ds)\n",
        "maxlen = max([len(i) for i in sequences])\n",
        "\n",
        "print(f\"Sequences length: {len(sequences)}\")\n",
        "print(f\"Max words length: {maxlen}\")"
      ],
      "metadata": {
        "id": "oIBIf8iDjF6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features_and_labels(sequences, n_classes):\n",
        "  features = sequences[:, :-1]\n",
        "  labels = sequences[:,-1]\n",
        "  one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=n_classes)\n",
        "\n",
        "  return features, one_hot_labels"
      ],
      "metadata": {
        "id": "7nMqqDVMjjrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(pad_sequences(sequences, maxlen=maxlen))\n",
        "features, labels = get_features_and_labels(sequences, total_words)\n",
        "\n",
        "print(f\"Features: {features[0:5]}\")"
      ],
      "metadata": {
        "id": "PVCX6izqkJVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(n_classes, embed_dims, maxlen):\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(layers.Embedding(n_classes, embed_dims, input_length=maxlen-1))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Bidirectional(layers.GRU(128, return_sequences=True)))\n",
        "  model.add(layers.Bidirectional(layers.GRU(256, return_sequences=True)))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.GlobalMaxPooling1D())\n",
        "  model.add(layers.Dense(1024, activation=tf.nn.relu))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Dense(n_classes, activation=tf.nn.softmax))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Y2v7LLTmkkb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 150\n",
        "LR = 1e-4\n",
        "EMBED_DIMS = 64\n",
        "\n",
        "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=LR)\n",
        "LOSS = tf.keras.losses.categorical_crossentropy\n",
        "\n",
        "CP_PATH = \"/content/IOH-Chat-App/Machine Learning/datasets/text generation/training_checkpoints/cp-{epoch:04d}.ckpt\"\n",
        "CP_DIR = os.path.dirname(CP_PATH)"
      ],
      "metadata": {
        "id": "rUpXUtCClZJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(CP_DIR):\n",
        "  os.makedirs()\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=CP_PATH, \n",
        "    save_weights_only=True,\n",
        "    save_freq=10,\n",
        "    save_best_only=True,\n",
        ")"
      ],
      "metadata": {
        "id": "eNzKGR28vjDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(total_words, EMBED_DIMS, maxlen)\n",
        "\n",
        "model.save_weights(CP_PATH.format(epoch=0))\n",
        "\n",
        "model.compile(\n",
        "    optimizer=OPTIMIZER,\n",
        "    loss=LOSS,\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    features, \n",
        "    labels, \n",
        "    epochs=EPOCHS, \n",
        "    callbacks=[cp_callback],\n",
        "    verbose=1\n",
        "    )"
      ],
      "metadata": {
        "id": "H5v72FYIr395"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}