{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diq8TM-70-aR"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets\n",
        "# !pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as pds\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import warnings\n",
        "import random\n",
        "import zipfile\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import tensorflow as tf\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "xoIdJCioHsOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Bangkit-Capstone-Team/IOH-Chat-App.git"
      ],
      "metadata": {
        "id": "ZsbpCP8w1qpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SPEECH_DATA_DIR = \"/content/IOH-Chat-App/Machine Learning/datasets/speech/audio.zip\"\n",
        "\n",
        "zf = zipfile.ZipFile(SPEECH_DATA_DIR)\n",
        "zf.extractall(\"/tmp\")\n",
        "zf.close()"
      ],
      "metadata": {
        "id": "XNb75eUX13GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/tmp/audio/\"\n",
        "JSON_PATH = \"/tmp/speech.json\""
      ],
      "metadata": {
        "id": "_cvR8rlt2TYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_sec_signal = 22050\n",
        "\n",
        "def prepare_dataset(dataset_path, json_path, **kwargs):\n",
        "  json_data = {\n",
        "      \"mapping\": list(),\n",
        "      \"features\": list(),\n",
        "      \"labels\": list(),\n",
        "  }\n",
        "\n",
        "  for i, (dirpath, _, files) in enumerate(os.walk(dataset_path)):\n",
        "    for audio in sorted(files):\n",
        "      i += 1\n",
        "      \n",
        "      filename = os.path.join(dirpath, audio)\n",
        "      string_label = re.findall(r\"^\\w*\",audio)[0]\n",
        "\n",
        "      if os.path.getsize(filename) != 0:\n",
        "        signal, sr = librosa.load(filename, sr=16000)\n",
        "\n",
        "        if len(signal) >= one_sec_signal:\n",
        "          signal = signal[:one_sec_signal]\n",
        "          mfcc = librosa.feature.mfcc(signal, **kwargs)\n",
        "        \n",
        "          json_data[\"mapping\"].append(string_label)\n",
        "          json_data[\"features\"].append(mfcc)\n",
        "          json_data[\"labels\"].append(i)\n",
        "          print(f\"{filename}: {string_label}\")\n",
        "\n",
        "  with open(json_path, \"w\") as fp:\n",
        "     json.dump(json_data, fp, indent=4)"
      ],
      "metadata": {
        "id": "WvlHtVWDHy-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_dataset(DATASET_PATH, JSON_PATH)"
      ],
      "metadata": {
        "id": "gvejV3ZoJ6cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json(json_data_path)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "hOad3d3eYPZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pds.Audio(train_dataset['audio_array'][random_idx], rate=train_dataset['sample_rate'])"
      ],
      "metadata": {
        "id": "9u8IQ5eZaJLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(n_class):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv1D(32, kernel_size=(3, 3), activation='relu', input_shape=(1,)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  model.add(layers.Conv1D(48, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  model.add(layers.Conv1D(120, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  model.add(layers.MaxPooling1D(2, 2))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Dense(n_class, activation='softmax'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "gVgpZjnyeenI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-4\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
        "\n",
        "model = create_model(len(train_dataset))\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "LPSo3xr0fRyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_dataset['audio_array']\n",
        "y_train = train_dataset['labels']\n",
        "\n",
        "x_test = test_dataset['audio_array']\n",
        "y_test = test_dataset['labels']\n",
        "\n",
        "epoch = 15\n",
        "\n",
        "model.fit(x_train, \n",
        "          y_train, \n",
        "          epochs=epoch, \n",
        "          validation_data=(x_train, y_train), \n",
        "          batch_size=128)"
      ],
      "metadata": {
        "id": "u5V7F7megJqE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "765233bfe060b87a8be23ec8f17030d468ac6435ae34b0ad14370b4cb734ac81"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "speech_to_text.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}