{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "diq8TM-70-aR"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets\n",
        "# !pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as pds\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import warnings\n",
        "import random\n",
        "import zipfile\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import tensorflow as tf\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "xoIdJCioHsOy"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Bangkit-Capstone-Team/IOH-Chat-App.git"
      ],
      "metadata": {
        "id": "ZsbpCP8w1qpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2786d2b1-221b-41c8-8e2e-b9f0f6c84f7d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'IOH-Chat-App' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SPEECH_DATA_DIR = \"/content/IOH-Chat-App/Machine Learning/datasets/speech/audio.zip\"\n",
        "\n",
        "zf = zipfile.ZipFile(SPEECH_DATA_DIR)\n",
        "zf.extractall(\"/tmp\")\n",
        "zf.close()"
      ],
      "metadata": {
        "id": "XNb75eUX13GO"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/tmp/audio/\"\n",
        "JSON_PATH = \"/tmp/speech.json\""
      ],
      "metadata": {
        "id": "_cvR8rlt2TYj"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_sec_signal = 22050\n",
        "\n",
        "def prepare_dataset(dataset_path, json_path, **kwargs):\n",
        "  json_data = {\n",
        "      \"mapping\": list(),\n",
        "      \"features\": list(),\n",
        "      \"labels\": list(),\n",
        "  }\n",
        "\n",
        "  for i, (dirpath, _, files) in enumerate(os.walk(dataset_path)):\n",
        "    for audio in sorted(files):\n",
        "      \n",
        "      filename = os.path.join(dirpath, audio)\n",
        "      string_label = re.findall(r\"^\\w*\",audio)[0]\n",
        "\n",
        "      if os.path.getsize(filename) != 0:\n",
        "        signal, sr = librosa.load(filename, sr=16000)\n",
        "\n",
        "        if len(signal) >= one_sec_signal:\n",
        "          signal = signal[:one_sec_signal]\n",
        "          mfcc = librosa.feature.mfcc(signal, **kwargs)\n",
        "        \n",
        "          json_data[\"mapping\"].append(string_label)\n",
        "          json_data[\"features\"].append(mfcc)\n",
        "          json_data[\"labels\"].append(i)\n",
        "\n",
        "          i += 1\n",
        "\n",
        "  return json_data"
      ],
      "metadata": {
        "id": "WvlHtVWDHy-j"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = prepare_dataset(DATASET_PATH, JSON_PATH, n_mfcc=13, n_fft=2048, hop_length=512)"
      ],
      "metadata": {
        "id": "gvejV3ZoJ6cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(dataset)\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "hOad3d3eYPZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = df.features.values\n",
        "labels = df.labels.values\n",
        "\n",
        "x_train, y_train, x_test, y_test = train_test_split(features, labels, test_size=0.2, random_state=1)\n",
        "\n",
        "x_train = np.expand_dims(x_train, axis=1)\n",
        "x_test = np.expand_dims(x_test, axis=1)\n",
        "\n",
        "input_shape = (x_train.shape[0], x_train.shape[1], 1)\n",
        "print(input_shape)"
      ],
      "metadata": {
        "id": "n775IRt9Vy9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(n_class, input_shape):\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "  model.add(layers.MaxPooling2D(2, 2))\n",
        "\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(2, 2))\n",
        "  \n",
        "  model.add(layers.Flatten())\n",
        "\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "\n",
        "  model.add(layers.Dense(n_class, activation='softmax'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "gVgpZjnyeenI"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 1e-4\n",
        "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=LR)\n",
        "LOSS = tf.keras.losses.sparse_categorical_crossentropy\n",
        "\n",
        "model = build_model(len(y_train), input_shape)\n",
        "\n",
        "model.compile(optimizer=OPTIMIZER,\n",
        "              loss=LOSS,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "LPSo3xr0fRyI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "a05f2a04-659e-453a-b973-c27d39740b71"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-3e5ba0b0f49d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mLOSS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m model.compile(optimizer=OPTIMIZER,\n",
            "\u001b[0;32m<ipython-input-134-815cf1c4c757>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(n_class, input_shape)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape,\n\u001b[0;32m----> 5\u001b[0;31m                                      kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m       raise ValueError(\n\u001b[0;32m--> 305\u001b[0;31m           \u001b[0;34mf'One of the dimensions in the output is <= 0 '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m           \u001b[0;34mf'due to downsampling in {self.name}. Consider '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m           \u001b[0;34mf'increasing the input size. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d_3. Consider increasing the input size. Received input shape [None, 411, 1, 1] which would produce output shape with a zero or negative value in a dimension."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15\n",
        "\n",
        "model.fit(x_train, \n",
        "          y_train, \n",
        "          epochs=EPOCHS, \n",
        "          validation_data=(x_test, y_test), \n",
        "          batch_size=128)"
      ],
      "metadata": {
        "id": "u5V7F7megJqE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "765233bfe060b87a8be23ec8f17030d468ac6435ae34b0ad14370b4cb734ac81"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "speech_to_text.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}