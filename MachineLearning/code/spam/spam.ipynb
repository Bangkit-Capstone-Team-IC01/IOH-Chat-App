{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgITdlB0wd5T"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihxwy88yw8Ja",
        "outputId": "db3ab3db-4b8a-4cac-874d-b007a419378b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_lower_and_split_punct(text):\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,]', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[.?!,]', r' \\0 ')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "eVfsIRhrPGhr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"sentences\")\n",
        "  preprocessor = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\", name=\"preprosesing\")(text_input)\n",
        "  encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\",trainable=False, name=\"embedding\")(preprocessor)\n",
        "  # pooled_output = outputs[\"pooled_output\"]# [batch_size, 768].\n",
        "  # sequence_output = outputs[\"sequence_output\"]# [batch_size, seq_length, 768].\n",
        "  x1 = tf.keras.layers.Dense(1024, activation=\"relu\")(encoder[\"pooled_output\"])\n",
        "  x2 = tf.keras.layers.Dropout(0.1)(x1)\n",
        "  x3 = tf.keras.layers.Dense(1, activation =\"sigmoid\", name=\"output_layer\")(x2)\n",
        "\n",
        "  model = tf.keras.Model(inputs=[text_input], outputs=[x3], name=\"Binary_Classification_Model\")\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=\"adam\",\n",
        "      loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "      metrics=[\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "with open(\"/content/drive/MyDrive/IOH/spam_or_not/data/emails.csv\") as f:\n",
        "  csvreader = csv.reader(f, delimiter=\",\")\n",
        "  next(csvreader)\n",
        "  masukan = []\n",
        "  keluaran = []\n",
        "  for a, i in enumerate(csvreader):\n",
        "      inp1 = tf_lower_and_split_punct(i[0]).numpy().decode()\n",
        "      inp2 = tf_lower_and_split_punct(i[2]).numpy().decode()\n",
        "      tar = int(i[1])\n",
        "      masukan.append(inp1)\n",
        "      masukan.append(inp2)\n",
        "      keluaran.append(int(tar))\n",
        "      keluaran.append(int(tar))\n",
        "\n",
        "BUFFER_SIZE = len(masukan)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((masukan, keluaran)).shuffle(BUFFER_SIZE)\n",
        "train = dataset.take(int(0.7*len(masukan)))\n",
        "remaining = dataset.skip(int(0.7*len(masukan)))\n",
        "validation = remaining.take(int(0.15*len(masukan)))\n",
        "test = remaining.skip(int(0.15*len(masukan)))\n",
        "\n",
        "train = train.batch(BATCH_SIZE)\n",
        "validation = validation.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "PLpQ7_LjyBxi"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for example_input_batch, example_target_batch in train.take(1):\n",
        "  print(example_input_batch[:5])\n",
        "  print()\n",
        "  print(example_target_batch[:5])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48jOlfwq0sH0",
        "outputId": "5c589a64-e767-437c-9d50-1e5731b68f9c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'pesan untuk peserta kursus lacima ,  julie ,  terima kasih .  juga ,  sebagai tindak lanjut apakah anda menerima cek dari paul quilkey ?  vince julie pada     pm harap tanggapi julie cc buku untuk peserta kursus lacima hanya ingin memberi tahu anda bahwa turunan energi  ?  buku harga dan manajemen risiko ,  oleh clewlow dan strickland dan disponsori oleh enron corp .   ,  ?  selesai .   ?  kami akan mulai pengiriman  januari ,  yang akan termasuk distribusi ?  salinan gratis anda .   ?  terima kasih atas kesabaran dan dukungan anda .   ?  hormat kami ,  julie ?  grup lacima ?   ?'\n",
            " b'meet during cmu visit  ?   aziz  ,   please  ,  contact me before or after the presentation and we can find  a time slot to chat later on friday  .   vince  al  v on           pm  vince  .  j  .  kaminski  enron  .  com  cc   meet during cmu visit  ?   dr  .  kaminski   i am a ph  .  d  .  student here at carnegie mellon who has a long  standing  interest in the energy industry  .   i have recently developed the framework of a simple model for electricity  prices that i would like your opinion on  .  could you please chalk out some  time for me during your cmu visit this friday  ?   unlike traditional electricty pricing models  ,  which assume that the  log  price is a sum of a couple of stochastic factors  ,  i assume that some  fundamentals of the electricity market are driven by stochastic factors  .   next  ,  given the current values of these factors  ,  price is determined by  economic forces of profit maximization by price setting electricity  generators  .  unlike typical factor models  ,  the factors in my model are  potentially observable  .   thank you  ,   aziz a  .  lookman  graduate school of industrial administration   forbes avenue  carnegie mellon university  pittsburgh  ,  pa   tel        fax         pls  .  mark the fax c  o jackie cavendish'\n",
            " b'viagra kapal cepat ,  phentermine ,  dll .   .   .  riym kami mengirim di seluruh dunia dalam waktu  jam !  tidak ada ruang tunggu ,  toko obat ,  atau percakapan yang memalukan .  apoteker berlisensi kami akan memesan anda dalam  atau  hari !  klik tautan ini untuk memulai hari ini !  viagra dan banyak obat resep lain yang tersedia ,  termasuk xenical dan phentermine ,  obat penurunan berat badan yang digunakan untuk membantu orang yang kelebihan berat badan menurunkan berat badan dan menjaga berat badan ini .  valtrex ,  perawatan untuk herpes .  propecia ,  pil pertama yang secara efektif memperlakukan kerontokan rambut pola pria .  zyban ,  zyban adalah nikotin pertama  pil gratis yang ,  sebagai bagian dari program komprehensif dari profesional perawatan kesehatan anda ,  dapat membantu anda berhenti merokok .  claritin ,  memberikan bantuan yang efektif dari gejala alergi musiman .  dan banyak lagi  .   .   .  cilck tautan ini untuk memulai hari ini !  untuk diekstraksi dari kontak di masa depan ,  kunjungi http   worldrxco .  com  hapus .  php flierguy    http   xent .  com  mailman  listinfo  fork'\n",
            " b'dear mr  .  kaminski  ,   since i am just about starting off on my research  ,  i do not have any papers  published in this area  .  but i do plan to address this shortcoming pretty  soon  .  i have a couple of other papers against my name  ,  but they are not  worth any serious mention  .   i thank you for taking time off your busy schedule to write to me  .  i will  keep you posted about my progress  .   thank you  ,   yours sincerely  ,   hari natarajan  fellowship student  indian institute of management bangalore  bannerghatta road  bangalore   india  tel        fax        e  mail  hnatraj  iimb  .  ernet  .  in       original message       vince  .  j  .  kaminski  enron  .  com  hnatraj  iimb  .  ernet  .  in  cc  shirley  .  crenshaw  enron  .  com  vince  .  j  .  kaminski  enron  .  com  sent          pm   hari  ,   thanks  .  please  ,  keep me posted about your progress  .   any published papers  ?   we shall send you the printout  .   vince  hari natrajan on           pm    vince  .  j  .  kaminski  enron  .  com    cc    dear mr  .  kaminski  ,   thank you very much for your prompt response  .  i look forward to  receiving a  copy of your article  .   i would also appreciate it if you could let me know whether enron  provides  research grants to individuals who are working in the area of energy  risk  management  .  towards my research  ,  i am trying to develop a model to  estimate  electricity spot price  .   in any case  ,  i will be getting in touch with you again a year or so down  the  line when i am nearing completion of my dissertation because enron is my  dream job  .   i look forward to hearing from you  .   thank you  ,   yours sincerely  ,   hari natarajan  fellowship student  indian institute of management bangalore  bannerghatta road  bangalore   india  tel        fax        e  mail  hnatraj  iimb  .  ernet  .  in       original message       vince  .  j  .  kaminski  enron  .  com  hnatraj  iimb  .  ernet  .  in  cc  shirley  .  crenshaw  enron  .  com  vince  .  j  .  kaminski  enron  .  com  sent          pm   hari  ,   i shall send you a reprint of the article  .  i had to  cancel my presentation at san antonio  .   vince  shirley  ,   please  ,  send a copy of the article to hari  .   hari natrajan on           am    vince  .  j  .  kaminski  enron  .  com    cc    dear mr  .  kaminski  ,   i am a doctoral student at the indian institute of management bangalore  ,   india  .  my area of interest is the energy sector  ,  especially electricity  derivatives  .  i am interested in obtaining a copy of the following items     your presentation  current challenges in modeling power price  volatility   at the session on price volatility  probabilistic methods in the energy  markets  .   http    www  .  informs  .  org  conf  sanantonio    talks  md   .  html     your chapter  the challenge of pricing and risk managing electricity  derivatives  in the book  the us power market   ,  risk publications  .   i would appreciate it if you could send me a soft  hard copy of the same  .   thank you  ,   yours sincerely  ,   hari natarajan  fellowship student  indian institute of management bangalore  bannerghatta road  bangalore   india  tel        fax        e  mail  hnatraj  iimb  .  ernet  .  in'\n",
            " b'restore your access  security  assistance  it has come to our attention that your account information needs to be  updated as part of our continuing commitment to protect your account and to  reduce the instance of fraud on our website  .  just update your personal records and you will not run into  any future problems with the online service  .   however  ,  failure to update your records until july  .    ,   your account considered as suspension  .   please update your records as soon as this email being sent  .   our system requires further account  verification  .   case id number  pp        once you have updated your account records  ,  your session will not be  interrupted and will continue as normal  .   as  soon as possible  .  allowing your account access to remain  limited for an extended period of  time may result in further limitations on  the use of your account and possible account  closure  .   click here to update your  account  you can  also confirm your identity by logging into your paypal account  at https    www  .  paypal  .  com  us   .   and you will be directed to the verifying page  .   thank you for using paypal  !   the paypal team  please do  not reply to this e  mail  .  mail sent to this address cannot be  answered unscribe  mailing  paypal  .  com  .  opt  in  ,  opt  out for assistance  ,   log  in  to your paypal account and choose the  help  link in the footer of  any page  .   to receive email notifications in plain text  instead of html  ,  update  your preferences here  .   paypal email id pp'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor([0 0 1 0 1], shape=(5,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "ckpt_path = \"/content/drive/MyDrive/IOH/spam_or_not/checkpoint/model.{epoch:02d}-{val_loss:.4f}.h5\"\n",
        "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=ckpt_path, \n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        "    verbose=1, \n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMJ7MdZw1c0a",
        "outputId": "66e694d2-a3b4-4a8f-b4be-e20919de0937"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Binary_Classification_Model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " sentences (InputLayer)         [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " preprosesing (KerasLayer)      {'input_type_ids':   0           ['sentences[0][0]']              \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " embedding (KerasLayer)         {'default': (None,   109482241   ['preprosesing[0][0]',           \n",
            "                                768),                             'preprosesing[0][1]',           \n",
            "                                 'sequence_output':               'preprosesing[0][2]']           \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768)}                                                       \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 1024)         787456      ['embedding[0][13]']             \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 1024)         0           ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            " output_layer (Dense)           (None, 1)            1025        ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 110,270,722\n",
            "Trainable params: 788,481\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train, validation_data=validation, epochs=15, callbacks=[ckpt])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4WHN7Wi1eFz",
        "outputId": "1a54edf4-e869-4bb8-d7f2-0212a1cfaa43"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.5428 - accuracy: 0.7568\n",
            "Epoch 1: val_loss improved from inf to 0.49062, saving model to /content/drive/MyDrive/IOH/spam_or_not/checkpoint/model.01-0.4906.h5\n",
            "126/126 [==============================] - 126s 932ms/step - loss: 0.5428 - accuracy: 0.7568 - val_loss: 0.4906 - val_accuracy: 0.7905\n",
            "Epoch 2/15\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3668 - accuracy: 0.8370\n",
            "Epoch 2: val_loss improved from 0.49062 to 0.34736, saving model to /content/drive/MyDrive/IOH/spam_or_not/checkpoint/model.02-0.3474.h5\n",
            "126/126 [==============================] - 115s 917ms/step - loss: 0.3668 - accuracy: 0.8370 - val_loss: 0.3474 - val_accuracy: 0.8318\n",
            "Epoch 3/15\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.8504\n",
            "Epoch 3: val_loss improved from 0.34736 to 0.31211, saving model to /content/drive/MyDrive/IOH/spam_or_not/checkpoint/model.03-0.3121.h5\n",
            "126/126 [==============================] - 116s 920ms/step - loss: 0.3345 - accuracy: 0.8504 - val_loss: 0.3121 - val_accuracy: 0.8673\n",
            "Epoch 4/15\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2991 - accuracy: 0.8646\n",
            "Epoch 4: val_loss improved from 0.31211 to 0.29926, saving model to /content/drive/MyDrive/IOH/spam_or_not/checkpoint/model.04-0.2993.h5\n",
            "126/126 [==============================] - 116s 918ms/step - loss: 0.2991 - accuracy: 0.8646 - val_loss: 0.2993 - val_accuracy: 0.8644\n",
            "Epoch 5/15\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2800 - accuracy: 0.8758\n",
            "Epoch 5: val_loss improved from 0.29926 to 0.23826, saving model to /content/drive/MyDrive/IOH/spam_or_not/checkpoint/model.05-0.2383.h5\n",
            "126/126 [==============================] - 116s 918ms/step - loss: 0.2800 - accuracy: 0.8758 - val_loss: 0.2383 - val_accuracy: 0.8987\n",
            "Epoch 6/15\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2988 - accuracy: 0.8662\n",
            "Epoch 6: val_loss did not improve from 0.23826\n",
            "126/126 [==============================] - 114s 905ms/step - loss: 0.2988 - accuracy: 0.8662 - val_loss: 0.2812 - val_accuracy: 0.8638\n",
            "Epoch 7/15\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2607 - accuracy: 0.8863\n",
            "Epoch 7: val_loss did not improve from 0.23826\n",
            "126/126 [==============================] - 114s 905ms/step - loss: 0.2607 - accuracy: 0.8863 - val_loss: 0.2619 - val_accuracy: 0.8958\n",
            "Epoch 8/15\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2626 - accuracy: 0.8859\n",
            "Epoch 8: val_loss did not improve from 0.23826\n",
            "126/126 [==============================] - 113s 899ms/step - loss: 0.2626 - accuracy: 0.8859 - val_loss: 0.2456 - val_accuracy: 0.9010\n",
            "Epoch 9/15\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2673 - accuracy: 0.8843\n",
            "Epoch 9: val_loss did not improve from 0.23826\n",
            "126/126 [==============================] - 113s 898ms/step - loss: 0.2673 - accuracy: 0.8843 - val_loss: 0.4545 - val_accuracy: 0.8137\n",
            "Epoch 10/15\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2467 - accuracy: 0.8936\n",
            "Epoch 10: val_loss did not improve from 0.23826\n",
            "126/126 [==============================] - 114s 903ms/step - loss: 0.2467 - accuracy: 0.8936 - val_loss: 0.3313 - val_accuracy: 0.8527\n",
            "Epoch 11/15\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2558 - accuracy: 0.8848\n",
            "Epoch 11: val_loss did not improve from 0.23826\n",
            "126/126 [==============================] - 120s 951ms/step - loss: 0.2558 - accuracy: 0.8848 - val_loss: 0.4020 - val_accuracy: 0.8335\n",
            "Epoch 12/15\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2318 - accuracy: 0.9034\n",
            "Epoch 12: val_loss improved from 0.23826 to 0.20098, saving model to /content/drive/MyDrive/IOH/spam_or_not/checkpoint/model.12-0.2010.h5\n",
            "126/126 [==============================] - 117s 932ms/step - loss: 0.2318 - accuracy: 0.9034 - val_loss: 0.2010 - val_accuracy: 0.9185\n",
            "Epoch 13/15\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.8994\n",
            "Epoch 13: val_loss did not improve from 0.20098\n",
            "126/126 [==============================] - 128s 1s/step - loss: 0.2333 - accuracy: 0.8994 - val_loss: 0.2876 - val_accuracy: 0.8696\n",
            "Epoch 14/15\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2376 - accuracy: 0.8961\n",
            "Epoch 14: val_loss did not improve from 0.20098\n",
            "126/126 [==============================] - 118s 940ms/step - loss: 0.2376 - accuracy: 0.8961 - val_loss: 0.3343 - val_accuracy: 0.8434\n",
            "Epoch 15/15\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2382 - accuracy: 0.8976\n",
            "Epoch 15: val_loss did not improve from 0.20098\n",
            "126/126 [==============================] - 115s 913ms/step - loss: 0.2382 - accuracy: 0.8976 - val_loss: 0.2103 - val_accuracy: 0.9203\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0be7f0b410>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teks_spam = \"DISNAKERJA and others share their thoughts on LinkedIn\"\n",
        "model.predict([teks_spam])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eLNr8y3XwMk",
        "outputId": "9d2e83c9-d7f8-4a93-ba35-1693aebd759f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 791ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.53002256]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teks = [\n",
        "        \"Bangkit Academy led by Google, Tokopedia, Gojek, & Traveloka and others share their thoughts on LinkedIn\",\n",
        "        \"Kanao, welcome to Samsung\",\n",
        "        \"[educba.com] Angular JS Certification Training Course (9 Courses, 5+ Projects)\",\n",
        "        \"PTEB UTS 07111940000001\",\n",
        "        \"Lomba Desain IG : itsmeeeaow\",\n",
        "        \"Photo from Vanny Ezha\",\n",
        "        \"SPCS1_tugas03_07111940000001\",\n",
        "        \"Pendaftaran Akun Kampus Merdeka\",\n",
        "]\n",
        "model.predict(teks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ull7aB2Ibh36",
        "outputId": "1f9b80c2-6336-48e5-baf8-477e86a70779"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9920954 ],\n",
              "       [0.12292992],\n",
              "       [0.24726641],\n",
              "       [0.28932017],\n",
              "       [0.53702146],\n",
              "       [0.34751543],\n",
              "       [0.51677513],\n",
              "       [0.09848826]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "benar = []\n",
        "for tes,lab in test.take(100):\n",
        "  # print(tes.numpy().decode())\n",
        "  if sum(model.predict([tes.numpy().decode()])) >= 0.5 and lab.numpy() == 1:\n",
        "    benar.append(1)\n",
        "  elif sum(model.predict([tes.numpy().decode()])) <= 0.5 and lab.numpy() == 1:\n",
        "    pass\n",
        "  elif sum(model.predict([tes.numpy().decode()])) >= 0.5 and lab.numpy() == 0:\n",
        "    # print(False)\n",
        "    pass\n",
        "  elif sum(model.predict([tes.numpy().decode()])) <= 0.5 and lab.numpy() == 0:\n",
        "    # print(True)\n",
        "    benar.append(1)\n",
        "\n",
        "sum(benar)\n",
        "  # print(model.predict([tes.numpy().decode()]))\n",
        "  # print(lab.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jcp4XTtQ8HQu",
        "outputId": "9acc8410-af86-4aa5-b94b-f689e036413b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/IOH/spam_or_not/saved_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQl1FDc39D_p",
        "outputId": "af8bc198-5259-4b55-edee-dae46d9e61fb"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 366). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/IOH/spam_or_not/saved_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/IOH/spam_or_not/saved_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/content/drive/MyDrive/IOH/spam_or_not/pickle/model_spam.pkl\",\"wb\") as f:\n",
        "  pickle.dump(model, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N7Sei05a5lr",
        "outputId": "dd7ff71c-bf20-4111-b120-e399e35b6b48"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 366). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://ad024f4a-4277-4b0c-a278-6688a21e7241/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://ad024f4a-4277-4b0c-a278-6688a21e7241/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keterangan : lebih dari 0.5 berpotensi spam, kurang dari tersebut tidak berpotensi spam"
      ],
      "metadata": {
        "id": "Py-ILMEIc5J9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/IOH/spam_or_not/saved_model/\")"
      ],
      "metadata": {
        "id": "5PDfBMV1c3ey"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teks = [\n",
        "        \"Bangkit Academy led by Google, Tokopedia, Gojek, & Traveloka and others share their thoughts on LinkedIn\",\n",
        "        \"Kanao, welcome to Samsung\",\n",
        "        \"[educba.com] Angular JS Certification Training Course (9 Courses, 5+ Projects)\",\n",
        "        \"PTEB UTS 07111940000001\",\n",
        "        \"Lomba Desain IG : itsmeeeaow\",\n",
        "        \"Photo from Vanny Ezha\",\n",
        "        \"SPCS1_tugas03_07111940000001\",\n",
        "        \"Pendaftaran Akun Kampus Merdeka\",\n",
        "]\n",
        "\n",
        "model(tf.constant(teks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmSj6u0ydVHr",
        "outputId": "d1909fce-64ad-4a79-96cb-a1cf716d27b3"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
              "array([[0.9920954 ],\n",
              "       [0.12292992],\n",
              "       [0.24726641],\n",
              "       [0.28932017],\n",
              "       [0.53702146],\n",
              "       [0.34751543],\n",
              "       [0.51677513],\n",
              "       [0.09848826]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    }
  ]
}