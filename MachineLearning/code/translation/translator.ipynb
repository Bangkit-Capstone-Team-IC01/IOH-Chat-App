{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "56aTseK4q9ol"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import subprocess\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import json\n",
        "import zipfile\n",
        "import re\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive, files #if use colab\n",
        "from tensorflow.nn import relu, tanh, softmax\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tz4aY7oDbyeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37db6e7e-c090-45e8-d25b-e757287ecba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# if use colab\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2ZtMplOQv6Lz"
      },
      "outputs": [],
      "source": [
        "#if use colab\n",
        "git_dir = \"/content/IOH-Chat-App\"\n",
        "git_url = \"https://github.com/bangkit-team/IOH-chat-app.git\"\n",
        "\n",
        "if not os.path.exists(git_dir):\n",
        "  subprocess.call([\"git\", \"clone\", git_url])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pN2M4PirLEQB"
      },
      "outputs": [],
      "source": [
        "filedir1 = \"/content/IOH-chat-app/MachineLearning/datasets/translation/result/eng-ind.csv\" # #if use colab\n",
        "filedir2 = \"/content/IOH-chat-app/MachineLearning/datasets/spam/emails.csv\" # #if use colab\n",
        "# filedir1 = \"../../datasets/translate sentence/result/eng-ind.csv\" #if use local env\n",
        "# filedir2 = \"../../datasets/spam/emails.csv\" #if use local env"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv(filedir1)\n",
        "df1"
      ],
      "metadata": {
        "id": "CTSHYGqdTyPk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "3142e7f0-d60a-45bf-adae-f208b6783828"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                English  \\\n",
              "0                                                  Run!   \n",
              "1                                                  Who?   \n",
              "2                                                  Wow!   \n",
              "3                                                 Help!   \n",
              "4                                                 Jump!   \n",
              "...                                                 ...   \n",
              "8814  Every student who has graduated from our unive...   \n",
              "8815  If you don't want to put on sunscreen, that's ...   \n",
              "8816  When she was finished ironing, Mary switched o...   \n",
              "8817  Irene Pepperberg, a researcher at Northwestern...   \n",
              "8818  If a person has not had a chance to acquire hi...   \n",
              "\n",
              "                                              Indonesia  \n",
              "0                                                 Lari!  \n",
              "1                                                Siapa?  \n",
              "2                                                  Wow!  \n",
              "3                                               Tolong!  \n",
              "4                                               Lompat!  \n",
              "...                                                 ...  \n",
              "8814  Semua mahasiswa yang telah menyelesaikan studi...  \n",
              "8815  Kalau kamu tidak mau pakai tabir surya, ya, te...  \n",
              "8816  Ketika dia sudah selesai menyetrika, Mary mema...  \n",
              "8817  Irene Pepperberg, seorang peneliti di Universi...  \n",
              "8818  Jika seseorang tidak berkesempatan untuk mengu...  \n",
              "\n",
              "[8819 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0782980c-9371-4e1c-a9da-39ec10eeb582\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Indonesia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Lari!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Siapa?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Wow!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Help!</td>\n",
              "      <td>Tolong!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jump!</td>\n",
              "      <td>Lompat!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8814</th>\n",
              "      <td>Every student who has graduated from our unive...</td>\n",
              "      <td>Semua mahasiswa yang telah menyelesaikan studi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8815</th>\n",
              "      <td>If you don't want to put on sunscreen, that's ...</td>\n",
              "      <td>Kalau kamu tidak mau pakai tabir surya, ya, te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8816</th>\n",
              "      <td>When she was finished ironing, Mary switched o...</td>\n",
              "      <td>Ketika dia sudah selesai menyetrika, Mary mema...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8817</th>\n",
              "      <td>Irene Pepperberg, a researcher at Northwestern...</td>\n",
              "      <td>Irene Pepperberg, seorang peneliti di Universi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8818</th>\n",
              "      <td>If a person has not had a chance to acquire hi...</td>\n",
              "      <td>Jika seseorang tidak berkesempatan untuk mengu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8819 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0782980c-9371-4e1c-a9da-39ec10eeb582')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0782980c-9371-4e1c-a9da-39ec10eeb582 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0782980c-9371-4e1c-a9da-39ec10eeb582');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(filedir2)\n",
        "df2 = df2.rename(columns={\"text\": \"English\", \"teks\": \"Indonesia\"})\n",
        "df2 = df2.drop(\"spam\", axis=1)\n",
        "df2"
      ],
      "metadata": {
        "id": "-eQatoc7bG2r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c337a029-839b-4c12-e94b-29416c8d2794"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                English  \\\n",
              "0     naturally irresistible your corporate identity...   \n",
              "1     the stock trading gunslinger  fanny is merrill...   \n",
              "2     unbelievable new homes made easy  im wanting t...   \n",
              "3     4 color printing special  request additional i...   \n",
              "4     do not have money , get software cds from here...   \n",
              "...                                                 ...   \n",
              "5723  research and development charges to gpg  here ...   \n",
              "5724  receipts from visit  jim ,  thanks again for t...   \n",
              "5725  enron case study update  wow ! all on the same...   \n",
              "5726  interest  david ,  please , call shirley crens...   \n",
              "5727  news : aurora 5 . 2 update  aurora version 5 ....   \n",
              "\n",
              "                                              Indonesia  \n",
              "0     Secara alami tak tertahankan identitas perusah...  \n",
              "1     Fanny Gunslinger Perdagangan Saham adalah Merr...  \n",
              "2     Rumah Baru yang Luar Biasa Menjadi Mudah Saya ...  \n",
              "3     4 PERMINTAAN PERMINTAAN KHUSUS INFORMASI KHUSU...  \n",
              "4     Jangan punya uang, dapatkan CD perangkat lunak...  \n",
              "...                                                 ...  \n",
              "5723  Biaya penelitian dan pengembangan ke GPG di si...  \n",
              "5724  Tanda terima dari kunjungan Jim, terima kasih ...  \n",
              "5725  Pembaruan Studi Kasus Enron Wow! Semua pada ha...  \n",
              "5726  Bunga David, tolong, hubungi Shirley Crenshaw ...  \n",
              "5727  Berita: Aurora 5. 2 Perbarui Aurora Versi 5. 2...  \n",
              "\n",
              "[5728 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acba82ac-b7e3-4cc4-a777-d5d409114734\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Indonesia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>naturally irresistible your corporate identity...</td>\n",
              "      <td>Secara alami tak tertahankan identitas perusah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the stock trading gunslinger  fanny is merrill...</td>\n",
              "      <td>Fanny Gunslinger Perdagangan Saham adalah Merr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>unbelievable new homes made easy  im wanting t...</td>\n",
              "      <td>Rumah Baru yang Luar Biasa Menjadi Mudah Saya ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4 color printing special  request additional i...</td>\n",
              "      <td>4 PERMINTAAN PERMINTAAN KHUSUS INFORMASI KHUSU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>do not have money , get software cds from here...</td>\n",
              "      <td>Jangan punya uang, dapatkan CD perangkat lunak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5723</th>\n",
              "      <td>research and development charges to gpg  here ...</td>\n",
              "      <td>Biaya penelitian dan pengembangan ke GPG di si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5724</th>\n",
              "      <td>receipts from visit  jim ,  thanks again for t...</td>\n",
              "      <td>Tanda terima dari kunjungan Jim, terima kasih ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5725</th>\n",
              "      <td>enron case study update  wow ! all on the same...</td>\n",
              "      <td>Pembaruan Studi Kasus Enron Wow! Semua pada ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5726</th>\n",
              "      <td>interest  david ,  please , call shirley crens...</td>\n",
              "      <td>Bunga David, tolong, hubungi Shirley Crenshaw ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5727</th>\n",
              "      <td>news : aurora 5 . 2 update  aurora version 5 ....</td>\n",
              "      <td>Berita: Aurora 5. 2 Perbarui Aurora Versi 5. 2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5728 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acba82ac-b7e3-4cc4-a777-d5d409114734')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acba82ac-b7e3-4cc4-a777-d5d409114734 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acba82ac-b7e3-4cc4-a777-d5d409114734');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2_len = len(df2)\n",
        "df = pd.concat([df1, df2])\n",
        "df"
      ],
      "metadata": {
        "id": "VLgct1pkbhn4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c8ee7c16-24f0-4ceb-8947-df26c6e475b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                English  \\\n",
              "0                                                  Run!   \n",
              "1                                                  Who?   \n",
              "2                                                  Wow!   \n",
              "3                                                 Help!   \n",
              "4                                                 Jump!   \n",
              "...                                                 ...   \n",
              "5723  research and development charges to gpg  here ...   \n",
              "5724  receipts from visit  jim ,  thanks again for t...   \n",
              "5725  enron case study update  wow ! all on the same...   \n",
              "5726  interest  david ,  please , call shirley crens...   \n",
              "5727  news : aurora 5 . 2 update  aurora version 5 ....   \n",
              "\n",
              "                                              Indonesia  \n",
              "0                                                 Lari!  \n",
              "1                                                Siapa?  \n",
              "2                                                  Wow!  \n",
              "3                                               Tolong!  \n",
              "4                                               Lompat!  \n",
              "...                                                 ...  \n",
              "5723  Biaya penelitian dan pengembangan ke GPG di si...  \n",
              "5724  Tanda terima dari kunjungan Jim, terima kasih ...  \n",
              "5725  Pembaruan Studi Kasus Enron Wow! Semua pada ha...  \n",
              "5726  Bunga David, tolong, hubungi Shirley Crenshaw ...  \n",
              "5727  Berita: Aurora 5. 2 Perbarui Aurora Versi 5. 2...  \n",
              "\n",
              "[14547 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f7d6924-0dc1-4cbd-8bd8-712e0fb6a229\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Indonesia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Lari!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Siapa?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Wow!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Help!</td>\n",
              "      <td>Tolong!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jump!</td>\n",
              "      <td>Lompat!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5723</th>\n",
              "      <td>research and development charges to gpg  here ...</td>\n",
              "      <td>Biaya penelitian dan pengembangan ke GPG di si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5724</th>\n",
              "      <td>receipts from visit  jim ,  thanks again for t...</td>\n",
              "      <td>Tanda terima dari kunjungan Jim, terima kasih ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5725</th>\n",
              "      <td>enron case study update  wow ! all on the same...</td>\n",
              "      <td>Pembaruan Studi Kasus Enron Wow! Semua pada ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5726</th>\n",
              "      <td>interest  david ,  please , call shirley crens...</td>\n",
              "      <td>Bunga David, tolong, hubungi Shirley Crenshaw ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5727</th>\n",
              "      <td>news : aurora 5 . 2 update  aurora version 5 ....</td>\n",
              "      <td>Berita: Aurora 5. 2 Perbarui Aurora Versi 5. 2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14547 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f7d6924-0dc1-4cbd-8bd8-712e0fb6a229')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f7d6924-0dc1-4cbd-8bd8-712e0fb6a229 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f7d6924-0dc1-4cbd-8bd8-712e0fb6a229');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RgUUgmronChh"
      },
      "outputs": [],
      "source": [
        "start_mark = '<start>'\n",
        "end_mark = '<end>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KA5VqxGKtrWx"
      },
      "outputs": [],
      "source": [
        "class TranslatorDataset:\n",
        "  def __init__(self, dataframe):\n",
        "    self.dataframe = dataframe\n",
        "    self.input_tokenizer = None\n",
        "    self.target_tokenizer = None\n",
        "    self._load_data_from_file()\n",
        "\n",
        "  def _load_data_from_file(self):\n",
        "    df = self.dataframe\n",
        "\n",
        "    input_lang = df.English.values\n",
        "    target_lang = df.Indonesia.values\n",
        "\n",
        "    return input_lang, target_lang\n",
        "\n",
        "  def _normalize_and_preprocess(self, text, use_mark=False):\n",
        "    if use_mark:\n",
        "      text = text.lower().strip()\n",
        "      text = \" \".join([start_mark, text, end_mark])\n",
        "    else:\n",
        "      text = text.lower().strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "  def _tokenize(self, sentences, num_words, maxlen):\n",
        "    punctuation = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=num_words, filters=punctuation, lower=False)\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "    sequences = pad_sequences(\n",
        "      sequences, maxlen=maxlen, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "    return sequences, tokenizer\n",
        "\n",
        "  def _create_dataset(self):\n",
        "    input_lang, target_lang = self._load_data_from_file()\n",
        "\n",
        "    input_sentence = np.array(\n",
        "        list(map(lambda x: self._normalize_and_preprocess(x, False), input_lang)))\n",
        "    \n",
        "    target_sentence = np.array(\n",
        "        list(map(lambda y: self._normalize_and_preprocess(y, True), target_lang)))\n",
        "    \n",
        "    return input_sentence, target_sentence\n",
        "\n",
        "  def _load_dataset(self, num_words):\n",
        "    input_lang, target_lang = self._create_dataset()\n",
        "\n",
        "    self.maxlen = max([len(i)for i in input_lang]) // 1000\n",
        "    self.buffer_size = len(input_lang)\n",
        "\n",
        "    input_sequences, input_tokenizer = self._tokenize(\n",
        "        input_lang, num_words, self.maxlen)\n",
        "    \n",
        "    target_sequences, target_tokenizer = self._tokenize(\n",
        "        target_lang, num_words, self.maxlen,)\n",
        "\n",
        "    return (input_sequences, input_tokenizer), (target_sequences, target_tokenizer)\n",
        "  \n",
        "  def get(self, num_words, batch_size):\n",
        "    input, target = self._load_dataset(num_words)\n",
        "\n",
        "    input_sequences, self.input_tokenizer = input\n",
        "    target_sequences, self.target_tokenizer = target\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((input_sequences, target_sequences))\n",
        "    dataset = dataset.shuffle(self.buffer_size).batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return self.input_tokenizer, self.target_tokenizer, dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8lYoZZjqXF__"
      },
      "outputs": [],
      "source": [
        "num_words = 15000\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QW7fD1GdrExy"
      },
      "outputs": [],
      "source": [
        "translator_dataset = TranslatorDataset(df)\n",
        "input_tokenizer, target_tokenizer, dataset = translator_dataset.get(num_words, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3lQitbaJXt4O"
      },
      "outputs": [],
      "source": [
        "input_batch, target_batch = next(iter(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2j91LroJX50x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848f75e1-205b-414d-8f5e-c56be9ac4796"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 43]), TensorShape([64, 43]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "input_batch.shape, target_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cI-TplUE22Tk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5063d54b-3e2a-4627-9aee-6322be458be3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43, 43, 38091, 38392)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "input_vocab_size = len(input_tokenizer.index_word) + 1\n",
        "target_vocab_size = len(target_tokenizer.index_word) + 1\n",
        "input_maxlen = input_batch.shape[1]\n",
        "target_maxlen = target_batch.shape[1]\n",
        "\n",
        "input_maxlen, target_maxlen, input_vocab_size, target_vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cPp4UAxdxemM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd0d9ef-b363-4ad9-eef7-8c859570deec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(43,), dtype=int32, numpy=\n",
              "array([ 1740,   602,   260,   240,  1051,     8,    88,    95,  1061,\n",
              "        1844,    11,     9,     1,   273,     4,  2483,  4986,   373,\n",
              "          18,     3,    44,  1728,     4,  1740,    26,    95,   575,\n",
              "          21,    23,    88,     2, 11151,   236,   224,   159,     2,\n",
              "          18,    73,    80,     2,   223,   415,     3], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "input_example = input_batch[-1]\n",
        "input_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1r5qpp8Hxjzk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d772c84e-346a-4b46-fef8-e0e2b7b152de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(43,), dtype=int32, numpy=\n",
              "array([   8, 2675,  405,  137,  472,  589,  589,    5, 1749, 1772, 1841,\n",
              "        230,   19,  264,  323, 1191,  282,    4,    2,  359, 2913,   11,\n",
              "         16,  971,  586,   60,  166,  239,  244,   20,  359,    4,    1,\n",
              "         29,   74,    2,    5, 1666,   31,   59,   48, 3344, 1713],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "target_example = target_batch[-1]\n",
        "target_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ulo132GvOX0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff739068-6758-4f54-d095-ffdd3a2ab5ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['exotica yet again hi guys i need some advice sharad is in the process of finding differences between your and our versions of exotica at some point we will need to migrate london office over to your more up to date version and']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "input_sentence = input_tokenizer.sequences_to_texts([input_example.numpy()])\n",
        "input_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "X59pOM0qOtyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e06adf-7ce5-4f96-ab0b-fc727b4bb379"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> exotica sekali lagi hai teman teman saya butuh nasihat sharad sedang dalam proses menemukan perbedaan antara anda dan versi eksotika kami pada titik tertentu kita perlu kantor london ke versi anda yang lebih baik dan saya khawatir bahwa mungkin ada implikasi gaya']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "target_sentence = target_tokenizer.sequences_to_texts([target_example.numpy()])\n",
        "target_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CeQhJSGasf4P"
      },
      "outputs": [],
      "source": [
        "embed_dims = 256\n",
        "units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fc2nYdHM0Xv0"
      },
      "outputs": [],
      "source": [
        "class Encoder():\n",
        "  def __init__(self, input_vocab_size, embedding_dims, units):\n",
        "    self.units = units\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "    self.embedding_dims = embedding_dims\n",
        "\n",
        "    self.embedding = layers.Embedding(self.input_vocab_size, self.embedding_dims)\n",
        "    self.lstm_layer = layers.LSTM(self.units,\n",
        "                                 return_sequences=True,\n",
        "                                 return_state=True,\n",
        "                                 recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    embedding = self.embedding(inputs)\n",
        "    encoder = self.lstm_layer(embedding, initial_state=None)\n",
        "\n",
        "    return encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TFONKQDzUdmw"
      },
      "outputs": [],
      "source": [
        "# class BahdanauAttention(layers.Layer):\n",
        "#   def __init__(self, units):\n",
        "#     super(BahdanauAttention, self).__init__()\n",
        "#     self.w1 = layers.Dense(units, use_bias=True) \n",
        "#     self.w2 = layers.Dense(units, use_bias=True) \n",
        "#     self.fd = layers.Dense(1)\n",
        "\n",
        "#   def call(self, query, values):\n",
        "#     query_with_time_axis = tf.expand_dims(query, 1)\n",
        "    \n",
        "#     score = self.fd(tf.nn.tanh(\n",
        "#         self.w1(query_with_time_axis) + self.w2(values)))\n",
        "\n",
        "#     attention_weights = softmax(score, axis=1)\n",
        "\n",
        "#     context_vector = attention_weights * values\n",
        "#     context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "#     return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8ayl_3A_1-IT"
      },
      "outputs": [],
      "source": [
        "class Decoder():\n",
        "  def __init__(self, output_vocab_size, embedding_dims, units):\n",
        "    self.units = units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dims = embedding_dims\n",
        "\n",
        "    self.embedding = layers.Embedding(self.output_vocab_size, self.embedding_dims)\n",
        "    self.lstm_layer = layers.LSTM(self.units,\n",
        "                                  return_sequences=True,\n",
        "                                  return_state=True,\n",
        "                                  recurrent_initializer='glorot_uniform')\n",
        "    self.attention = layers.AdditiveAttention()\n",
        "    self.dense1 = layers.Dense(self.units, activation=tanh)\n",
        "    self.dense2 = layers.Dense(self.output_vocab_size)\n",
        "\n",
        "  def call(self, inputs, en_outputs, state):\n",
        "    embedding = self.embedding(inputs)\n",
        "    dec_outputs, dec_h_state, dec_c_state = self.lstm_layer(\n",
        "        embedding, initial_state=state)\n",
        "    \n",
        "    context_vector = self.attention([dec_outputs, en_outputs])\n",
        "    \n",
        "    context_and_rnn_output = tf.concat([context_vector, dec_outputs], axis=-1)\n",
        "\n",
        "    attention_vector = self.dense1(dec_outputs)\n",
        "    outputs = self.dense2(attention_vector)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Kio22M03Yp9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "032db346-0d35-4f17-ecf6-c23b73c39e18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 43, 1024]), TensorShape([64, 1024]), TensorShape([64, 1024]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "encoder = Encoder(input_vocab_size, embed_dims, units)\n",
        "en_outputs, en_h_state, en_c_state = encoder.call(input_batch)\n",
        "\n",
        "en_outputs.shape, en_h_state.shape, en_c_state.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "x_7A5-GTadcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b409e62e-9050-497e-85d4-52162a35db1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 43, 38392])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "decoder = Decoder(target_vocab_size, embed_dims, units)\n",
        "dec_outputs= decoder.call(target_batch, en_outputs, [en_h_state, en_c_state])\n",
        "\n",
        "dec_outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "OdJEFRmxg0zW"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "epochs = 30\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "       from_logits=True, reduction='none')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-ifmblhR4X8i"
      },
      "outputs": [],
      "source": [
        "class TranslatorModel:\n",
        "  def __init__(self, input_vocab_size, \n",
        "               target_vocab_size, \n",
        "               embed_dims, \n",
        "               units):\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "    self.target_vocab_size = target_vocab_size\n",
        "    self.embed_dims = embed_dims\n",
        "    self.units = units\n",
        "\n",
        "    self.encoder = Encoder(self.input_vocab_size, self.embed_dims, self.units)\n",
        "    self.decoder = Decoder(self.target_vocab_size, self.embed_dims, self.units)\n",
        "  \n",
        "  def build_model(self):\n",
        "    en_inputs = layers.Input(shape=(None,))\n",
        "    en_output, en_h_state, en_c_state = self.encoder.call(en_inputs)\n",
        "\n",
        "    dec_outputs = self.decoder.call(en_inputs, en_output, [en_h_state, en_c_state])\n",
        "\n",
        "    model = Model(inputs=[en_inputs], \n",
        "                  outputs=[dec_outputs])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "SsTiGR8daD4K"
      },
      "outputs": [],
      "source": [
        "translator_model = TranslatorModel(\n",
        "    input_vocab_size,\n",
        "    target_vocab_size,\n",
        "    embed_dims,\n",
        "    units,\n",
        ")\n",
        "model = translator_model.build_model()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "VOUD1xKgIDH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "639fe7b3-659a-423d-a532-c757cb8adb70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, None, 256)    9751296     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 256)    9828352     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, None, 1024)  5246976     ['embedding_2[0][0]']            \n",
            "                                , (None, 1024),                                                   \n",
            "                                 (None, 1024)]                                                    \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 1024)  5246976     ['embedding_3[0][0]',            \n",
            "                                , (None, 1024),                   'lstm_2[0][1]',                 \n",
            "                                 (None, 1024)]                    'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, None, 1024)   1049600     ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, None, 38392)  39351800    ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 70,475,000\n",
            "Trainable params: 70,475,000\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/translate/checkpoint/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "callback_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='loss',\n",
        "    patience=3, \n",
        "    verbose=1)\n",
        "\n",
        "callback_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    monitor='loss', \n",
        "    verbose=1, \n",
        "    save_weights_only=True, \n",
        "    save_best_only=True)\n",
        "\n",
        "callbacks = [callback_early_stopping,\n",
        "             callback_checkpoint]\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "daAENyOqwdjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185b38b3-8dde-4c0b-dd44-22c07c2eb662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 3.5914 - accuracy: 0.5476\n",
            "Epoch 1: loss improved from inf to 3.59139, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0001.ckpt\n",
            "227/227 [==============================] - 71s 297ms/step - loss: 3.5914 - accuracy: 0.5476\n",
            "Epoch 2/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 2.9503 - accuracy: 0.5710\n",
            "Epoch 2: loss improved from 3.59139 to 2.95033, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0002.ckpt\n",
            "227/227 [==============================] - 71s 313ms/step - loss: 2.9503 - accuracy: 0.5710\n",
            "Epoch 3/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 2.7233 - accuracy: 0.5865\n",
            "Epoch 3: loss improved from 2.95033 to 2.72330, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0003.ckpt\n",
            "227/227 [==============================] - 73s 321ms/step - loss: 2.7233 - accuracy: 0.5865\n",
            "Epoch 4/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 2.5090 - accuracy: 0.6058\n",
            "Epoch 4: loss improved from 2.72330 to 2.50896, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0004.ckpt\n",
            "227/227 [==============================] - 74s 326ms/step - loss: 2.5090 - accuracy: 0.6058\n",
            "Epoch 5/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 2.3018 - accuracy: 0.6238\n",
            "Epoch 5: loss improved from 2.50896 to 2.30182, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0005.ckpt\n",
            "227/227 [==============================] - 76s 333ms/step - loss: 2.3018 - accuracy: 0.6238\n",
            "Epoch 6/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 2.1013 - accuracy: 0.6425\n",
            "Epoch 6: loss improved from 2.30182 to 2.10127, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0006.ckpt\n",
            "227/227 [==============================] - 75s 330ms/step - loss: 2.1013 - accuracy: 0.6425\n",
            "Epoch 7/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 1.9135 - accuracy: 0.6621\n",
            "Epoch 7: loss improved from 2.10127 to 1.91352, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0007.ckpt\n",
            "227/227 [==============================] - 75s 329ms/step - loss: 1.9135 - accuracy: 0.6621\n",
            "Epoch 8/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 1.7477 - accuracy: 0.6811\n",
            "Epoch 8: loss improved from 1.91352 to 1.74769, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0008.ckpt\n",
            "227/227 [==============================] - 75s 331ms/step - loss: 1.7477 - accuracy: 0.6811\n",
            "Epoch 9/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 1.5994 - accuracy: 0.6985\n",
            "Epoch 9: loss improved from 1.74769 to 1.59944, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0009.ckpt\n",
            "227/227 [==============================] - 76s 334ms/step - loss: 1.5994 - accuracy: 0.6985\n",
            "Epoch 10/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 1.4541 - accuracy: 0.7171\n",
            "Epoch 10: loss improved from 1.59944 to 1.45411, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0010.ckpt\n",
            "227/227 [==============================] - 75s 332ms/step - loss: 1.4541 - accuracy: 0.7171\n",
            "Epoch 11/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 1.3095 - accuracy: 0.7370\n",
            "Epoch 11: loss improved from 1.45411 to 1.30948, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0011.ckpt\n",
            "227/227 [==============================] - 75s 332ms/step - loss: 1.3095 - accuracy: 0.7370\n",
            "Epoch 12/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 1.1766 - accuracy: 0.7562\n",
            "Epoch 12: loss improved from 1.30948 to 1.17657, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0012.ckpt\n",
            "227/227 [==============================] - 75s 332ms/step - loss: 1.1766 - accuracy: 0.7562\n",
            "Epoch 13/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 1.0464 - accuracy: 0.7762\n",
            "Epoch 13: loss improved from 1.17657 to 1.04637, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0013.ckpt\n",
            "227/227 [==============================] - 75s 332ms/step - loss: 1.0464 - accuracy: 0.7762\n",
            "Epoch 14/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.9024 - accuracy: 0.8000\n",
            "Epoch 14: loss improved from 1.04637 to 0.90242, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0014.ckpt\n",
            "227/227 [==============================] - 76s 333ms/step - loss: 0.9024 - accuracy: 0.8000\n",
            "Epoch 15/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.7991 - accuracy: 0.8179\n",
            "Epoch 15: loss improved from 0.90242 to 0.79914, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0015.ckpt\n",
            "227/227 [==============================] - 75s 332ms/step - loss: 0.7991 - accuracy: 0.8179\n",
            "Epoch 16/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.6899 - accuracy: 0.8384\n",
            "Epoch 16: loss improved from 0.79914 to 0.68992, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0016.ckpt\n",
            "227/227 [==============================] - 76s 334ms/step - loss: 0.6899 - accuracy: 0.8384\n",
            "Epoch 17/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.5550 - accuracy: 0.8660\n",
            "Epoch 17: loss improved from 0.68992 to 0.55502, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0017.ckpt\n",
            "227/227 [==============================] - 75s 332ms/step - loss: 0.5550 - accuracy: 0.8660\n",
            "Epoch 18/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.4528 - accuracy: 0.8881\n",
            "Epoch 18: loss improved from 0.55502 to 0.45280, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0018.ckpt\n",
            "227/227 [==============================] - 75s 331ms/step - loss: 0.4528 - accuracy: 0.8881\n",
            "Epoch 19/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.3588 - accuracy: 0.9106\n",
            "Epoch 19: loss improved from 0.45280 to 0.35885, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0019.ckpt\n",
            "227/227 [==============================] - 75s 330ms/step - loss: 0.3588 - accuracy: 0.9106\n",
            "Epoch 20/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.9322\n",
            "Epoch 20: loss improved from 0.35885 to 0.27593, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0020.ckpt\n",
            "227/227 [==============================] - 76s 334ms/step - loss: 0.2759 - accuracy: 0.9322\n",
            "Epoch 21/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.9477\n",
            "Epoch 21: loss improved from 0.27593 to 0.21542, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0021.ckpt\n",
            "227/227 [==============================] - 76s 334ms/step - loss: 0.2154 - accuracy: 0.9477\n",
            "Epoch 22/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.1658 - accuracy: 0.9612\n",
            "Epoch 22: loss improved from 0.21542 to 0.16575, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0022.ckpt\n",
            "227/227 [==============================] - 76s 333ms/step - loss: 0.1658 - accuracy: 0.9612\n",
            "Epoch 23/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 0.9710\n",
            "Epoch 23: loss improved from 0.16575 to 0.12793, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0023.ckpt\n",
            "227/227 [==============================] - 76s 336ms/step - loss: 0.1279 - accuracy: 0.9710\n",
            "Epoch 24/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.9779\n",
            "Epoch 24: loss improved from 0.12793 to 0.10240, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0024.ckpt\n",
            "227/227 [==============================] - 75s 332ms/step - loss: 0.1024 - accuracy: 0.9779\n",
            "Epoch 25/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9816\n",
            "Epoch 25: loss improved from 0.10240 to 0.08652, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0025.ckpt\n",
            "227/227 [==============================] - 75s 332ms/step - loss: 0.0865 - accuracy: 0.9816\n",
            "Epoch 26/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.9837\n",
            "Epoch 26: loss improved from 0.08652 to 0.07601, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0026.ckpt\n",
            "227/227 [==============================] - 75s 333ms/step - loss: 0.0760 - accuracy: 0.9837\n",
            "Epoch 27/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.9849\n",
            "Epoch 27: loss improved from 0.07601 to 0.06840, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0027.ckpt\n",
            "227/227 [==============================] - 76s 334ms/step - loss: 0.0684 - accuracy: 0.9849\n",
            "Epoch 28/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9869\n",
            "Epoch 28: loss improved from 0.06840 to 0.05895, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0028.ckpt\n",
            "227/227 [==============================] - 76s 335ms/step - loss: 0.0590 - accuracy: 0.9869\n",
            "Epoch 29/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9872\n",
            "Epoch 29: loss improved from 0.05895 to 0.05745, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0029.ckpt\n",
            "227/227 [==============================] - 77s 338ms/step - loss: 0.0574 - accuracy: 0.9872\n",
            "Epoch 30/30\n",
            "227/227 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9885\n",
            "Epoch 30: loss improved from 0.05745 to 0.05176, saving model to /content/drive/MyDrive/translate/checkpoint/cp-0030.ckpt\n",
            "227/227 [==============================] - 76s 335ms/step - loss: 0.0518 - accuracy: 0.9885\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f15705eafd0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "model.fit(dataset,\n",
        "          epochs=epochs,\n",
        "          callbacks=callbacks,\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0QGxWYuiQPnv"
      },
      "outputs": [],
      "source": [
        "# if use colab\n",
        "saved_model_path = \"saved_model/translation.h5\"\n",
        "\n",
        "# if use local env\n",
        "# saved_model_path = \"code/translate sentence/saved_model\"\n",
        "saved_model_dir = os.path.dirname(saved_model_path)\n",
        "\n",
        "if os.path.exists(saved_model_dir):\n",
        "  shutil.rmtree(saved_model_dir)\n",
        "  \n",
        "model.save(saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS\n",
        "]\n",
        "converter.experimental_new_converter = True\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "open(\"translation.tflite\", \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFpBRO4W31YA",
        "outputId": "03e3b188-497e-4315-b036-6e119512015e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpt0l277ii/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpt0l277ii/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "281951664"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1YmcvYUyzqLd"
      },
      "outputs": [],
      "source": [
        "# class Translator:\n",
        "#   def __init__(self, model_path, input_tokenizer, target_tokenizer, maxlen):\n",
        "#     self.input_tokenizer = input_tokenizer\n",
        "#     self.target_tokenizer = target_tokenizer\n",
        "#     self.maxlen = maxlen\n",
        "#     self.model_path = model_path\n",
        "\n",
        "#     self._load_model()\n",
        "\n",
        "#   def _load_model(self):\n",
        "#     self.model = tf.keras.models.load_model(self.model_path, compile=True)\n",
        "\n",
        "#   def _normalize_and_preprocess(self, text):\n",
        "#     punctuation = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        "    \n",
        "#     text = text.lower().strip()\n",
        "#     text = text.replace(punctuation, \"\")\n",
        "\n",
        "#     return text\n",
        "    \n",
        "#   def translate(self, sentence):\n",
        "#     index_prediction = list()\n",
        "\n",
        "#     normalize_sentence = self._normalize_and_preprocess(sentence)\n",
        "\n",
        "#     sequences = input_tokenizer.texts_to_sequences([normalize_sentence])\n",
        "#     sequences = pad_sequences(\n",
        "#         sequences, maxlen=self.maxlen, padding=\"post\", truncating=\"post\")\n",
        "    \n",
        "#     predictions = self.model.predict(sequences)\n",
        "\n",
        "#     for i in predictions[0]:\n",
        "#       index_prediction.append(np.argmax(i))\n",
        "\n",
        "#     marks = [start_mark, end_mark]\n",
        "#     result = target_tokenizer.sequences_to_texts([index_prediction])[0]\n",
        "#     result = \" \".join([word for word in result.split(\" \") if word not in marks])\n",
        "\n",
        "#     return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NkNd7WY3LSvJ"
      },
      "outputs": [],
      "source": [
        "# translator = Translator(\n",
        "#     saved_model_path,\n",
        "#     input_tokenizer, \n",
        "#     target_tokenizer,\n",
        "#     input_maxlen,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# translate = translator.translate(\"i'm joking\")\n",
        "# translate"
      ],
      "metadata": {
        "id": "gLjLFWVdFCCQ"
      },
      "execution_count": 36,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "translator.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "765233bfe060b87a8be23ec8f17030d468ac6435ae34b0ad14370b4cb734ac81"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}