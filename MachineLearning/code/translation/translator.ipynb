{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "ewbrnbnHgEoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "362183cd-5289-4b68-93cf-85ae6f6f0769"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "56aTseK4q9ol"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import subprocess\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import pathlib\n",
        "\n",
        "from langdetect import detect\n",
        "from google.colab import drive, files #if use colab\n",
        "from tensorflow.nn import relu, tanh, softmax\n",
        "from tensorflow.lite.python import interpreter\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.text import tokenizer_from_json\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "tz4aY7oDbyeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27a6d87-fb1a-46a6-9dda-1b319a588157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "2ZtMplOQv6Lz"
      },
      "outputs": [],
      "source": [
        "git_dir = '/content/IOH-Chat-App'\n",
        "git_url = 'https://github.com/bangkit-team/IOH-chat-app.git'\n",
        "\n",
        "if not os.path.exists(git_dir):\n",
        "  subprocess.call(['git', 'clone', git_url])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "pN2M4PirLEQB"
      },
      "outputs": [],
      "source": [
        "filedir = '/content/IOH-chat-app/MachineLearning/datasets/translation/result/eng-ind.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "CTSHYGqdTyPk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "19dbf1b3-4237-4e88-fec8-114112aa639c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 English  \\\n",
              "0                                                   Run!   \n",
              "1                                                   Who?   \n",
              "2                                                   Wow!   \n",
              "3                                                  Help!   \n",
              "4                                                  Jump!   \n",
              "...                                                  ...   \n",
              "15359  Limitation of this capability causes opportuni...   \n",
              "15360  Subjective approach evaluates poverty based on...   \n",
              "15361  Limited sufficiency and food quality , seen fr...   \n",
              "15362  Around 20 percents people with the lowest inco...   \n",
              "15363  Deficiency of calory intake , namely less than...   \n",
              "\n",
              "                                               Indonesia  \n",
              "0                                                  Lari!  \n",
              "1                                                 Siapa?  \n",
              "2                                                   Wow!  \n",
              "3                                                Tolong!  \n",
              "4                                                Lompat!  \n",
              "...                                                  ...  \n",
              "15359  Keterbatasan kemampuan ini menyebabkan tertutu...  \n",
              "15360  Pendekatan subyektif menilai kemiskinan berdas...  \n",
              "15361  terbatasnya kecukupan dan mutu pangan , diliha...  \n",
              "15362  Sekitar 20 persen penduduk dengan tingkat pend...  \n",
              "15363  Kekurangan asupan kalori , yaitu kurang dari 2...  \n",
              "\n",
              "[15364 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1cd7923f-a668-444c-a161-a52356e4d149\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Indonesia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Lari!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Siapa?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Wow!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Help!</td>\n",
              "      <td>Tolong!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jump!</td>\n",
              "      <td>Lompat!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15359</th>\n",
              "      <td>Limitation of this capability causes opportuni...</td>\n",
              "      <td>Keterbatasan kemampuan ini menyebabkan tertutu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15360</th>\n",
              "      <td>Subjective approach evaluates poverty based on...</td>\n",
              "      <td>Pendekatan subyektif menilai kemiskinan berdas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15361</th>\n",
              "      <td>Limited sufficiency and food quality , seen fr...</td>\n",
              "      <td>terbatasnya kecukupan dan mutu pangan , diliha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15362</th>\n",
              "      <td>Around 20 percents people with the lowest inco...</td>\n",
              "      <td>Sekitar 20 persen penduduk dengan tingkat pend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15363</th>\n",
              "      <td>Deficiency of calory intake , namely less than...</td>\n",
              "      <td>Kekurangan asupan kalori , yaitu kurang dari 2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15364 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1cd7923f-a668-444c-a161-a52356e4d149')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1cd7923f-a668-444c-a161-a52356e4d149 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1cd7923f-a668-444c-a161-a52356e4d149');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "df = pd.read_csv(filedir)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "RgUUgmronChh"
      },
      "outputs": [],
      "source": [
        "start_mark = '<start>'\n",
        "end_mark = '<end>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "KA5VqxGKtrWx"
      },
      "outputs": [],
      "source": [
        "class TranslatorDataset:\n",
        "  def __init__(self, dataframe):\n",
        "    self.dataframe = dataframe\n",
        "    self.input_tokenizer = None\n",
        "    self.target_tokenizer = None\n",
        "    self._load_data_from_file()\n",
        "\n",
        "  def _load_data_from_file(self):\n",
        "    df = self.dataframe\n",
        "\n",
        "    input_lang = df.English.values\n",
        "    target_lang = df.Indonesia.values\n",
        "\n",
        "    return input_lang, target_lang\n",
        "\n",
        "  def _normalize_and_preprocess(self, text, use_mark=False):\n",
        "    if use_mark:\n",
        "      text = text.strip()\n",
        "      text = ' '.join([start_mark, text, end_mark])\n",
        "    else:\n",
        "      text = text.strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "  def _tokenize(self, sentences, num_words, maxlen):\n",
        "    punctuation = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=num_words, filters=punctuation)\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "    sequences = pad_sequences(\n",
        "        sequences, maxlen=self.maxlen, padding='post', truncating='post')\n",
        "\n",
        "    return sequences, tokenizer\n",
        "\n",
        "  def _create_dataset(self):\n",
        "    input_lang, target_lang = self._load_data_from_file()\n",
        "\n",
        "    input_sentence = np.array(\n",
        "        list(map(lambda x: self._normalize_and_preprocess(x, False), input_lang)))\n",
        "    \n",
        "    target_sentence = np.array(\n",
        "        list(map(lambda y: self._normalize_and_preprocess(y, True), target_lang)))\n",
        "    \n",
        "    return input_sentence, target_sentence\n",
        "\n",
        "  def _load_dataset(self, num_words):\n",
        "    input_lang, target_lang = self._create_dataset()\n",
        "\n",
        "    self.maxlen = 20\n",
        "    self.buffer_size = len(input_lang)\n",
        "\n",
        "    input_sequences, input_tokenizer = self._tokenize(\n",
        "        input_lang, num_words, self.maxlen)\n",
        "    \n",
        "    target_sequences, target_tokenizer = self._tokenize(\n",
        "        target_lang, num_words, self.maxlen,)\n",
        "\n",
        "    return (input_sequences, input_tokenizer), (target_sequences, target_tokenizer)\n",
        "  \n",
        "  def get(self, num_words, batch_size):\n",
        "    input, target = self._load_dataset(num_words)\n",
        "\n",
        "    input_sequences, self.input_tokenizer = input\n",
        "    target_sequences, self.target_tokenizer = target\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((input_sequences, target_sequences))\n",
        "    dataset = dataset.shuffle(self.buffer_size).batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return self.input_tokenizer, self.target_tokenizer, dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "8lYoZZjqXF__"
      },
      "outputs": [],
      "source": [
        "num_words = 20000\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "QW7fD1GdrExy"
      },
      "outputs": [],
      "source": [
        "translator_dataset = TranslatorDataset(df)\n",
        "\n",
        "input_tokenizer, target_tokenizer, dataset = translator_dataset.get(num_words, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "3lQitbaJXt4O"
      },
      "outputs": [],
      "source": [
        "input_batch, target_batch = next(iter(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "2j91LroJX50x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408ab3bb-a345-41f5-aafc-e4701f8600c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 20]), TensorShape([64, 20]))"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "input_batch.shape, target_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "cI-TplUE22Tk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "542ca8b9-b0e3-460c-e4da-c3c30d2ec248"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 20, 12035, 13498)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "input_vocab_size = len(input_tokenizer.index_word) + 1\n",
        "target_vocab_size = len(target_tokenizer.index_word) + 1\n",
        "input_maxlen = input_batch.shape[1]\n",
        "target_maxlen = target_batch.shape[1]\n",
        "\n",
        "input_maxlen, target_maxlen, input_vocab_size, target_vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokenizer_dir = '/content/drive/MyDrive/Company Case Bangkit/TranslationModel/input_tokenizer.json'\n",
        "\n",
        "input_tokenizer_json = input_tokenizer.to_json()\n",
        "with open(input_tokenizer_dir, 'w', encoding='utf-8') as f:\n",
        "    f.write(json.dumps(input_tokenizer_json, ensure_ascii=False))\n",
        "\n",
        "files.download(input_tokenizer_dir)"
      ],
      "metadata": {
        "id": "am-Q49eTM-3V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6111da6b-35b4-4463-977f-5caa9f74a2f9"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c93eca8b-e225-4aff-9034-10eb2291bcb5\", \"input_tokenizer.json\", 1335024)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_tokenizer_dir = '/content/drive/MyDrive/Company Case Bangkit/TranslationModel/target_tokenizer.json'\n",
        "\n",
        "target_tokenizer_json = target_tokenizer.to_json()\n",
        "with open(target_tokenizer_dir, 'w', encoding='utf-8') as f:\n",
        "    f.write(json.dumps(target_tokenizer_json, ensure_ascii=False))\n",
        "\n",
        "files.download(target_tokenizer_dir)"
      ],
      "metadata": {
        "id": "0f7HIf8RNCvd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "48196a42-876f-43d2-af6b-c49635b1557b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_29b7353c-5bb6-4cba-9818-04e1c9706b27\", \"target_tokenizer.json\", 1526757)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "cPp4UAxdxemM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f40d7d-8196-4c7c-a769-1bae3689b1ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=int32, numpy=\n",
              "array([   1,   98, 3201,    3, 2906,    6,  274, 2162,   34,  990,  384,\n",
              "         17,   23,   38,    1,   87,   23,  911,  393,    2], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "input_example = input_batch[-1]\n",
        "input_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "1r5qpp8Hxjzk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c95c6903-e51a-4689-b29a-14756a72ad12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=int32, numpy=\n",
              "array([   1,  868, 2206,    4,  238, 1631,  553,  452,   20,   23,   52,\n",
              "          3,  319,   52,  243,   28,  213,  543,  310,   10], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "target_example = target_batch[-1]\n",
        "target_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "ulo132GvOX0l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2d40ec36-7d2e-40cc-9cc1-ab44a76f4ada"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"the indonesian chamber of commerce and industry kadin has expressed support for bank indonesia the central bank bi's decision to\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "input_sentence = input_tokenizer.sequences_to_texts([input_example.numpy()])[0]\n",
        "input_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "X59pOM0qOtyb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a988d4c3-a255-486f-c9ff-93b87fe3efb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> kamar dagang dan industri kadin mendukung langkah bank indonesia bi yang menaikkan bi rate sebesar 25 basis poin dari'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "target_sentence = target_tokenizer.sequences_to_texts([target_example.numpy()])[0]\n",
        "target_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "CeQhJSGasf4P"
      },
      "outputs": [],
      "source": [
        "embed_dims = 512\n",
        "units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "fc2nYdHM0Xv0"
      },
      "outputs": [],
      "source": [
        "class Encoder():\n",
        "  def __init__(self, input_vocab_size, embedding_dims, units):\n",
        "    self.units = units\n",
        "    self.batch_size = batch_size\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "    self.embedding_dims = embedding_dims\n",
        "\n",
        "    self.embedding = layers.Embedding(self.input_vocab_size, self.embedding_dims)\n",
        "    self.lstm_layer = layers.LSTM(self.units,\n",
        "                                 return_sequences=True,\n",
        "                                 return_state=True,\n",
        "                                 recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    embedding = self.embedding(inputs)\n",
        "    encoder = self.lstm_layer(embedding)\n",
        "\n",
        "    return encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "TFONKQDzUdmw"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.w1 = layers.Dense(units, use_bias=True) \n",
        "    self.w2 = layers.Dense(units, use_bias=True) \n",
        "    self.fd = layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "    \n",
        "    score = self.fd(tanh(\n",
        "        self.w1(query_with_time_axis) + self.w2(values)))\n",
        "\n",
        "    attention_weights = softmax(score, axis=1)\n",
        "\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "8ayl_3A_1-IT"
      },
      "outputs": [],
      "source": [
        "class Decoder:\n",
        "  def __init__(self, output_vocab_size, embedding_dims, units):\n",
        "    self.units = units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dims = embedding_dims\n",
        "\n",
        "    self.embedding = layers.Embedding(self.output_vocab_size, self.embedding_dims)\n",
        "    self.lstm_layer = layers.LSTM(self.units,\n",
        "                                  return_sequences=True,\n",
        "                                  return_state=True,\n",
        "                                  recurrent_initializer='glorot_uniform')\n",
        "    self.attention = BahdanauAttention(self.units)\n",
        "    self.dense1 = layers.Dense(self.units, activation=tanh, use_bias=False)\n",
        "    self.dropout = layers.Dropout(.5)\n",
        "    self.dense2 = layers.TimeDistributed(layers.Dense(self.output_vocab_size))\n",
        "\n",
        "  def call(self, inputs, en_outputs, state):\n",
        "    embedding = self.embedding(inputs)\n",
        "    dec_outputs, dec_h_state, dec_c_state = self.lstm_layer(\n",
        "        embedding, initial_state=state)\n",
        "    \n",
        "    context_vector, attention_weights = self.attention(\n",
        "        query=dec_outputs, values=en_outputs)\n",
        "    \n",
        "    context_and_rnn_output = tf.concat([context_vector, dec_outputs], axis=-1)\n",
        "\n",
        "    attention_vector = self.dense1(context_and_rnn_output)\n",
        "    outputs = self.dropout(attention_vector)\n",
        "    outputs = self.dense2(outputs)\n",
        "\n",
        "    return outputs, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "Kio22M03Yp9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a659840b-3c90-4802-ea67-72f7c517b4df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 20, 1024]), TensorShape([64, 1024]), TensorShape([64, 1024]))"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "encoder = Encoder(input_vocab_size, embed_dims, units)\n",
        "\n",
        "en_outputs, en_h_state, en_c_state = encoder.call(input_batch)\n",
        "\n",
        "en_outputs.shape, en_h_state.shape, en_c_state.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "x_7A5-GTadcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511e6626-1b5a-4c7a-d382-09370004d32e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 20, 13498])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "decoder = Decoder(target_vocab_size, embed_dims, units)\n",
        "dec_outputs, _= decoder.call(target_batch, en_outputs, [en_h_state, en_c_state])\n",
        "\n",
        "dec_outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "OdJEFRmxg0zW"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "epochs = 30\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=lr, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "       from_logits=True, reduction='none')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "-ifmblhR4X8i"
      },
      "outputs": [],
      "source": [
        "class TranslatorModel:\n",
        "  def __init__(self, input_vocab_size, \n",
        "               target_vocab_size, \n",
        "               embed_dims, \n",
        "               units):\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "    self.target_vocab_size = target_vocab_size\n",
        "    self.embed_dims = embed_dims\n",
        "    self.units = units\n",
        "\n",
        "    self.encoder = Encoder(\n",
        "        self.input_vocab_size, self.embed_dims, self.units)\n",
        "    \n",
        "    self.decoder = Decoder(\n",
        "        self.target_vocab_size, self.embed_dims, self.units)\n",
        "  \n",
        "  def build_model(self):\n",
        "    en_inputs = layers.Input(shape=(None,))\n",
        "\n",
        "    en_output, en_h_state, en_c_state = self.encoder.call(en_inputs)\n",
        "\n",
        "    dec_outputs, _ = self.decoder.call(\n",
        "        en_inputs, en_output, [en_h_state, en_c_state])\n",
        "\n",
        "    model = Model(inputs=[en_inputs], \n",
        "                  outputs=[dec_outputs])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "SsTiGR8daD4K"
      },
      "outputs": [],
      "source": [
        "translator_model = TranslatorModel(\n",
        "    input_vocab_size,\n",
        "    target_vocab_size,\n",
        "    embed_dims,\n",
        "    units,\n",
        ")\n",
        "model = translator_model.build_model()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "VOUD1xKgIDH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f3d203-7d02-4956-afb6-f84551153f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_6 (Embedding)        (None, None, 512)    6161920     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_7 (Embedding)        (None, None, 512)    6910976     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_6 (LSTM)                  [(None, None, 1024)  6295552     ['embedding_6[0][0]']            \n",
            "                                , (None, 1024),                                                   \n",
            "                                 (None, 1024)]                                                    \n",
            "                                                                                                  \n",
            " lstm_7 (LSTM)                  [(None, None, 1024)  6295552     ['embedding_7[0][0]',            \n",
            "                                , (None, 1024),                   'lstm_6[0][1]',                 \n",
            "                                 (None, 1024)]                    'lstm_6[0][2]']                 \n",
            "                                                                                                  \n",
            " bahdanau_attention_3 (Bahdanau  ((None, None, 1024)  2100225    ['lstm_7[0][0]',                 \n",
            " Attention)                     , (None, None, None               'lstm_6[0][0]']                 \n",
            "                                , 1))                                                             \n",
            "                                                                                                  \n",
            " tf.concat_1 (TFOpLambda)       (None, None, 2048)   0           ['bahdanau_attention_3[0][0]',   \n",
            "                                                                  'lstm_7[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, None, 1024)   2097152     ['tf.concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, None, 1024)   0           ['dense_18[0][0]']               \n",
            "                                                                                                  \n",
            " time_distributed_3 (TimeDistri  (None, None, 13498)  13835450   ['dropout_3[0][0]']              \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 43,696,827\n",
            "Trainable params: 43,696,827\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = 'checkpoint/cp.ckpt'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "callback_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='loss',\n",
        "    patience=3, \n",
        "    verbose=1)\n",
        "\n",
        "callback_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    monitor='loss', \n",
        "    verbose=1, \n",
        "    save_weights_only=True, \n",
        "    save_best_only=True)\n",
        "\n",
        "callbacks = [callback_early_stopping,\n",
        "             callback_checkpoint]\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daAENyOqwdjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84578685-612a-4ef2-c43f-9dc7a541d3c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 4.1457 - accuracy: 0.4588\n",
            "Epoch 1: loss improved from inf to 4.14574, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 38s 141ms/step - loss: 4.1457 - accuracy: 0.4588\n",
            "Epoch 2/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 3.6184 - accuracy: 0.4838\n",
            "Epoch 2: loss improved from 4.14574 to 3.61842, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 35s 145ms/step - loss: 3.6184 - accuracy: 0.4838\n",
            "Epoch 3/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 3.3872 - accuracy: 0.5014\n",
            "Epoch 3: loss improved from 3.61842 to 3.38722, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 36s 150ms/step - loss: 3.3872 - accuracy: 0.5014\n",
            "Epoch 4/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 3.2002 - accuracy: 0.5151\n",
            "Epoch 4: loss improved from 3.38722 to 3.20019, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 37s 155ms/step - loss: 3.2002 - accuracy: 0.5151\n",
            "Epoch 5/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 3.0289 - accuracy: 0.5283\n",
            "Epoch 5: loss improved from 3.20019 to 3.02892, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 36s 150ms/step - loss: 3.0289 - accuracy: 0.5283\n",
            "Epoch 6/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 2.8712 - accuracy: 0.5407\n",
            "Epoch 6: loss improved from 3.02892 to 2.87123, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 37s 153ms/step - loss: 2.8712 - accuracy: 0.5407\n",
            "Epoch 7/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 2.7088 - accuracy: 0.5541\n",
            "Epoch 7: loss improved from 2.87123 to 2.70879, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 36s 151ms/step - loss: 2.7088 - accuracy: 0.5541\n",
            "Epoch 8/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 2.5440 - accuracy: 0.5689\n",
            "Epoch 8: loss improved from 2.70879 to 2.54404, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 36s 152ms/step - loss: 2.5440 - accuracy: 0.5689\n",
            "Epoch 9/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 2.3667 - accuracy: 0.5861\n",
            "Epoch 9: loss improved from 2.54404 to 2.36666, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 36s 152ms/step - loss: 2.3667 - accuracy: 0.5861\n",
            "Epoch 10/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 2.1858 - accuracy: 0.6046\n",
            "Epoch 10: loss improved from 2.36666 to 2.18580, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 37s 152ms/step - loss: 2.1858 - accuracy: 0.6046\n",
            "Epoch 11/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 2.0016 - accuracy: 0.6254\n",
            "Epoch 11: loss improved from 2.18580 to 2.00160, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 37s 152ms/step - loss: 2.0016 - accuracy: 0.6254\n",
            "Epoch 12/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 1.8089 - accuracy: 0.6487\n",
            "Epoch 12: loss improved from 2.00160 to 1.80892, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 37s 153ms/step - loss: 1.8089 - accuracy: 0.6487\n",
            "Epoch 13/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 1.6171 - accuracy: 0.6746\n",
            "Epoch 13: loss improved from 1.80892 to 1.61713, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 36s 152ms/step - loss: 1.6171 - accuracy: 0.6746\n",
            "Epoch 14/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 1.4420 - accuracy: 0.7007\n",
            "Epoch 14: loss improved from 1.61713 to 1.44198, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 37s 152ms/step - loss: 1.4420 - accuracy: 0.7007\n",
            "Epoch 15/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 1.2717 - accuracy: 0.7276\n",
            "Epoch 15: loss improved from 1.44198 to 1.27167, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 36s 151ms/step - loss: 1.2717 - accuracy: 0.7276\n",
            "Epoch 16/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 1.1222 - accuracy: 0.7527\n",
            "Epoch 16: loss improved from 1.27167 to 1.12222, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 37s 153ms/step - loss: 1.1222 - accuracy: 0.7527\n",
            "Epoch 17/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.9849 - accuracy: 0.7773\n",
            "Epoch 17: loss improved from 1.12222 to 0.98493, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 37s 154ms/step - loss: 0.9849 - accuracy: 0.7773\n",
            "Epoch 18/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.8729 - accuracy: 0.7988\n",
            "Epoch 18: loss improved from 0.98493 to 0.87286, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 37s 153ms/step - loss: 0.8729 - accuracy: 0.7988\n",
            "Epoch 19/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.7633 - accuracy: 0.8212\n",
            "Epoch 19: loss improved from 0.87286 to 0.76328, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 36s 152ms/step - loss: 0.7633 - accuracy: 0.8212\n",
            "Epoch 20/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.6749 - accuracy: 0.8394\n",
            "Epoch 20: loss improved from 0.76328 to 0.67485, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 36s 152ms/step - loss: 0.6749 - accuracy: 0.8394\n",
            "Epoch 21/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.5927 - accuracy: 0.8574\n",
            "Epoch 21: loss improved from 0.67485 to 0.59273, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 37s 155ms/step - loss: 0.5927 - accuracy: 0.8574\n",
            "Epoch 22/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.5186 - accuracy: 0.8748\n",
            "Epoch 22: loss improved from 0.59273 to 0.51859, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 36s 152ms/step - loss: 0.5186 - accuracy: 0.8748\n",
            "Epoch 23/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.4602 - accuracy: 0.8885\n",
            "Epoch 23: loss improved from 0.51859 to 0.46022, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 37s 153ms/step - loss: 0.4602 - accuracy: 0.8885\n",
            "Epoch 24/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.4056 - accuracy: 0.9016\n",
            "Epoch 24: loss improved from 0.46022 to 0.40559, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 36s 152ms/step - loss: 0.4056 - accuracy: 0.9016\n",
            "Epoch 25/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.3553 - accuracy: 0.9135\n",
            "Epoch 25: loss improved from 0.40559 to 0.35529, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 37s 152ms/step - loss: 0.3553 - accuracy: 0.9135\n",
            "Epoch 26/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.3153 - accuracy: 0.9231\n",
            "Epoch 26: loss improved from 0.35529 to 0.31526, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 37s 153ms/step - loss: 0.3153 - accuracy: 0.9231\n",
            "Epoch 27/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.2896 - accuracy: 0.9298\n",
            "Epoch 27: loss improved from 0.31526 to 0.28960, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 37s 152ms/step - loss: 0.2896 - accuracy: 0.9298\n",
            "Epoch 28/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.2629 - accuracy: 0.9365\n",
            "Epoch 28: loss improved from 0.28960 to 0.26288, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 36s 152ms/step - loss: 0.2629 - accuracy: 0.9365\n",
            "Epoch 29/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.2408 - accuracy: 0.9425\n",
            "Epoch 29: loss improved from 0.26288 to 0.24079, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 37s 152ms/step - loss: 0.2408 - accuracy: 0.9425\n",
            "Epoch 30/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.2210 - accuracy: 0.9471\n",
            "Epoch 30: loss improved from 0.24079 to 0.22105, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 37s 153ms/step - loss: 0.2210 - accuracy: 0.9471\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc63fc6bb10>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model.fit(dataset,\n",
        "          epochs=epochs,\n",
        "          callbacks=callbacks,\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QGxWYuiQPnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb71179-62dc-4435-f970-221ec84e868e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, dense_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Company Case Bangkit/TranslationModel/saved_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Company Case Bangkit/TranslationModel/saved_model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fc63ff93050> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fc63fbd9510> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "saved_model_path = '/content/drive/MyDrive/Company Case Bangkit/TranslationModel/saved_model'\n",
        "saved_model_dir = os.path.dirname(saved_model_path)\n",
        "\n",
        "if os.path.exists(saved_model_dir):\n",
        "  shutil.rmtree(saved_model_dir)\n",
        "  \n",
        "model.save(saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFpBRO4W31YA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd2f2e8-65f6-4b6a-8a9b-fb6ff34f3ed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, dense_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp19mok75u/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp19mok75u/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43830672"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS\n",
        "]\n",
        "converter.experimental_new_converter = True\n",
        "converter.allow_custom_ops = True\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_model_file = pathlib.Path('translation.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkJJXewBdV2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c19fa12f-8469-4499-b863-4f6b4ca43936"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([{'dtype': numpy.float32,\n",
              "   'index': 0,\n",
              "   'name': 'serving_default_input_1:0',\n",
              "   'quantization': (0.0, 0),\n",
              "   'quantization_parameters': {'quantized_dimension': 0,\n",
              "    'scales': array([], dtype=float32),\n",
              "    'zero_points': array([], dtype=int32)},\n",
              "   'shape': array([1, 1], dtype=int32),\n",
              "   'shape_signature': array([-1, -1], dtype=int32),\n",
              "   'sparsity_parameters': {}}],\n",
              " [{'dtype': numpy.float32,\n",
              "   'index': 124,\n",
              "   'name': 'StatefulPartitionedCall:0',\n",
              "   'quantization': (0.0, 0),\n",
              "   'quantization_parameters': {'quantized_dimension': 0,\n",
              "    'scales': array([], dtype=float32),\n",
              "    'zero_points': array([], dtype=int32)},\n",
              "   'shape': array([    1,     1, 13498], dtype=int32),\n",
              "   'shape_signature': array([   -1,    -1, 13498], dtype=int32),\n",
              "   'sparsity_parameters': {}}])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "interpreter = tf.lite.Interpreter('translation.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_details, output_details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YmcvYUyzqLd"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.Module):\n",
        "  def __init__(self, model_path, input_tokenizer_json, target_tokenizer_json, maxlen):\n",
        "    self.model_path = model_path\n",
        "    self.input_tokenizer_json = input_tokenizer_json\n",
        "    self.target_tokenizer_json = target_tokenizer_json\n",
        "    self.maxlen = maxlen\n",
        "\n",
        "    self._load_model()\n",
        "    self._load_tokenizer()\n",
        "\n",
        "  def _load_model(self):\n",
        "    self.model = tf.keras.models.load_model(self.model_path, compile=True)\n",
        "  \n",
        "  def _load_tokenizer(self):\n",
        "    with open(self.input_tokenizer_json) as f:\n",
        "      input_json = json.load(f)\n",
        "      self.input_tokenizer = tokenizer_from_json(input_json)\n",
        "\n",
        "    with open(self.target_tokenizer_json) as f:\n",
        "      target_json = json.load(f)\n",
        "      self.target_tokenizer = tokenizer_from_json(target_json)\n",
        "\n",
        "  def _normalize_and_preprocess(self, text):\n",
        "    punctuation = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "    \n",
        "    text = text.lower().strip()\n",
        "    text = ''.join((filter(lambda x: x not in punctuation, text)))\n",
        "\n",
        "    return text\n",
        "\n",
        "  def lang_detector(self, sentence):\n",
        "      return detect(sentence)\n",
        "\n",
        "  def __call__(self, sentence):\n",
        "    index_prediction = list()\n",
        "\n",
        "    normalize_sentence = self._normalize_and_preprocess(sentence)\n",
        "    sequences = self.input_tokenizer.texts_to_sequences([normalize_sentence])\n",
        "    sequences = pad_sequences(\n",
        "        sequences, maxlen=self.maxlen, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "    predictions = self.model(sequences)\n",
        "\n",
        "    for i in predictions[0]:\n",
        "        index_prediction.append(np.argmax(i))\n",
        "\n",
        "    marks = [start_mark, end_mark]\n",
        "    result = self.target_tokenizer.sequences_to_texts([index_prediction])[0]\n",
        "\n",
        "    result = ' '.join([word for word in result.split(' ') if word not in marks])\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkNd7WY3LSvJ"
      },
      "outputs": [],
      "source": [
        "saved_model_path = '/content/drive/MyDrive/Company Case Bangkit/TranslationModel/saved_model'\n",
        "\n",
        "translator = Translator(\n",
        "    saved_model_path,\n",
        "    input_tokenizer_dir,\n",
        "    target_tokenizer_dir,\n",
        "    input_maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLjLFWVdFCCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a9709f8-d94f-45da-f9ea-91576c831f2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aku suka apel\n"
          ]
        }
      ],
      "source": [
        "text_input = 'i like apple'\n",
        "lang_detector = translator.lang_detector(text_input)\n",
        "\n",
        "translate = translator(text_input)\n",
        "print(translate)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "translator.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "765233bfe060b87a8be23ec8f17030d468ac6435ae34b0ad14370b4cb734ac81"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}