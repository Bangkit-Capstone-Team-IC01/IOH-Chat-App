{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ewbrnbnHgEoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3800cdca-2bee-4eb3-cd35-a51b5e56cea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=73794da55880d71b99063dfa5276b7f3fa9ec927211aa9f539a6d754b3ba9ad9\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "56aTseK4q9ol"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import subprocess\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import pathlib\n",
        "\n",
        "from langdetect import detect\n",
        "from google.colab import drive, files #if use colab\n",
        "from tensorflow.nn import relu, tanh, softmax\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.lite.python import interpreter\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tz4aY7oDbyeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abab7dd3-50e4-4c63-c982-c15abf117a0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# if use colab\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2ZtMplOQv6Lz"
      },
      "outputs": [],
      "source": [
        "#if use colab\n",
        "git_dir = \"/content/IOH-Chat-App\"\n",
        "git_url = \"https://github.com/bangkit-team/IOH-chat-app.git\"\n",
        "\n",
        "if not os.path.exists(git_dir):\n",
        "  subprocess.call([\"git\", \"clone\", git_url])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pN2M4PirLEQB"
      },
      "outputs": [],
      "source": [
        "filedir1 = \"/content/IOH-chat-app/MachineLearning/datasets/translation/result/eng-ind.csv\" # #if use colab\n",
        "# filedir1 = \"../../datasets/translate sentence/result/eng-ind.csv\" #if use local env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CTSHYGqdTyPk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "5444c411-f89e-4949-a5eb-ad4f6b4499e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 English  \\\n",
              "0                                                   Run!   \n",
              "1                                                   Who?   \n",
              "2                                                   Wow!   \n",
              "3                                                  Help!   \n",
              "4                                                  Jump!   \n",
              "...                                                  ...   \n",
              "15359  Limitation of this capability causes opportuni...   \n",
              "15360  Subjective approach evaluates poverty based on...   \n",
              "15361  Limited sufficiency and food quality , seen fr...   \n",
              "15362  Around 20 percents people with the lowest inco...   \n",
              "15363  Deficiency of calory intake , namely less than...   \n",
              "\n",
              "                                               Indonesia  \n",
              "0                                                  Lari!  \n",
              "1                                                 Siapa?  \n",
              "2                                                   Wow!  \n",
              "3                                                Tolong!  \n",
              "4                                                Lompat!  \n",
              "...                                                  ...  \n",
              "15359  Keterbatasan kemampuan ini menyebabkan tertutu...  \n",
              "15360  Pendekatan subyektif menilai kemiskinan berdas...  \n",
              "15361  terbatasnya kecukupan dan mutu pangan , diliha...  \n",
              "15362  Sekitar 20 persen penduduk dengan tingkat pend...  \n",
              "15363  Kekurangan asupan kalori , yaitu kurang dari 2...  \n",
              "\n",
              "[15364 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f138b34c-2df6-41f9-ae96-79bcc6c1e1fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Indonesia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Lari!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Siapa?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Wow!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Help!</td>\n",
              "      <td>Tolong!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jump!</td>\n",
              "      <td>Lompat!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15359</th>\n",
              "      <td>Limitation of this capability causes opportuni...</td>\n",
              "      <td>Keterbatasan kemampuan ini menyebabkan tertutu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15360</th>\n",
              "      <td>Subjective approach evaluates poverty based on...</td>\n",
              "      <td>Pendekatan subyektif menilai kemiskinan berdas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15361</th>\n",
              "      <td>Limited sufficiency and food quality , seen fr...</td>\n",
              "      <td>terbatasnya kecukupan dan mutu pangan , diliha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15362</th>\n",
              "      <td>Around 20 percents people with the lowest inco...</td>\n",
              "      <td>Sekitar 20 persen penduduk dengan tingkat pend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15363</th>\n",
              "      <td>Deficiency of calory intake , namely less than...</td>\n",
              "      <td>Kekurangan asupan kalori , yaitu kurang dari 2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15364 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f138b34c-2df6-41f9-ae96-79bcc6c1e1fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f138b34c-2df6-41f9-ae96-79bcc6c1e1fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f138b34c-2df6-41f9-ae96-79bcc6c1e1fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df = pd.read_csv(filedir1)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RgUUgmronChh"
      },
      "outputs": [],
      "source": [
        "start_mark = '<start>'\n",
        "end_mark = '<end>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "KA5VqxGKtrWx"
      },
      "outputs": [],
      "source": [
        "class TranslatorDataset:\n",
        "  def __init__(self, dataframe):\n",
        "    self.dataframe = dataframe\n",
        "    self.input_tokenizer = None\n",
        "    self.target_tokenizer = None\n",
        "    self._load_data_from_file()\n",
        "\n",
        "  def _load_data_from_file(self):\n",
        "    df = self.dataframe\n",
        "\n",
        "    input_lang = df.English.values\n",
        "    target_lang = df.Indonesia.values\n",
        "\n",
        "    return input_lang, target_lang\n",
        "\n",
        "  def _normalize_and_preprocess(self, text, use_mark=False):\n",
        "    if use_mark:\n",
        "      text = text.lower().strip()\n",
        "      text = \" \".join([start_mark, text, end_mark])\n",
        "    else:\n",
        "      text = text.lower().strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "  def _tokenize(self, sentences, num_words, maxlen):\n",
        "    punctuation = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=num_words, filters=punctuation, lower=False)\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "    sequences = pad_sequences(\n",
        "      sequences, maxlen=maxlen, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "    return sequences, tokenizer\n",
        "\n",
        "  def _create_dataset(self):\n",
        "    input_lang, target_lang = self._load_data_from_file()\n",
        "\n",
        "    input_sentence = np.array(\n",
        "        list(map(lambda x: self._normalize_and_preprocess(x, False), input_lang)))\n",
        "    \n",
        "    target_sentence = np.array(\n",
        "        list(map(lambda y: self._normalize_and_preprocess(y, True), target_lang)))\n",
        "    \n",
        "    return input_sentence, target_sentence\n",
        "\n",
        "  def _load_dataset(self, num_words):\n",
        "    input_lang, target_lang = self._create_dataset()\n",
        "\n",
        "    self.maxlen = 15\n",
        "    self.buffer_size = len(input_lang)\n",
        "\n",
        "    input_sequences, input_tokenizer = self._tokenize(\n",
        "        input_lang, num_words, self.maxlen)\n",
        "    \n",
        "    target_sequences, target_tokenizer = self._tokenize(\n",
        "        target_lang, num_words, self.maxlen,)\n",
        "\n",
        "    return (input_sequences, input_tokenizer), (target_sequences, target_tokenizer)\n",
        "  \n",
        "  def get(self, num_words, batch_size):\n",
        "    input, target = self._load_dataset(num_words)\n",
        "\n",
        "    input_sequences, self.input_tokenizer = input\n",
        "    target_sequences, self.target_tokenizer = target\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((input_sequences, target_sequences))\n",
        "    dataset = dataset.shuffle(self.buffer_size).batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return self.input_tokenizer, self.target_tokenizer, dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8lYoZZjqXF__"
      },
      "outputs": [],
      "source": [
        "num_words = 15000\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "QW7fD1GdrExy"
      },
      "outputs": [],
      "source": [
        "translator_dataset = TranslatorDataset(df)\n",
        "\n",
        "input_tokenizer, target_tokenizer, dataset = translator_dataset.get(num_words, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "3lQitbaJXt4O"
      },
      "outputs": [],
      "source": [
        "input_batch, target_batch = next(iter(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "2j91LroJX50x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8218e66f-efb9-41fa-9d97-4bf23ac503e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 15]), TensorShape([64, 15]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "input_batch.shape, target_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "cI-TplUE22Tk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de0769c-fdac-4cd7-833d-e0a35de711c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 15, 12035, 13498)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "input_vocab_size = len(input_tokenizer.index_word) + 1\n",
        "target_vocab_size = len(target_tokenizer.index_word) + 1\n",
        "input_maxlen = input_batch.shape[1]\n",
        "target_maxlen = target_batch.shape[1]\n",
        "\n",
        "input_maxlen, target_maxlen, input_vocab_size, target_vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "oGqzRcEYueo4"
      },
      "outputs": [],
      "source": [
        "input_wi_json = \"input_word_index.json\"\n",
        "\n",
        "with open(input_wi_json, 'w') as f:\n",
        "    json.dump(input_tokenizer.word_index, f)\n",
        "\n",
        "# files.download(input_wi_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "cFuiAY_bu_EX"
      },
      "outputs": [],
      "source": [
        "target_wi_json = \"target_index_word.json\"\n",
        "\n",
        "with open(target_wi_json, 'w') as f:\n",
        "    json.dump(target_tokenizer.index_word, f)\n",
        "\n",
        "# files.download(target_wi_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "cPp4UAxdxemM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c093e42f-0974-493f-e719-15adc96595dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(15,), dtype=int32, numpy=\n",
              "array([   1,  299,  576,    5, 5618,    3, 4528, 1677,   22,    0,    0,\n",
              "          0,    0,    0,    0], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "input_example = input_batch[-1]\n",
        "input_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "1r5qpp8Hxjzk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e46a1d0-14a4-435d-98b5-d820e8394c58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(15,), dtype=int32, numpy=\n",
              "array([   1,  410,   15, 1257, 8775, 6047,    2,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "target_example = target_batch[-1]\n",
        "target_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ulo132GvOX0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f399fd-1e10-43ae-e35f-b2c66b0cce4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the car left a cloud of dust behind it']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "input_sentence = input_tokenizer.sequences_to_texts([input_example.numpy()])\n",
        "input_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "X59pOM0qOtyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7bbb704-9559-4932-b011-c9c836ee1b53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> mobil itu mengeluarkan asap tebal <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "target_sentence = target_tokenizer.sequences_to_texts([target_example.numpy()])\n",
        "target_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "CeQhJSGasf4P"
      },
      "outputs": [],
      "source": [
        "embed_dims = 512\n",
        "units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "fc2nYdHM0Xv0"
      },
      "outputs": [],
      "source": [
        "class Encoder():\n",
        "  def __init__(self, input_vocab_size, embedding_dims, units):\n",
        "    self.units = units\n",
        "    self.batch_size = batch_size\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "    self.embedding_dims = embedding_dims\n",
        "\n",
        "    self.embedding = layers.Embedding(self.input_vocab_size, self.embedding_dims)\n",
        "    self.lstm_layer = layers.LSTM(self.units,\n",
        "                                 return_sequences=True,\n",
        "                                 return_state=True,\n",
        "                                 recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    embedding = self.embedding(inputs)\n",
        "    encoder = self.lstm_layer(embedding)\n",
        "\n",
        "    return encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "TFONKQDzUdmw"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.w1 = layers.Dense(units, use_bias=True) \n",
        "    self.w2 = layers.Dense(units, use_bias=True) \n",
        "    self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "  def call(self, query, values):\n",
        "    w1_query = self.w1(query)\n",
        "    w2_key = self.w2(values)\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, values, w2_key],\n",
        "        return_attention_scores = True)\n",
        "\n",
        "    return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "8ayl_3A_1-IT"
      },
      "outputs": [],
      "source": [
        "class Decoder:\n",
        "  def __init__(self, output_vocab_size, embedding_dims, units):\n",
        "    self.units = units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dims = embedding_dims\n",
        "\n",
        "    self.embedding = layers.Embedding(self.output_vocab_size, self.embedding_dims)\n",
        "    self.lstm_layer = layers.LSTM(self.units,\n",
        "                                  return_sequences=True,\n",
        "                                  return_state=True,\n",
        "                                  recurrent_initializer='glorot_uniform')\n",
        "    self.attention = BahdanauAttention(self.units)\n",
        "    self.dense1 = layers.Dense(self.units, activation=tanh, use_bias=False)\n",
        "    self.dropout = layers.Dropout(.5)\n",
        "    self.dense2 = layers.TimeDistributed(layers.Dense(self.output_vocab_size))\n",
        "\n",
        "  def call(self, inputs, en_outputs, state):\n",
        "    embedding = self.embedding(inputs)\n",
        "    dec_outputs, dec_h_state, dec_c_state = self.lstm_layer(\n",
        "        embedding, initial_state=state)\n",
        "    \n",
        "    context_vector, attention_weights = self.attention(\n",
        "        query=dec_outputs, values=en_outputs)\n",
        "    \n",
        "    context_and_rnn_output = tf.concat([context_vector, dec_outputs], axis=-1)\n",
        "\n",
        "    attention_vector = self.dense1(context_and_rnn_output)\n",
        "    outputs = self.dropout(attention_vector)\n",
        "    outputs = self.dense2(outputs)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "Kio22M03Yp9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337886f4-bbcb-4127-dc38-8cb715dfdcba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 15, 1024]), TensorShape([64, 1024]), TensorShape([64, 1024]))"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "encoder = Encoder(input_vocab_size, embed_dims, units)\n",
        "\n",
        "en_outputs, en_h_state, en_c_state = encoder.call(input_batch)\n",
        "\n",
        "en_outputs.shape, en_h_state.shape, en_c_state.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "x_7A5-GTadcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d287eb54-82d2-4920-a638-b7202ca9b760"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 15, 13498])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "decoder = Decoder(target_vocab_size, embed_dims, units)\n",
        "dec_outputs= decoder.call(target_batch, en_outputs, [en_h_state, en_c_state])\n",
        "\n",
        "dec_outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "OdJEFRmxg0zW"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "epochs = 30\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=lr, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "       from_logits=True, reduction='none')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "-ifmblhR4X8i"
      },
      "outputs": [],
      "source": [
        "class TranslatorModel:\n",
        "  def __init__(self, input_vocab_size, \n",
        "               target_vocab_size, \n",
        "               embed_dims, \n",
        "               units):\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "    self.target_vocab_size = target_vocab_size\n",
        "    self.embed_dims = embed_dims\n",
        "    self.units = units\n",
        "\n",
        "    self.encoder = Encoder(\n",
        "        self.input_vocab_size, self.embed_dims, self.units)\n",
        "    \n",
        "    self.decoder = Decoder(\n",
        "        self.target_vocab_size, self.embed_dims, self.units)\n",
        "  \n",
        "  def build_model(self):\n",
        "    en_inputs = layers.Input(shape=(None,))\n",
        "\n",
        "    en_output, en_h_state, en_c_state = self.encoder.call(en_inputs)\n",
        "\n",
        "    dec_outputs = self.decoder.call(\n",
        "        en_inputs, en_output, [en_h_state, en_c_state])\n",
        "\n",
        "    model = Model(inputs=[en_inputs], \n",
        "                  outputs=[dec_outputs])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "SsTiGR8daD4K"
      },
      "outputs": [],
      "source": [
        "translator_model = TranslatorModel(\n",
        "    input_vocab_size,\n",
        "    target_vocab_size,\n",
        "    embed_dims,\n",
        "    units,\n",
        ")\n",
        "model = translator_model.build_model()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "VOUD1xKgIDH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e39ba23c-a0f9-4da3-dcd5-35b45b89675d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_25 (Embedding)       (None, None, 512)    6161920     ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_26 (Embedding)       (None, None, 512)    6910976     ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_25 (LSTM)                 [(None, None, 1024)  6295552     ['embedding_25[0][0]']           \n",
            "                                , (None, 1024),                                                   \n",
            "                                 (None, 1024)]                                                    \n",
            "                                                                                                  \n",
            " lstm_26 (LSTM)                 [(None, None, 1024)  6295552     ['embedding_26[0][0]',           \n",
            "                                , (None, 1024),                   'lstm_25[0][1]',                \n",
            "                                 (None, 1024)]                    'lstm_25[0][2]']                \n",
            "                                                                                                  \n",
            " bahdanau_attention_14 (Bahdana  ((None, None, 1024)  2100224    ['lstm_26[0][0]',                \n",
            " uAttention)                    , (None, None, None               'lstm_25[0][0]']                \n",
            "                                ))                                                                \n",
            "                                                                                                  \n",
            " tf.concat_2 (TFOpLambda)       (None, None, 2048)   0           ['bahdanau_attention_14[0][0]',  \n",
            "                                                                  'lstm_26[0][0]']                \n",
            "                                                                                                  \n",
            " dense_58 (Dense)               (None, None, 1024)   2097152     ['tf.concat_2[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, None, 1024)   0           ['dense_58[0][0]']               \n",
            "                                                                                                  \n",
            " time_distributed_14 (TimeDistr  (None, None, 13498)  13835450   ['dropout_14[0][0]']             \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 43,696,826\n",
            "Trainable params: 43,696,826\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = \"checkpoint/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "callback_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='loss',\n",
        "    patience=3, \n",
        "    verbose=1)\n",
        "\n",
        "callback_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    monitor='loss', \n",
        "    verbose=1, \n",
        "    save_weights_only=True, \n",
        "    save_best_only=True)\n",
        "\n",
        "callbacks = [callback_early_stopping,\n",
        "             callback_checkpoint]\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "daAENyOqwdjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a401d2-8ae2-4f83-834f-54056a55e5cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 4.4966 - accuracy: 0.3949\n",
            "Epoch 1: loss improved from inf to 4.49656, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 24s 91ms/step - loss: 4.4966 - accuracy: 0.3949\n",
            "Epoch 2/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 3.9223 - accuracy: 0.4318\n",
            "Epoch 2: loss improved from 4.49656 to 3.92235, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 91ms/step - loss: 3.9223 - accuracy: 0.4318\n",
            "Epoch 3/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 3.6185 - accuracy: 0.4558\n",
            "Epoch 3: loss improved from 3.92235 to 3.61854, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 92ms/step - loss: 3.6185 - accuracy: 0.4558\n",
            "Epoch 4/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 3.3660 - accuracy: 0.4753\n",
            "Epoch 4: loss improved from 3.61854 to 3.36603, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 90ms/step - loss: 3.3660 - accuracy: 0.4753\n",
            "Epoch 5/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 3.1346 - accuracy: 0.4948\n",
            "Epoch 5: loss improved from 3.36603 to 3.13464, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 21s 89ms/step - loss: 3.1346 - accuracy: 0.4948\n",
            "Epoch 6/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 2.9094 - accuracy: 0.5137\n",
            "Epoch 6: loss improved from 3.13464 to 2.90938, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 92ms/step - loss: 2.9094 - accuracy: 0.5137\n",
            "Epoch 7/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 2.6882 - accuracy: 0.5337\n",
            "Epoch 7: loss improved from 2.90938 to 2.68816, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 91ms/step - loss: 2.6882 - accuracy: 0.5337\n",
            "Epoch 8/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 2.4650 - accuracy: 0.5549\n",
            "Epoch 8: loss improved from 2.68816 to 2.46505, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 21s 89ms/step - loss: 2.4650 - accuracy: 0.5549\n",
            "Epoch 9/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 2.2289 - accuracy: 0.5808\n",
            "Epoch 9: loss improved from 2.46505 to 2.22887, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 21s 89ms/step - loss: 2.2289 - accuracy: 0.5808\n",
            "Epoch 10/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 1.9844 - accuracy: 0.6107\n",
            "Epoch 10: loss improved from 2.22887 to 1.98436, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 92ms/step - loss: 1.9844 - accuracy: 0.6107\n",
            "Epoch 11/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 1.7401 - accuracy: 0.6446\n",
            "Epoch 11: loss improved from 1.98436 to 1.74012, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 91ms/step - loss: 1.7401 - accuracy: 0.6446\n",
            "Epoch 12/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 1.5055 - accuracy: 0.6779\n",
            "Epoch 12: loss improved from 1.74012 to 1.50548, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 21s 89ms/step - loss: 1.5055 - accuracy: 0.6779\n",
            "Epoch 13/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 1.2917 - accuracy: 0.7140\n",
            "Epoch 13: loss improved from 1.50548 to 1.29173, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 91ms/step - loss: 1.2917 - accuracy: 0.7140\n",
            "Epoch 14/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 1.1093 - accuracy: 0.7466\n",
            "Epoch 14: loss improved from 1.29173 to 1.10934, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 91ms/step - loss: 1.1093 - accuracy: 0.7466\n",
            "Epoch 15/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.9470 - accuracy: 0.7775\n",
            "Epoch 15: loss improved from 1.10934 to 0.94701, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 21s 89ms/step - loss: 0.9470 - accuracy: 0.7775\n",
            "Epoch 16/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.8099 - accuracy: 0.8074\n",
            "Epoch 16: loss improved from 0.94701 to 0.80986, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 92ms/step - loss: 0.8099 - accuracy: 0.8074\n",
            "Epoch 17/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.8325\n",
            "Epoch 17: loss improved from 0.80986 to 0.69406, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 90ms/step - loss: 0.6941 - accuracy: 0.8325\n",
            "Epoch 18/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.5981 - accuracy: 0.8548\n",
            "Epoch 18: loss improved from 0.69406 to 0.59809, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 92ms/step - loss: 0.5981 - accuracy: 0.8548\n",
            "Epoch 19/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.5175 - accuracy: 0.8732\n",
            "Epoch 19: loss improved from 0.59809 to 0.51749, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 91ms/step - loss: 0.5175 - accuracy: 0.8732\n",
            "Epoch 20/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.8898\n",
            "Epoch 20: loss improved from 0.51749 to 0.45106, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 21s 89ms/step - loss: 0.4511 - accuracy: 0.8898\n",
            "Epoch 21/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.3953 - accuracy: 0.9017\n",
            "Epoch 21: loss improved from 0.45106 to 0.39528, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 21s 89ms/step - loss: 0.3953 - accuracy: 0.9017\n",
            "Epoch 22/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.9147\n",
            "Epoch 22: loss improved from 0.39528 to 0.34806, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 90ms/step - loss: 0.3481 - accuracy: 0.9147\n",
            "Epoch 23/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.3119 - accuracy: 0.9235\n",
            "Epoch 23: loss improved from 0.34806 to 0.31190, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 90ms/step - loss: 0.3119 - accuracy: 0.9235\n",
            "Epoch 24/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.2798 - accuracy: 0.9323\n",
            "Epoch 24: loss improved from 0.31190 to 0.27985, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 90ms/step - loss: 0.2798 - accuracy: 0.9323\n",
            "Epoch 25/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.2530 - accuracy: 0.9391\n",
            "Epoch 25: loss improved from 0.27985 to 0.25298, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 90ms/step - loss: 0.2530 - accuracy: 0.9391\n",
            "Epoch 26/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.9457\n",
            "Epoch 26: loss improved from 0.25298 to 0.22946, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 90ms/step - loss: 0.2295 - accuracy: 0.9457\n",
            "Epoch 27/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.2086 - accuracy: 0.9515\n",
            "Epoch 27: loss improved from 0.22946 to 0.20864, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 93ms/step - loss: 0.2086 - accuracy: 0.9515\n",
            "Epoch 28/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.1924 - accuracy: 0.9556\n",
            "Epoch 28: loss improved from 0.20864 to 0.19245, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 21s 89ms/step - loss: 0.1924 - accuracy: 0.9556\n",
            "Epoch 29/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.1831 - accuracy: 0.9582\n",
            "Epoch 29: loss improved from 0.19245 to 0.18313, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 92ms/step - loss: 0.1831 - accuracy: 0.9582\n",
            "Epoch 30/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.1708 - accuracy: 0.9615\n",
            "Epoch 30: loss improved from 0.18313 to 0.17085, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 22s 91ms/step - loss: 0.1708 - accuracy: 0.9615\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa84d9b7490>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "model.fit(dataset,\n",
        "          epochs=epochs,\n",
        "          callbacks=callbacks,\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "0QGxWYuiQPnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f992c9d-627e-42eb-c296-40d742ef5ec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_31_layer_call_fn, lstm_cell_31_layer_call_and_return_conditional_losses, lstm_cell_32_layer_call_fn, lstm_cell_32_layer_call_and_return_conditional_losses, dense_56_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Company Case Bangkit/TranslationModel/saved_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Company Case Bangkit/TranslationModel/saved_model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fa84e1b3410> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fa84e184150> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "# if use colab\n",
        "saved_model_path = \"/content/drive/MyDrive/Company Case Bangkit/TranslationModel/saved_model\"\n",
        "\n",
        "# if use local env\n",
        "# saved_model_path = \"code/translate sentence/saved_model\"\n",
        "saved_model_dir = os.path.dirname(saved_model_path)\n",
        "\n",
        "if os.path.exists(saved_model_dir):\n",
        "  shutil.rmtree(saved_model_dir)\n",
        "  \n",
        "model.save(saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "FFpBRO4W31YA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6b1f96-4ec6-4594-9dbc-680ade8bfae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_31_layer_call_fn, lstm_cell_31_layer_call_and_return_conditional_losses, lstm_cell_32_layer_call_fn, lstm_cell_32_layer_call_and_return_conditional_losses, dense_56_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmps3bs_m_n/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmps3bs_m_n/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43832016"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS\n",
        "]\n",
        "converter.experimental_new_converter = True\n",
        "converter.allow_custom_ops = True\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_model_file = pathlib.Path('translation.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "NkJJXewBdV2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d2fd551-a548-4671-b17a-7e2f437c4e73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([{'dtype': numpy.float32,\n",
              "   'index': 0,\n",
              "   'name': 'serving_default_input_6:0',\n",
              "   'quantization': (0.0, 0),\n",
              "   'quantization_parameters': {'quantized_dimension': 0,\n",
              "    'scales': array([], dtype=float32),\n",
              "    'zero_points': array([], dtype=int32)},\n",
              "   'shape': array([1, 1], dtype=int32),\n",
              "   'shape_signature': array([-1, -1], dtype=int32),\n",
              "   'sparsity_parameters': {}}],\n",
              " [{'dtype': numpy.float32,\n",
              "   'index': 110,\n",
              "   'name': 'StatefulPartitionedCall:0',\n",
              "   'quantization': (0.0, 0),\n",
              "   'quantization_parameters': {'quantized_dimension': 0,\n",
              "    'scales': array([], dtype=float32),\n",
              "    'zero_points': array([], dtype=int32)},\n",
              "   'shape': array([    1,     1, 13498], dtype=int32),\n",
              "   'shape_signature': array([   -1,    -1, 13498], dtype=int32),\n",
              "   'sparsity_parameters': {}}])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "interpreter = tf.lite.Interpreter(\"translation.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_details, output_details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "1YmcvYUyzqLd"
      },
      "outputs": [],
      "source": [
        "class Translator:\n",
        "  def __init__(self, model_path, input_word_index, target_index_word, maxlen):\n",
        "    self.input_word_index = input_word_index\n",
        "    self.target_index_word = target_index_word\n",
        "    self.maxlen = maxlen\n",
        "    self.model_path = model_path\n",
        "\n",
        "    self._load_model()\n",
        "    self._load_vocab()\n",
        "\n",
        "  def _load_model(self):\n",
        "    self.model = tf.keras.models.load_model(self.model_path, compile=True)\n",
        "  \n",
        "  def _load_vocab(self):\n",
        "    with open(self.input_word_index) as f:\n",
        "      self.input_vocab = json.load(f)\n",
        "    \n",
        "    with open(self.target_index_word) as f:\n",
        "      vocab = json.load(f)\n",
        "      self.target_vocab = {int(k):v for k,v in vocab.items()}\n",
        "      \n",
        "  def _normalize_and_preprocess(self, text):\n",
        "    punctuation = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        "    \n",
        "    text = text.lower().strip()\n",
        "    text = \"\".join((filter(lambda x: x not in punctuation, text)))\n",
        "\n",
        "    return text\n",
        "\n",
        "  def _texts_to_sequences(self, text):\n",
        "    words = text.split(\" \")\n",
        "    sequences = list()\n",
        "\n",
        "    for word in words:\n",
        "      if word in self.input_vocab.keys():\n",
        "        token = self.input_vocab[word]\n",
        "        sequences.append(token)\n",
        "\n",
        "    return sequences\n",
        "\n",
        "  def _sequences_to_texts(self, sequences):\n",
        "    words = list()\n",
        "\n",
        "    for token in sequences:\n",
        "      if token in self.target_vocab.keys():\n",
        "        word = self.target_vocab[token]\n",
        "        words.append(word)    \n",
        "\n",
        "    return words  \n",
        "\n",
        "  def lang_detector(self, sentence):\n",
        "    return detect(sentence)\n",
        "    \n",
        "  def translate(self, sentence):\n",
        "    index_prediction = list()\n",
        "    normalize_sentence = self._normalize_and_preprocess(sentence)\n",
        "    \n",
        "    sequences = self._texts_to_sequences(normalize_sentence)\n",
        "    sequences = pad_sequences(\n",
        "        [sequences], maxlen=self.maxlen, padding=\"post\", truncating=\"post\")\n",
        "    \n",
        "    predictions = self.model(sequences)\n",
        "\n",
        "    for i in predictions[0]:\n",
        "      index_prediction.append(np.argmax(i))\n",
        "\n",
        "    marks = [start_mark, end_mark]\n",
        "    result = self._sequences_to_texts(index_prediction)\n",
        "\n",
        "    result = \" \".join([word for word in result if word not in marks])\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "NkNd7WY3LSvJ"
      },
      "outputs": [],
      "source": [
        "input_wi = \"/content/input_word_index.json\"\n",
        "target_iw = \"/content/target_index_word.json\"\n",
        "\n",
        "translator = Translator(\n",
        "    saved_model_path,\n",
        "    input_wi, \n",
        "    target_iw,\n",
        "    15,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "gLjLFWVdFCCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d09385e0-cc59-40c0-c627-405f4d8d50b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dia menanggalkannya\n"
          ]
        }
      ],
      "source": [
        "text_input = \"She took it off.\"\n",
        "lang_detector = translator.lang_detector(text_input)\n",
        "\n",
        "if lang_detector == \"en\":\n",
        "  translate = translator.translate(text_input)\n",
        "  print(translate)\n",
        "else:\n",
        "  print(\"Bahasa tidak dikenali\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "translator.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "765233bfe060b87a8be23ec8f17030d468ac6435ae34b0ad14370b4cb734ac81"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}