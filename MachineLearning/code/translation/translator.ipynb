{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "56aTseK4q9ol"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import subprocess\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import pathlib\n",
        "\n",
        "from textblob import TextBlob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive, files #if use colab\n",
        "from tensorflow.nn import relu, tanh, softmax\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.lite.python import interpreter\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tz4aY7oDbyeg"
      },
      "outputs": [],
      "source": [
        "# # if use colab\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2ZtMplOQv6Lz"
      },
      "outputs": [],
      "source": [
        "#if use colab\n",
        "git_dir = \"/content/IOH-Chat-App\"\n",
        "git_url = \"https://github.com/bangkit-team/IOH-chat-app.git\"\n",
        "\n",
        "if not os.path.exists(git_dir):\n",
        "  subprocess.call([\"git\", \"clone\", git_url])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pN2M4PirLEQB"
      },
      "outputs": [],
      "source": [
        "filedir1 = \"/content/IOH-chat-app/MachineLearning/datasets/translation/result/eng-ind.csv\" # #if use colab\n",
        "# filedir1 = \"../../datasets/translate sentence/result/eng-ind.csv\" #if use local env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CTSHYGqdTyPk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "aa9764f1-f2e0-42f3-adfa-0a0852faa74e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 English  \\\n",
              "0                                                   Run!   \n",
              "1                                                   Who?   \n",
              "2                                                   Wow!   \n",
              "3                                                  Help!   \n",
              "4                                                  Jump!   \n",
              "...                                                  ...   \n",
              "15359  Limitation of this capability causes opportuni...   \n",
              "15360  Subjective approach evaluates poverty based on...   \n",
              "15361  Limited sufficiency and food quality , seen fr...   \n",
              "15362  Around 20 percents people with the lowest inco...   \n",
              "15363  Deficiency of calory intake , namely less than...   \n",
              "\n",
              "                                               Indonesia  \n",
              "0                                                  Lari!  \n",
              "1                                                 Siapa?  \n",
              "2                                                   Wow!  \n",
              "3                                                Tolong!  \n",
              "4                                                Lompat!  \n",
              "...                                                  ...  \n",
              "15359  Keterbatasan kemampuan ini menyebabkan tertutu...  \n",
              "15360  Pendekatan subyektif menilai kemiskinan berdas...  \n",
              "15361  terbatasnya kecukupan dan mutu pangan , diliha...  \n",
              "15362  Sekitar 20 persen penduduk dengan tingkat pend...  \n",
              "15363  Kekurangan asupan kalori , yaitu kurang dari 2...  \n",
              "\n",
              "[15364 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e480402b-fb59-47f3-8ec7-8729e71d2ca0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Indonesia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Lari!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Siapa?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Wow!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Help!</td>\n",
              "      <td>Tolong!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jump!</td>\n",
              "      <td>Lompat!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15359</th>\n",
              "      <td>Limitation of this capability causes opportuni...</td>\n",
              "      <td>Keterbatasan kemampuan ini menyebabkan tertutu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15360</th>\n",
              "      <td>Subjective approach evaluates poverty based on...</td>\n",
              "      <td>Pendekatan subyektif menilai kemiskinan berdas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15361</th>\n",
              "      <td>Limited sufficiency and food quality , seen fr...</td>\n",
              "      <td>terbatasnya kecukupan dan mutu pangan , diliha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15362</th>\n",
              "      <td>Around 20 percents people with the lowest inco...</td>\n",
              "      <td>Sekitar 20 persen penduduk dengan tingkat pend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15363</th>\n",
              "      <td>Deficiency of calory intake , namely less than...</td>\n",
              "      <td>Kekurangan asupan kalori , yaitu kurang dari 2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15364 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e480402b-fb59-47f3-8ec7-8729e71d2ca0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e480402b-fb59-47f3-8ec7-8729e71d2ca0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e480402b-fb59-47f3-8ec7-8729e71d2ca0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = pd.read_csv(filedir1)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RgUUgmronChh"
      },
      "outputs": [],
      "source": [
        "start_mark = '<start>'\n",
        "end_mark = '<end>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KA5VqxGKtrWx"
      },
      "outputs": [],
      "source": [
        "class TranslatorDataset:\n",
        "  def __init__(self, dataframe):\n",
        "    self.dataframe = dataframe\n",
        "    self.input_tokenizer = None\n",
        "    self.target_tokenizer = None\n",
        "    self._load_data_from_file()\n",
        "\n",
        "  def _load_data_from_file(self):\n",
        "    df = self.dataframe\n",
        "\n",
        "    input_lang = df.English.values\n",
        "    target_lang = df.Indonesia.values\n",
        "\n",
        "    return input_lang, target_lang\n",
        "\n",
        "  def _normalize_and_preprocess(self, text, use_mark=False):\n",
        "    if use_mark:\n",
        "      text = text.lower().strip()\n",
        "      text = \" \".join([start_mark, text, end_mark])\n",
        "    else:\n",
        "      text = text.lower().strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "  def _tokenize(self, sentences, num_words, maxlen):\n",
        "    punctuation = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=num_words, filters=punctuation, lower=False)\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "    sequences = pad_sequences(\n",
        "      sequences, maxlen=maxlen, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "    return sequences, tokenizer\n",
        "\n",
        "  def _create_dataset(self):\n",
        "    input_lang, target_lang = self._load_data_from_file()\n",
        "\n",
        "    input_sentence = np.array(\n",
        "        list(map(lambda x: self._normalize_and_preprocess(x, False), input_lang)))\n",
        "    \n",
        "    target_sentence = np.array(\n",
        "        list(map(lambda y: self._normalize_and_preprocess(y, True), target_lang)))\n",
        "    \n",
        "    return input_sentence, target_sentence\n",
        "\n",
        "  def _load_dataset(self, num_words):\n",
        "    input_lang, target_lang = self._create_dataset()\n",
        "\n",
        "    self.maxlen = max([len(i)for i in input_lang]) // 5\n",
        "    self.buffer_size = len(input_lang)\n",
        "\n",
        "    input_sequences, input_tokenizer = self._tokenize(\n",
        "        input_lang, num_words, self.maxlen)\n",
        "    \n",
        "    target_sequences, target_tokenizer = self._tokenize(\n",
        "        target_lang, num_words, self.maxlen,)\n",
        "\n",
        "    return (input_sequences, input_tokenizer), (target_sequences, target_tokenizer)\n",
        "  \n",
        "  def get(self, num_words, batch_size):\n",
        "    input, target = self._load_dataset(num_words)\n",
        "\n",
        "    input_sequences, self.input_tokenizer = input\n",
        "    target_sequences, self.target_tokenizer = target\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((input_sequences, target_sequences))\n",
        "    dataset = dataset.shuffle(self.buffer_size).batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return self.input_tokenizer, self.target_tokenizer, dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8lYoZZjqXF__"
      },
      "outputs": [],
      "source": [
        "num_words = 15000\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QW7fD1GdrExy"
      },
      "outputs": [],
      "source": [
        "translator_dataset = TranslatorDataset(df)\n",
        "\n",
        "input_tokenizer, target_tokenizer, dataset = translator_dataset.get(num_words, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3lQitbaJXt4O"
      },
      "outputs": [],
      "source": [
        "input_batch, target_batch = next(iter(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2j91LroJX50x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef9c1366-3063-4bea-aa01-a56dec2ee8fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 112]), TensorShape([64, 112]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "input_batch.shape, target_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cI-TplUE22Tk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b86c00-19d8-480c-ccc7-5a1a423c56f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112, 112, 12035, 13498)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "input_vocab_size = len(input_tokenizer.index_word) + 1\n",
        "target_vocab_size = len(target_tokenizer.index_word) + 1\n",
        "input_maxlen = input_batch.shape[1]\n",
        "target_maxlen = target_batch.shape[1]\n",
        "\n",
        "input_maxlen, target_maxlen, input_vocab_size, target_vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oGqzRcEYueo4"
      },
      "outputs": [],
      "source": [
        "input_wi_json = \"input_word_index.json\"\n",
        "\n",
        "with open(input_wi_json, 'w') as f:\n",
        "    json.dump(input_tokenizer.word_index, f)\n",
        "\n",
        "# files.download(input_wi_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cFuiAY_bu_EX"
      },
      "outputs": [],
      "source": [
        "target_wi_json = \"target_index_word.json\"\n",
        "\n",
        "with open(target_wi_json, 'w') as f:\n",
        "    json.dump(target_tokenizer.index_word, f)\n",
        "\n",
        "# files.download(target_wi_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cPp4UAxdxemM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "457ebbbf-5c9e-4fef-b0d3-74b49e7f1803"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(112,), dtype=int32, numpy=\n",
              "array([  74, 1240,    3, 7767,  465,  579,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "input_example = input_batch[-1]\n",
        "input_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r5qpp8Hxjzk",
        "outputId": "0c1d784f-ad6e-47df-9a07-b6a1ddf81c48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(112,), dtype=int32, numpy=\n",
              "array([   1,  108,  108,    7,   14, 1986,    9,  303,    2,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "target_example = target_batch[-1]\n",
        "target_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulo132GvOX0l",
        "outputId": "eddb54d8-7c69-482c-e2e5-2f31608ff1d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"i'm sick of conferences these days\"]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "input_sentence = input_tokenizer.sequences_to_texts([input_example.numpy()])\n",
        "input_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X59pOM0qOtyb",
        "outputId": "665067ff-e25e-4fca-fdc7-4629ffefdcb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> akhir akhir ini aku bosan dengan rapat <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "target_sentence = target_tokenizer.sequences_to_texts([target_example.numpy()])\n",
        "target_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CeQhJSGasf4P"
      },
      "outputs": [],
      "source": [
        "embed_dims = 256\n",
        "units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fc2nYdHM0Xv0"
      },
      "outputs": [],
      "source": [
        "class Encoder():\n",
        "  def __init__(self, input_vocab_size, embedding_dims, units, batch_size):\n",
        "    self.units = units\n",
        "    self.batch_size = batch_size\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "    self.embedding_dims = embedding_dims\n",
        "\n",
        "    self.embedding = layers.Embedding(self.input_vocab_size, self.embedding_dims)\n",
        "    self.lstm_layer = layers.LSTM(self.units,\n",
        "                                 return_sequences=True,\n",
        "                                 return_state=True,\n",
        "                                 recurrent_initializer='glorot_uniform')\n",
        "    \n",
        "  def initialize_hidden_state(self):\n",
        "    return [tf.zeros((self.batch_size, self.units)), tf.zeros((self.batch_size, self.units))]\n",
        "\n",
        "  def call(self, inputs, hidden):\n",
        "    embedding = self.embedding(inputs)\n",
        "    encoder = self.lstm_layer(embedding, initial_state=hidden)\n",
        "\n",
        "    return encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TFONKQDzUdmw"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.w1 = layers.Dense(units, use_bias=True) \n",
        "    self.w2 = layers.Dense(units, use_bias=True) \n",
        "    self.fd = layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "    \n",
        "    score = self.fd(tf.nn.tanh(\n",
        "        self.w1(query_with_time_axis) + self.w2(values)))\n",
        "\n",
        "    attention_weights = softmax(score, axis=1)\n",
        "\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8ayl_3A_1-IT"
      },
      "outputs": [],
      "source": [
        "class Decoder:\n",
        "  def __init__(self, output_vocab_size, embedding_dims, units):\n",
        "    self.units = units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dims = embedding_dims\n",
        "\n",
        "    self.embedding = layers.Embedding(self.output_vocab_size, self.embedding_dims)\n",
        "    self.lstm_layer = layers.LSTM(self.units,\n",
        "                                  return_sequences=True,\n",
        "                                  return_state=True,\n",
        "                                  recurrent_initializer='glorot_uniform')\n",
        "    self.attention = BahdanauAttention(self.units)\n",
        "    self.dense1 = layers.Dense(self.units, activation=tanh)\n",
        "    self.dropout = layers.Dropout(.5)\n",
        "    self.dense2 = layers.Dense(self.output_vocab_size)\n",
        "\n",
        "  def call(self, inputs, en_outputs, state):\n",
        "    embedding = self.embedding(inputs)\n",
        "    dec_outputs, dec_h_state, dec_c_state = self.lstm_layer(\n",
        "        embedding, initial_state=state)\n",
        "    \n",
        "    context_vector, attention_weights = self.attention(\n",
        "        query=dec_outputs, values=en_outputs)\n",
        "    \n",
        "    context_and_rnn_output = tf.concat([context_vector, dec_outputs], axis=-1)\n",
        "\n",
        "    attention_vector = self.dense1(context_and_rnn_output)\n",
        "    outputs = self.dropout(attention_vector)\n",
        "    outputs = self.dense2(outputs)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kio22M03Yp9S",
        "outputId": "84b11e52-6788-4858-c3fc-fde16124359a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 112, 1024]),\n",
              " TensorShape([64, 1024]),\n",
              " TensorShape([64, 1024]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "encoder = Encoder(input_vocab_size, embed_dims, units, batch_size)\n",
        "\n",
        "sample_en_hidden = encoder.initialize_hidden_state()\n",
        "en_outputs, en_h_state, en_c_state = encoder.call(input_batch, sample_en_hidden)\n",
        "\n",
        "en_outputs.shape, en_h_state.shape, en_c_state.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "x_7A5-GTadcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43bdb11f-0509-41ff-cc50-7bb9606405f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 112, 13498])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "decoder = Decoder(target_vocab_size, embed_dims, units)\n",
        "dec_outputs= decoder.call(target_batch, en_outputs, [en_h_state, en_c_state])\n",
        "\n",
        "dec_outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OdJEFRmxg0zW"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "epochs = 30\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=lr, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "       from_logits=True, reduction='none')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-ifmblhR4X8i"
      },
      "outputs": [],
      "source": [
        "class TranslatorModel:\n",
        "  def __init__(self, input_vocab_size, \n",
        "               target_vocab_size, \n",
        "               embed_dims, \n",
        "               units, \n",
        "               batch_size):\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "    self.target_vocab_size = target_vocab_size\n",
        "    self.embed_dims = embed_dims\n",
        "    self.units = units\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    self.encoder = Encoder(\n",
        "        self.input_vocab_size, self.embed_dims, self.units, self.batch_size)\n",
        "    \n",
        "    self.decoder = Decoder(\n",
        "        self.target_vocab_size, self.embed_dims, self.units)\n",
        "  \n",
        "  def build_model(self):\n",
        "    en_inputs = layers.Input(shape=(None,))\n",
        "\n",
        "    en_hidden = self.encoder.initialize_hidden_state()\n",
        "    en_output, en_h_state, en_c_state = self.encoder.call(en_inputs, en_hidden)\n",
        "\n",
        "    dec_outputs = self.decoder.call(en_inputs, en_output, [en_h_state, en_c_state])\n",
        "\n",
        "    model = Model(inputs=[en_inputs], \n",
        "                  outputs=[dec_outputs])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "SsTiGR8daD4K"
      },
      "outputs": [],
      "source": [
        "translator_model = TranslatorModel(\n",
        "    input_vocab_size,\n",
        "    target_vocab_size,\n",
        "    embed_dims,\n",
        "    units,\n",
        "    batch_size\n",
        ")\n",
        "model = translator_model.build_model()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOUD1xKgIDH3",
        "outputId": "6ddb0829-d8cc-4f1f-8cd0-4d9be8dc06a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, None, 256)    3080960     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 256)    3455488     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(64, None, 1024),   5246976     ['embedding_2[0][0]']            \n",
            "                                 (64, 1024),                                                      \n",
            "                                 (64, 1024)]                                                      \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(64, None, 1024),   5246976     ['embedding_3[0][0]',            \n",
            "                                 (64, 1024),                      'lstm_2[0][1]',                 \n",
            "                                 (64, 1024)]                      'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " bahdanau_attention_1 (Bahdanau  ((64, None, 1024),  2100225     ['lstm_3[0][0]',                 \n",
            " Attention)                      (64, 64, None, 1))               'lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (64, None, 2048)     0           ['bahdanau_attention_1[0][0]',   \n",
            "                                                                  'lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (64, None, 1024)     2098176     ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (64, None, 1024)     0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (64, None, 13498)    13835450    ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 35,064,251\n",
            "Trainable params: 35,064,251\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = \"checkpoint/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "callback_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='loss',\n",
        "    patience=3, \n",
        "    verbose=1)\n",
        "\n",
        "callback_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    monitor='loss', \n",
        "    verbose=1, \n",
        "    save_weights_only=True, \n",
        "    save_best_only=True)\n",
        "\n",
        "callbacks = [callback_early_stopping,\n",
        "             callback_checkpoint]\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daAENyOqwdjZ",
        "outputId": "1fcb8d4b-ae3f-47db-dcb9-433b8119e8fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 1.0797 - accuracy: 0.8711\n",
            "Epoch 1: loss improved from inf to 1.07971, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 162s 661ms/step - loss: 1.0797 - accuracy: 0.8711\n",
            "Epoch 2/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.9041 - accuracy: 0.8775\n",
            "Epoch 2: loss improved from 1.07971 to 0.90412, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 159s 664ms/step - loss: 0.9041 - accuracy: 0.8775\n",
            "Epoch 3/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.8569 - accuracy: 0.8799\n",
            "Epoch 3: loss improved from 0.90412 to 0.85695, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 159s 663ms/step - loss: 0.8569 - accuracy: 0.8799\n",
            "Epoch 4/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.8221 - accuracy: 0.8818\n",
            "Epoch 4: loss improved from 0.85695 to 0.82206, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 664ms/step - loss: 0.8221 - accuracy: 0.8818\n",
            "Epoch 5/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.7923 - accuracy: 0.8838\n",
            "Epoch 5: loss improved from 0.82206 to 0.79225, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 159s 664ms/step - loss: 0.7923 - accuracy: 0.8838\n",
            "Epoch 6/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.7659 - accuracy: 0.8856\n",
            "Epoch 6: loss improved from 0.79225 to 0.76591, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 665ms/step - loss: 0.7659 - accuracy: 0.8856\n",
            "Epoch 7/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.7393 - accuracy: 0.8873\n",
            "Epoch 7: loss improved from 0.76591 to 0.73932, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 665ms/step - loss: 0.7393 - accuracy: 0.8873\n",
            "Epoch 8/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.7133 - accuracy: 0.8889\n",
            "Epoch 8: loss improved from 0.73932 to 0.71330, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 665ms/step - loss: 0.7133 - accuracy: 0.8889\n",
            "Epoch 9/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.6899 - accuracy: 0.8906\n",
            "Epoch 9: loss improved from 0.71330 to 0.68990, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 159s 664ms/step - loss: 0.6899 - accuracy: 0.8906\n",
            "Epoch 10/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.6636 - accuracy: 0.8925\n",
            "Epoch 10: loss improved from 0.68990 to 0.66357, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 665ms/step - loss: 0.6636 - accuracy: 0.8925\n",
            "Epoch 11/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.8947\n",
            "Epoch 11: loss improved from 0.66357 to 0.63584, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 665ms/step - loss: 0.6358 - accuracy: 0.8947\n",
            "Epoch 12/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.6085 - accuracy: 0.8969\n",
            "Epoch 12: loss improved from 0.63584 to 0.60852, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 666ms/step - loss: 0.6085 - accuracy: 0.8969\n",
            "Epoch 13/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.5791 - accuracy: 0.8995\n",
            "Epoch 13: loss improved from 0.60852 to 0.57908, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 668ms/step - loss: 0.5791 - accuracy: 0.8995\n",
            "Epoch 14/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.5498 - accuracy: 0.9024\n",
            "Epoch 14: loss improved from 0.57908 to 0.54977, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 665ms/step - loss: 0.5498 - accuracy: 0.9024\n",
            "Epoch 15/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.5142 - accuracy: 0.9062\n",
            "Epoch 15: loss improved from 0.54977 to 0.51422, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 666ms/step - loss: 0.5142 - accuracy: 0.9062\n",
            "Epoch 16/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.4812 - accuracy: 0.9099\n",
            "Epoch 16: loss improved from 0.51422 to 0.48121, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 666ms/step - loss: 0.4812 - accuracy: 0.9099\n",
            "Epoch 17/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.9140\n",
            "Epoch 17: loss improved from 0.48121 to 0.44707, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 666ms/step - loss: 0.4471 - accuracy: 0.9140\n",
            "Epoch 18/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.9182\n",
            "Epoch 18: loss improved from 0.44707 to 0.41354, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 665ms/step - loss: 0.4135 - accuracy: 0.9182\n",
            "Epoch 19/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.9229\n",
            "Epoch 19: loss improved from 0.41354 to 0.38043, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 665ms/step - loss: 0.3804 - accuracy: 0.9229\n",
            "Epoch 20/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.9272\n",
            "Epoch 20: loss improved from 0.38043 to 0.35046, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 665ms/step - loss: 0.3505 - accuracy: 0.9272\n",
            "Epoch 21/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.3192 - accuracy: 0.9320\n",
            "Epoch 21: loss improved from 0.35046 to 0.31918, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 665ms/step - loss: 0.3192 - accuracy: 0.9320\n",
            "Epoch 22/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.2906 - accuracy: 0.9367\n",
            "Epoch 22: loss improved from 0.31918 to 0.29062, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 667ms/step - loss: 0.2906 - accuracy: 0.9367\n",
            "Epoch 23/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.2644 - accuracy: 0.9411\n",
            "Epoch 23: loss improved from 0.29062 to 0.26439, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 666ms/step - loss: 0.2644 - accuracy: 0.9411\n",
            "Epoch 24/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.2406 - accuracy: 0.9455\n",
            "Epoch 24: loss improved from 0.26439 to 0.24060, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 667ms/step - loss: 0.2406 - accuracy: 0.9455\n",
            "Epoch 25/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.2174 - accuracy: 0.9496\n",
            "Epoch 25: loss improved from 0.24060 to 0.21742, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 666ms/step - loss: 0.2174 - accuracy: 0.9496\n",
            "Epoch 26/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.1959 - accuracy: 0.9540\n",
            "Epoch 26: loss improved from 0.21742 to 0.19586, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 667ms/step - loss: 0.1959 - accuracy: 0.9540\n",
            "Epoch 27/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.9579\n",
            "Epoch 27: loss improved from 0.19586 to 0.17641, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 666ms/step - loss: 0.1764 - accuracy: 0.9579\n",
            "Epoch 28/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.1588 - accuracy: 0.9617\n",
            "Epoch 28: loss improved from 0.17641 to 0.15877, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 667ms/step - loss: 0.1588 - accuracy: 0.9617\n",
            "Epoch 29/30\n",
            "240/240 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 0.9654\n",
            "Epoch 29: loss improved from 0.15877 to 0.14183, saving model to checkpoint/cp.ckpt\n",
            "240/240 [==============================] - 160s 667ms/step - loss: 0.1418 - accuracy: 0.9654\n",
            "Epoch 30/30\n",
            " 83/240 [=========>....................] - ETA: 1:43 - loss: 0.1376 - accuracy: 0.9661"
          ]
        }
      ],
      "source": [
        "model.fit(dataset,\n",
        "          epochs=epochs,\n",
        "          callbacks=callbacks,\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QGxWYuiQPnv"
      },
      "outputs": [],
      "source": [
        "# if use colab\n",
        "saved_model_path = \"saved_model\"\n",
        "\n",
        "# if use local env\n",
        "# saved_model_path = \"code/translate sentence/saved_model\"\n",
        "saved_model_dir = os.path.dirname(saved_model_path)\n",
        "\n",
        "if os.path.exists(saved_model_dir):\n",
        "  shutil.rmtree(saved_model_dir)\n",
        "  \n",
        "model.save(saved_model_path)\n",
        "\n",
        "files.download(saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFpBRO4W31YA"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS\n",
        "]\n",
        "converter.experimental_new_converter = True\n",
        "converter.allow_custom_ops = True\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_model_file = pathlib.Path('translation.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkJJXewBdV2J"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(\"translation.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_details, output_details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YmcvYUyzqLd"
      },
      "outputs": [],
      "source": [
        "class Translator:\n",
        "  def __init__(self, model_path, input_word_index, target_index_word, maxlen):\n",
        "    self.input_word_index = input_word_index\n",
        "    self.target_index_word = target_index_word\n",
        "    self.maxlen = maxlen\n",
        "    self.model_path = model_path\n",
        "\n",
        "    self._load_model()\n",
        "    self._load_vocab()\n",
        "\n",
        "  def _load_model(self):\n",
        "    self.model = tf.keras.models.load_model(self.model_path, compile=True)\n",
        "\n",
        "  def _load_vocab(self):\n",
        "    with open(self.input_word_index) as f:\n",
        "      self.input_vocab = json.load(f)\n",
        "    \n",
        "    with open(self.target_index_word) as f:\n",
        "      vocab = json.load(f)\n",
        "      self.target_vocab = {int(k):v for k,v in vocab.items()}\n",
        "      \n",
        "  def _normalize_and_preprocess(self, text):\n",
        "    punctuation = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        "    \n",
        "    text = text.lower().strip()\n",
        "    text = \"\".join((filter(lambda x: x not in punctuation, text)))\n",
        "\n",
        "    return text\n",
        "\n",
        "  def _texts_to_sequences(self, text):\n",
        "    words = text.split(\" \")\n",
        "    sequences = list()\n",
        "\n",
        "    for word in words:\n",
        "      if word in self.input_vocab.keys():\n",
        "        token = self.input_vocab[word]\n",
        "        sequences.append(token)\n",
        "\n",
        "    return sequences\n",
        "\n",
        "  def _sequences_to_texts(self, sequences):\n",
        "    words = list()\n",
        "\n",
        "    for token in sequences:\n",
        "      if token in self.target_vocab.keys():\n",
        "        word = self.target_vocab[token]\n",
        "        words.append(word)    \n",
        "\n",
        "    return words  \n",
        "\n",
        "  def lang_detector(self, sentence):\n",
        "    lang = TextBlob(sentence)\n",
        "    return lang\n",
        "    \n",
        "  def translate(self, sentence):\n",
        "    index_prediction = list()\n",
        "    normalize_sentence = self._normalize_and_preprocess(sentence)\n",
        "    \n",
        "    sequences = self._texts_to_sequences(normalize_sentence)\n",
        "    sequences = pad_sequences(\n",
        "        [sequences], maxlen=self.maxlen, padding=\"post\", truncating=\"post\")\n",
        "    \n",
        "    predictions = self.model.predict(sequences)\n",
        "\n",
        "    for i in predictions[0]:\n",
        "      index_prediction.append(np.argmax(i))\n",
        "\n",
        "    marks = [start_mark, end_mark]\n",
        "    result = self._sequences_to_texts(index_prediction)\n",
        "\n",
        "    result = \" \".join([word for word in result if word not in marks])\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkNd7WY3LSvJ"
      },
      "outputs": [],
      "source": [
        "input_wi = \"/content/input_word_index.json\"\n",
        "target_iw = \"/content/target_index_word.json\"\n",
        "\n",
        "translator = Translator(\n",
        "    encoder, decoder, input_tokenizer, target_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLjLFWVdFCCQ"
      },
      "outputs": [],
      "source": [
        "text_input = \"i'm looking for\"\n",
        "lang_detector = translator.lang_detector(text_input)\n",
        "\n",
        "if lang_detector == \"en\":\n",
        "  translate = translator.translate(text_input)\n",
        "  print(translate)\n",
        "else:\n",
        "  print(\"Bahasa tidak dikenali\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "translator2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "765233bfe060b87a8be23ec8f17030d468ac6435ae34b0ad14370b4cb734ac81"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}